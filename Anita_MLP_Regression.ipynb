{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xwcvRNDIPw2U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #Untuk manipulasi dan analisis data menggunakan struktur data DataFrame.\n",
        "import torch #Menyediakan tools untuk membangun dan melatih neural networks.\n",
        "import torch.nn as nn #Modul PyTorch yang berisi berbagai layer dan fungsi aktivasi untuk membangun neural networks.\n",
        "import torch.optim as optim #Modul PyTorch yang berisi berbagai algoritma optimasi untuk melatih neural networks.\n",
        "from sklearn.model_selection import train_test_split #untuk membagi dataset menjadi data training dan data testing.\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder #Berisi tools untuk preprocessing data seperti scaling dan encoding.\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score #untuk mengevaluasi kinerja model regresi dalam machine learning.\n",
        "import numpy as np #Untuk komputasi numerik menggunakan array multidimensi\n",
        "import seaborn as sns #Untuk visualisasi data yang menarik dan informatif.\n",
        "import matplotlib.pyplot as plt #membuat berbagai jenis visualisasi data seperti grafik garis, diagram batang, scatter plot, dan lainnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9M03yMtQsn_"
      },
      "source": [
        "## Load The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5hpZK3lXQoz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "07428566-df30-42af-96ad-6daa6bb0c0ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
              "0    1     M14860    M                298.1                    308.6   \n",
              "1    2     L47181    L                298.2                    308.7   \n",
              "2    3     L47182    L                298.1                    308.5   \n",
              "3    4     L47183    L                298.2                    308.6   \n",
              "4    5     L47184    L                298.2                    308.7   \n",
              "\n",
              "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
              "0                    1551         42.8                0                0    0   \n",
              "1                    1408         46.3                3                0    0   \n",
              "2                    1498         49.4                5                0    0   \n",
              "3                    1433         39.5                7                0    0   \n",
              "4                    1408         40.0                9                0    0   \n",
              "\n",
              "   HDF  PWF  OSF  RNF  \n",
              "0    0    0    0    0  \n",
              "1    0    0    0    0  \n",
              "2    0    0    0    0  \n",
              "3    0    0    0    0  \n",
              "4    0    0    0    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3296f06b-28b4-4814-8a70-0a5f7a6c02a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UDI</th>\n",
              "      <th>Product ID</th>\n",
              "      <th>Type</th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Machine failure</th>\n",
              "      <th>TWF</th>\n",
              "      <th>HDF</th>\n",
              "      <th>PWF</th>\n",
              "      <th>OSF</th>\n",
              "      <th>RNF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>M14860</td>\n",
              "      <td>M</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>L47181</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>L47182</td>\n",
              "      <td>L</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>L47183</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>L47184</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3296f06b-28b4-4814-8a70-0a5f7a6c02a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3296f06b-28b4-4814-8a70-0a5f7a6c02a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3296f06b-28b4-4814-8a70-0a5f7a6c02a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1823a8a9-207f-4307-adcb-a8f6315fc4e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1823a8a9-207f-4307-adcb-a8f6315fc4e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1823a8a9-207f-4307-adcb-a8f6315fc4e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#memuat dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"UDI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"L47181\",\n          \"L47184\",\n          \"L47182\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"L\",\n          \"M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Air temperature [K]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05477225575049793,\n        \"min\": 298.1,\n        \"max\": 298.2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          298.2,\n          298.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Process temperature [K]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08366600265339941,\n        \"min\": 308.5,\n        \"max\": 308.7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          308.6,\n          308.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rotational speed [rpm]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62,\n        \"min\": 1408,\n        \"max\": 1551,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1408,\n          1433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Torque [Nm]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.2231504827557345,\n        \"min\": 39.5,\n        \"max\": 49.4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          46.3,\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tool wear [min]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Machine failure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TWF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HDF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PWF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OSF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RNF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df = pd.read_csv('/content/ai4i2020.csv')\n",
        "df.head()\n",
        "#memuat dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "38Rd_Gk5Q2jF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd45234-811d-4962-dd5a-41c29b704381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   UDI                      10000 non-null  int64  \n",
            " 1   Product ID               10000 non-null  object \n",
            " 2   Type                     10000 non-null  object \n",
            " 3   Air temperature [K]      10000 non-null  float64\n",
            " 4   Process temperature [K]  10000 non-null  float64\n",
            " 5   Rotational speed [rpm]   10000 non-null  int64  \n",
            " 6   Torque [Nm]              10000 non-null  float64\n",
            " 7   Tool wear [min]          10000 non-null  int64  \n",
            " 8   Machine failure          10000 non-null  int64  \n",
            " 9   TWF                      10000 non-null  int64  \n",
            " 10  HDF                      10000 non-null  int64  \n",
            " 11  PWF                      10000 non-null  int64  \n",
            " 12  OSF                      10000 non-null  int64  \n",
            " 13  RNF                      10000 non-null  int64  \n",
            "dtypes: float64(3), int64(9), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()\n",
        "#untuk menampilkan ringkasan informasi tentang DataFrame Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dbAlPU87Q5gT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "267e0489-18dd-44fe-db63-616b3e64846b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               UDI  Air temperature [K]  Process temperature [K]  \\\n",
              "count  10000.00000         10000.000000             10000.000000   \n",
              "mean    5000.50000           300.004930               310.005560   \n",
              "std     2886.89568             2.000259                 1.483734   \n",
              "min        1.00000           295.300000               305.700000   \n",
              "25%     2500.75000           298.300000               308.800000   \n",
              "50%     5000.50000           300.100000               310.100000   \n",
              "75%     7500.25000           301.500000               311.100000   \n",
              "max    10000.00000           304.500000               313.800000   \n",
              "\n",
              "       Rotational speed [rpm]   Torque [Nm]  Tool wear [min]  Machine failure  \\\n",
              "count            10000.000000  10000.000000     10000.000000     10000.000000   \n",
              "mean              1538.776100     39.986910       107.951000         0.033900   \n",
              "std                179.284096      9.968934        63.654147         0.180981   \n",
              "min               1168.000000      3.800000         0.000000         0.000000   \n",
              "25%               1423.000000     33.200000        53.000000         0.000000   \n",
              "50%               1503.000000     40.100000       108.000000         0.000000   \n",
              "75%               1612.000000     46.800000       162.000000         0.000000   \n",
              "max               2886.000000     76.600000       253.000000         1.000000   \n",
              "\n",
              "                TWF           HDF           PWF           OSF          RNF  \n",
              "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.00000  \n",
              "mean       0.004600      0.011500      0.009500      0.009800      0.00190  \n",
              "std        0.067671      0.106625      0.097009      0.098514      0.04355  \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.00000  \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.00000  \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.00000  \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.00000  \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.00000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-078a959f-3a2e-433f-9288-15d2683f90af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UDI</th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Machine failure</th>\n",
              "      <th>TWF</th>\n",
              "      <th>HDF</th>\n",
              "      <th>PWF</th>\n",
              "      <th>OSF</th>\n",
              "      <th>RNF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>300.004930</td>\n",
              "      <td>310.005560</td>\n",
              "      <td>1538.776100</td>\n",
              "      <td>39.986910</td>\n",
              "      <td>107.951000</td>\n",
              "      <td>0.033900</td>\n",
              "      <td>0.004600</td>\n",
              "      <td>0.011500</td>\n",
              "      <td>0.009500</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.00190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2886.89568</td>\n",
              "      <td>2.000259</td>\n",
              "      <td>1.483734</td>\n",
              "      <td>179.284096</td>\n",
              "      <td>9.968934</td>\n",
              "      <td>63.654147</td>\n",
              "      <td>0.180981</td>\n",
              "      <td>0.067671</td>\n",
              "      <td>0.106625</td>\n",
              "      <td>0.097009</td>\n",
              "      <td>0.098514</td>\n",
              "      <td>0.04355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>295.300000</td>\n",
              "      <td>305.700000</td>\n",
              "      <td>1168.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2500.75000</td>\n",
              "      <td>298.300000</td>\n",
              "      <td>308.800000</td>\n",
              "      <td>1423.000000</td>\n",
              "      <td>33.200000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>300.100000</td>\n",
              "      <td>310.100000</td>\n",
              "      <td>1503.000000</td>\n",
              "      <td>40.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7500.25000</td>\n",
              "      <td>301.500000</td>\n",
              "      <td>311.100000</td>\n",
              "      <td>1612.000000</td>\n",
              "      <td>46.800000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>304.500000</td>\n",
              "      <td>313.800000</td>\n",
              "      <td>2886.000000</td>\n",
              "      <td>76.600000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-078a959f-3a2e-433f-9288-15d2683f90af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-078a959f-3a2e-433f-9288-15d2683f90af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-078a959f-3a2e-433f-9288-15d2683f90af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0fbc0182-c5cc-4032-a7d7-ac45e9d6eb58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fbc0182-c5cc-4032-a7d7-ac45e9d6eb58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0fbc0182-c5cc-4032-a7d7-ac45e9d6eb58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#untuk menghasilkan statistik deskriptif dari DataFrame Pandas\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"UDI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3603.743586536124,\n        \"min\": 1.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          10000.0,\n          5000.5,\n          7500.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Air temperature [K]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3446.112587891836,\n        \"min\": 2.0002586829157574,\n        \"max\": 10000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          300.00493,\n          300.1,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Process temperature [K]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3443.232448462189,\n        \"min\": 1.4837342191657419,\n        \"max\": 10000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          310.00556,\n          310.1,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rotational speed [rpm]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3103.301433905864,\n        \"min\": 179.28409591342628,\n        \"max\": 10000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1538.7761,\n          1503.0,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Torque [Nm]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3522.9553380464768,\n        \"min\": 3.8,\n        \"max\": 10000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          39.986909999999995,\n          40.1,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tool wear [min]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3498.6028684989537,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          107.951,\n          108.0,\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Machine failure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.4725618125285,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0339,\n          1.0,\n          0.18098084265064265\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TWF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.479765071392,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0046,\n          1.0,\n          0.06767051004531742\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HDF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.477448920331,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0115,\n          1.0,\n          0.10662498247917784\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PWF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.4780356645374,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0095,\n          1.0,\n          0.09700871645943188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OSF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.4779444983915,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0098,\n          1.0,\n          0.09851360562404972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RNF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3535.481119834332,\n        \"min\": 0.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0019,\n          1.0,\n          0.04354973774853278\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.describe()\n",
        "#untuk menghasilkan statistik deskriptif dari DataFrame Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tJMu8Q0DQ8SB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "4bc7e2ef-28ab-4567-9488-61fd6e76af25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UDI                        0\n",
              "Product ID                 0\n",
              "Type                       0\n",
              "Air temperature [K]        0\n",
              "Process temperature [K]    0\n",
              "Rotational speed [rpm]     0\n",
              "Torque [Nm]                0\n",
              "Tool wear [min]            0\n",
              "Machine failure            0\n",
              "TWF                        0\n",
              "HDF                        0\n",
              "PWF                        0\n",
              "OSF                        0\n",
              "RNF                        0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>UDI</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Type</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Machine failure</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TWF</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HDF</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PWF</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OSF</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RNF</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.isna().sum()\n",
        "#untuk menghitung jumlah nilai yang hilang (missing values) di setiap kolom DataFrame Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uBIMZWidRAW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8740e1a-8dd0-4f74-8617-fde0dbeba50f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['UDI', 'Product ID', 'Type', 'Air temperature [K]',\n",
              "       'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]',\n",
              "       'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF',\n",
              "       'RNF'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.columns\n",
        "#untuk mendapatkan daftar nama kolom dalam DataFrame Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tluV-i6NRGSH"
      },
      "outputs": [],
      "source": [
        "label_cols = ['Product ID', 'Type', 'Machine failure']\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for col in label_cols:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "#melakukan encoding pada kolom kategorikal menggunakan LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P3oennWIRIk4"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['Machine failure'], axis=1)\n",
        "y = df['Machine failure']\n",
        "#menentukan fitur (X) dan target (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F8BYOZsDRQF-"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#psahkan data menjadi training dan testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0y7-3EtrRUkI"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "#standardisasi fitur numerik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r-9RyKD_RatN"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "#konversi data ke tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tbx6AIBGRg03"
      },
      "outputs": [],
      "source": [
        "class MLPRegression(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, neurons, activation):\n",
        "        super(MLPRegression, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.neurons = neurons\n",
        "        self.activation = activation\n",
        "\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(self.input_size, self.neurons))\n",
        "        #membuat layer input ke layer tersembunyi\n",
        "\n",
        "        for _ in range(self.hidden_layers - 1):\n",
        "            layers.append(self.activation())\n",
        "            layers.append(nn.Linear(self.neurons, self.neurons))\n",
        "        #Menambahkan hidden layers\n",
        "\n",
        "        layers.append(nn.Linear(self.neurons, 1))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze()\n",
        "\n",
        "#menyusun model MLP untuk regresi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s5lrONWRwNa",
        "outputId": "438bcb69-e154-4a71-d373-641c78260a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-4645.474972367287\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-123693.95831937791\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-66536.14659588337\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-137135.0211600304\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-65246.05434296132\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-60373.60693879127\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-136.33811312913892\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-727.5809589400887\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-749.0453414693475\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-828.3919089227915\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-129.51355482339858\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-322.70600288063287\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:80.0300198717974\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:81.49238389879466\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:69.56873292401433\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:69.87816464919597\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:87.41916178883984\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:90.622894376982\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:47.32902847826481\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:82.35875726304948\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:59.75716878399253\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:72.38172302246093\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:61.5177000068128\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:59.8839207008481\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.76403284817935\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:79.68388364315034\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:58.829420344531535\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:46.6381076157093\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:83.45501693822443\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:64.30203264318406\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:20.92819120809436\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:68.79647630155085\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:42.765787184238434\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:71.72159079760313\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:63.25712386518717\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:66.86680999696254\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-11373.855893898011\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-44503.44413651228\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-34883.010423862936\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-33842.756896549465\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-13390.919272232057\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-16591.953105926514\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-89.05723463594914\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-21.96704643517733\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-65.19204057455063\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-228.6811547935009\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-152.78851748108866\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-111.82035276293756\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:93.26730342153459\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:92.38450800087304\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:96.61358456062153\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:80.18597595058381\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.57944593802094\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:94.38041306622327\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.21153996288776\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.84264721646905\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:93.50412543166895\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.33209039433859\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:94.07390482677147\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:94.00373590621166\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:83.03950225301087\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:73.3569049295038\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:49.86043471470475\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:41.15602873116732\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:75.31757585722954\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:87.47073596995324\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:39.42314440682531\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:58.61786543615162\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:73.96451546028257\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:75.66854733377694\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:74.54801477147267\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:60.55971493944525\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-12351.186618423462\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-2655.232585334778\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-14778.769150733948\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-14084.296195316316\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-15648.556531906126\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-36369.249407315256\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-13.729570436477667\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:27.897935402393337\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-57.93157461881637\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-89.21379653960466\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-87.08504480719566\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-43.87560770511627\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:92.53053024709224\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:97.25023305905052\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:96.84222542718052\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:97.46622377615421\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:96.99864165857434\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.80958206066862\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:95.31987998411059\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.97561035659164\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:94.47889569476247\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:94.70961502548307\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:94.887010581512\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:93.9282975077629\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:77.83193905353546\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:50.909136668592694\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:76.28196186311543\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:86.21609060205519\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:66.95610918961465\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:76.14382156282663\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.720592046529056\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:80.4705928524956\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:68.3739430308342\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:70.30480647459626\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.46760768592358\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:81.2260990459472\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1952.9301927566528\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-907.3267673611641\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4663.253123474121\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-3505.4931946039196\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2114.6347147703173\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1841.8819896697996\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:92.23659536498599\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:51.70715938210487\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:37.41421911716461\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:46.36652384400368\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:80.86468111276626\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:49.5782150387764\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.26431620158255\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.98199958726764\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.36576706147753\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.69986720741727\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.22775706648827\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.73169676810502\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.67694335179404\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:97.72121095508336\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:97.66820024503396\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.17255989033728\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.06116072935983\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.39525034548716\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:66.19463099837304\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:92.09880488291383\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:78.44046340882778\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:88.84137836843729\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.55446547307074\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:88.5945417895913\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:73.1662595629692\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:60.290074451267714\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:76.00491408966481\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:62.00575874596834\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:56.061454392224555\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:46.452999606728554\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-67.22726042270662\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:13.648671269416813\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:73.81664788722992\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-676.4240653991699\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-111.885489577055\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-190.16748809814453\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:97.93847645521164\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:96.7217570066452\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:97.1043090492487\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:97.4141771376133\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:96.96761312093585\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:97.15996890515089\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.06434650034643\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.93994476520457\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.04305569208228\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.03793214932084\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.01757309800014\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.07246751869097\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:98.957075496763\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:98.84893880486489\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.01167507693171\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:98.98159467577933\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:98.91080206632614\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.10698614045977\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:72.42433069646358\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:74.39873650297523\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:71.33349414020776\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:92.58249662145973\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:91.25675582662225\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:85.46401106864214\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:81.415517244488\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:86.06869270466268\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:69.39370872620493\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:75.38861314840615\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:79.68555721119046\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:73.53411184698344\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:93.5023035287857\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-95.90659408271314\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:96.14504532814026\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:92.56013925336302\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:97.46897830963135\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:96.3716760635376\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:99.06361588835716\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:98.99572539329529\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06819369792939\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.06683434247971\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:98.5384239077568\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.067023062706\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06684679165483\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06264253519475\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.0682577362284\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:98.51092837001197\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.07021429166197\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:98.7017931163311\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:98.91481487648561\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06643483564258\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.0380972802639\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06740213036537\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06612908169627\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06733304709196\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:86.8315403148532\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.0613325588405\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:97.37164150625468\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:95.6992365250364\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:96.8476065710187\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.41509173549711\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.24936331287027\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:59.20962319746613\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:81.41633062437177\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:86.45975635629148\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:68.55917389132082\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:78.59523220658302\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-61749.04266428947\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-57768.68891749382\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-123853.52958185672\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-137993.29639759063\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-125752.39386339187\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-3206.95634675026\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:2.2176879763603163\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-356.8741527214646\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-333.10158775597813\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-852.5514608055353\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-165.02912051826715\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-595.8366500645876\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:73.02641574516893\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:93.92855638302862\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:90.10855190837755\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:76.35666266307236\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:75.3905269889161\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:80.51467071017251\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:59.19088715016842\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:57.10495972260833\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:60.93254183977843\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:58.94593315124512\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.8469451636076\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:46.80128579810262\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.510687762498854\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:62.509184518456465\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:69.45424017943442\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:36.42460994049907\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:73.27046692911536\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:57.864834517985585\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:61.64329099059105\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:64.58428979888559\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:84.9211861262098\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:64.54551500305533\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:69.30633206870407\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:62.314979939907786\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-16316.718623352052\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-28748.36491961479\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-24308.398740482327\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-30298.40043138266\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-50704.80808897018\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-18445.073340988158\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-180.9471995025873\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-87.25709937810898\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-199.58104212880136\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-107.6396682024002\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-306.50564812123775\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-224.53238256573678\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:95.95212780293078\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:89.75355480033905\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:95.88707096911968\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:93.99309461712836\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:92.78398995050229\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:95.53248271215708\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:90.99892614525743\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:87.65844466388225\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.00981649570167\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:89.88455746043473\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:84.67560850195586\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:84.9797804415226\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:57.86707699447871\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:74.57671373225749\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:67.63834941089154\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:47.4772145345807\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:69.15557224340738\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:68.26986214853822\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:40.16570347100497\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:67.02457787245513\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:66.98128982186317\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.44869489818811\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:80.22383865686133\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:68.55574857220054\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-7384.30661444664\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-18213.97505645752\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-10220.603869342804\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-3268.587390613556\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-11195.851197957993\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-22791.978463554384\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-39.06041272878647\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-39.22925819754602\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-41.48656386137009\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:3.283720582723615\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1.2730536699295136\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-131.9585002630949\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:91.9417197143659\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:97.04774016151205\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.36985619198532\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:97.82243060031905\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:97.16389603903517\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:95.42274653743952\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:82.8441429503262\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:94.92390013588592\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:93.40647002309561\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:85.102041997388\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.09871281525119\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.57976339440792\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:65.89457218721509\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:89.44237787239253\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:64.21040870323777\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:77.95029467269778\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:52.20879246592523\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:84.01624597460031\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:54.36189352944494\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:77.79981315238402\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:65.25232901386917\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:65.35153030157089\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:62.43109834305942\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:72.07492171153427\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2900.7621558189394\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-2794.695433521271\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5481.291179466248\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1832.3634326934816\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-5005.192819643021\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2553.697072225809\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:76.87818279638886\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:56.566592815518376\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:74.23397873044014\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:57.608090072870255\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:58.503557527065276\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:80.8044110879302\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:99.14972383810672\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.79610164966435\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.1483633861877\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:97.78419973831623\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.55520258862526\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.08003248302266\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:96.39265692569316\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:97.54130459278822\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.14787447750568\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.27112690813374\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.66895151529461\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.40277013853192\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:58.99412676393986\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:82.7665355041623\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:66.92469617202879\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:69.74662851616739\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:90.4553909227252\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:87.96080319560133\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:73.6060392184183\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:45.56243653818966\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:79.48526439256966\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:66.53968068435788\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:49.73901024609803\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:63.245173945277934\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:8.080423355102539\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-84.62621356844902\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-144.04410934448242\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1153.828955411911\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-157.3857786655426\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-108.93343181610109\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:95.28130265548825\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:97.24941443949938\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:96.48933264166116\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:96.69516007900239\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:96.310649754107\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:98.63273997306824\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.09252146991203\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.96461534146219\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.04671339597553\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:98.9919484640006\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:98.88105807183311\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.99910000246018\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:98.95180630078539\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.06474459687014\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:98.68319527171552\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.08759910799563\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:98.6480467476882\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:98.89005816057325\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:93.28721469696612\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:71.74360573515295\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.89790391996503\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:97.42281199134887\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:93.05666650328786\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:92.2142214776948\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:77.83593004522845\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.83902192935348\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:77.55798315182328\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:57.69653547555208\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:76.8640173083637\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:67.57527492381632\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:95.5671527147293\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:4.6106326103210415\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:97.70755110681057\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:94.1633593082428\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:98.97431907653808\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:99.02402591705322\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.98590066432953\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.0677695274353\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:98.74486567955464\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.06763892769813\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.06739592552185\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.06731536984444\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.07012316882611\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.07056464686757\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.07255329531618\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.05984226632863\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.05545564368367\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.0620667242445\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06119682341814\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.0759087593644\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:98.71426746398211\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.07050346005708\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.04658973962069\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06146045401692\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:97.84877187097445\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:97.78463198244572\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.04478859305382\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:97.97367478013038\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.83181787468493\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.04437120538205\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:73.24352927803993\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:78.03233047686517\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:58.151864195615055\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:74.2831647656858\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:78.47080718204379\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:79.75710116438567\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-68342.0562253952\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-65863.96969342232\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-51365.602941775316\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-59049.753187441835\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-76657.41041340827\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-57914.5876026392\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-73.48147879093885\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-763.9048499643802\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-419.76036048829553\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-91.06635117977856\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-809.6083647966385\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-760.3080540254713\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:77.00480859428644\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:55.149324954301115\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:93.06398557429202\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:72.931014919281\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:91.00514814008494\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:85.92084701228887\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:55.446963202953334\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:47.02965483367443\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.43252724930644\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:71.5660509917885\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:60.189547624439\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.701167581975454\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:41.77515566945076\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:73.02746330536903\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:62.436372994258996\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:42.25989048033952\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:77.05967479087413\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:66.20964636169374\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:71.434364445135\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:57.9302101161331\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:73.40106274113059\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:54.98317904770374\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:72.11456715911626\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:67.22850088924169\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-58011.28002300262\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-32396.624424138667\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-19461.121588516235\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-42253.99236109257\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-40438.331759828325\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-46918.24513802231\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-48.20650018155575\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-121.62089833021166\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-93.01810371875763\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-94.9481277346611\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-460.2864217162132\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-39.056251606345185\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:85.86711844461969\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:92.02658491395414\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:91.40411300100386\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:95.11153560010716\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.48344479752704\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:92.86439361162483\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:65.61787002682686\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.136151874065405\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:69.27206825092436\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.09666811842472\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:89.5612157933414\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:81.44214589968324\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:76.11297852881252\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:61.05975029915571\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:60.52917401567102\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:82.29523084703833\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.15162273645401\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:50.919584815204146\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:68.49556328877806\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.99961229935288\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:65.71680317660793\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.432184933125974\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:72.17420023940504\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.31963781192899\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-9673.996159267424\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-3100.2690823554994\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-14559.43439092636\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-3138.577713489533\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-12638.997252726555\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-14669.346034049988\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-117.59974008798596\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:28.44347459077835\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-25.933055460453037\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-31.557190465927132\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-110.50615441799164\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:4.984297445416452\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:97.3113694543019\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:97.10855048187076\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:97.28047622740269\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:96.07719479752704\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:97.08307737456636\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:97.26146810282953\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:91.92142208646983\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:94.85663667609914\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.6184780459851\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.92038936098106\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.36943424949422\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.42021841965615\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:68.81744086779655\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:80.38955114148557\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:60.254988078027964\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:89.68943499736488\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.51764507368206\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:62.95379583612084\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:71.95226205214857\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.05984511300921\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:75.58913433998823\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:70.72548576761038\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:68.70587532222271\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:45.13483450561762\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-3551.695230436325\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5468.579150772095\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6145.6559036254885\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-964.7982409000397\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3128.6004800319674\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1109.010629439354\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:74.94509755074978\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:46.54588032960891\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:68.33072514235974\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:58.11544525623322\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:60.52563651949168\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:74.64091001749038\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.49718583938666\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.4883341233246\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.7180127615342\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.3140531821875\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.89366942420602\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.4308669094462\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.83495772890747\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.11932593286038\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:97.70725283771753\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.51585300341249\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:97.40523258149624\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.70197425119113\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:69.82442980185151\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.1211987676099\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:77.87917555943132\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:82.92533033266663\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:84.99157188683748\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:67.43719526678325\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:57.02400644943118\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:42.79300741925836\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:63.02964695841074\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:45.811406299471855\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:73.52743834014981\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:57.92117120102047\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-129.18844089508056\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:50.63648672103882\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:52.19935305118562\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-3.5517871141433677\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-6.80300049781799\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:30.608577799797054\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:96.03846834474243\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:97.03990782219917\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:98.10421075820923\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:97.26191525412723\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:97.86143463253974\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:97.44135541319847\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.03135920539499\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.05420231926256\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.0435003313236\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:97.83404361726717\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.03181224651635\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.99148828466423\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:98.50045760162175\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:98.52171579152346\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:98.67196869184262\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.01135274544359\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.0739191569388\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:98.56763451844454\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:90.35969983413815\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:84.0895215369761\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:90.8073228482157\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:89.90195132382213\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:81.2213884435594\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:95.17434314992279\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:65.06635426431895\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:71.98424284420908\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:64.59812706708907\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:67.22988353371619\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:82.47320764060132\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:48.19091270677745\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:97.86827807426452\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:98.8517214179039\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:97.34604572057724\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:99.0178035736084\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:58.624744367599476\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:99.11399593353272\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.94130268618464\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.0653849184513\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.0679320693016\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:98.8115497916937\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.00530004673638\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:98.93191269040108\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:98.19808912808075\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.07216611322947\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06501391390339\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06948374137282\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06949053453282\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.03257239349188\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06716048996896\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06720356866717\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:98.89534212052821\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.07238044987898\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06771598979832\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.05293137636035\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.33218293599785\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.85346233099699\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.94964624643325\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.09135167300701\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:97.70782503895461\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.7223284073174\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:82.1422047963366\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.53888740614057\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:77.09453910216689\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:86.60332301687448\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:47.47274640873075\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:69.60912333652377\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-60937.21526396274\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-53250.21075210572\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-69633.59730331898\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-2516.2225397109987\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-116113.02223336697\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-132924.6890669346\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-340.80309340208765\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-839.6618866726757\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-809.5023718252778\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-161.0083636805415\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-206.48221109211445\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-221.60696805417535\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:87.20933901695534\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:79.29327252008952\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:79.13334655156359\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:70.73621129915118\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:76.58325298354029\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:80.569663958624\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:36.10675402134657\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:74.07576742637903\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:69.1297644983977\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:77.74253137260676\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:59.58732536658644\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:66.65966863036155\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:53.951540945470335\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:70.17972620083019\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:71.37976674400271\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:30.030853738635777\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:78.66098683273886\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:62.88095795363188\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:67.699728365615\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:71.4247896399349\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:78.84615293852984\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:66.64301380887628\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:48.827381768077615\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:60.85120513439178\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-38710.73727182746\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-14518.419185066225\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-35091.85564994812\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-34339.42543909848\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-17255.57787399292\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-17217.275794219968\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-67.37325784265995\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-104.0466129422188\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-171.58729289472103\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-67.3386035501957\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-303.63764779865744\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-220.9251523852348\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:96.68004288622178\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:96.10829193042592\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:90.17962863612921\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:92.96669487436301\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:97.33213014816864\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:93.58424811400474\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:89.26718837935478\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:67.49133098050952\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:78.55648073926568\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:96.19343438018113\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:84.07194569706917\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:75.74743054285645\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:67.00364970713855\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:65.49169725514949\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:37.0356576219201\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:67.5920202948153\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:74.23571144901216\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:80.46597317410632\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:77.85575898662209\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:66.50414846390485\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:59.450064925104385\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:71.12430260572582\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:67.89948595687747\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:73.98941237130202\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-8613.82873635292\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-7633.584209823609\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-13187.416156721116\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-17678.800883197782\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3510.9235246658322\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-14391.41630191803\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-84.78915707990527\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-0.7195754110813191\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:39.00989592075348\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:67.11165023297072\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-32.708098459243786\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-0.43182949125766257\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:93.60351877156646\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:98.02703376878053\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:96.10416171597316\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:97.2656248361338\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:95.13976265341043\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:97.54402028108015\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:94.1818862117827\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:91.94974080771208\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:92.31688872422092\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.72759194001556\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:93.25105578061194\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.40448635742068\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:57.179314544796945\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.676432638615374\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:77.45325284786522\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:71.90819109454752\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:76.32148703113198\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:85.12475816111547\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:72.0209363438189\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:80.09988637156783\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:77.9207506544888\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:72.1108578145504\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.63787076398731\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:77.74924922315404\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1703.2377707719802\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5296.807688236237\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6215.304676914215\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-93.1030828475952\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1979.7310925722122\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-9282.814454030991\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:70.75511408746242\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:80.86238666772843\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:73.32577868383378\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:72.25026510953903\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:87.75684254169465\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:92.12927255034447\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.43762343004346\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.40226397588849\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.62831590566785\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.37995728775859\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.604313547723\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.4240985730663\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:95.93506758846343\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.29453930305317\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.64739699009806\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:96.80270504578948\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.13374105975963\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.54528148584068\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:77.2935274200514\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:88.12632515281439\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:90.69050506539644\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:87.07966899611056\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:75.56384458802641\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:84.93582830987872\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:70.57432188652456\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:89.14318020073696\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:82.26986246742308\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:75.93297368884086\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:56.19848292171955\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:73.69620216339827\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-26.82899250984192\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-149.91388280391692\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-4.332390022277832\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-120.57045161724092\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-63.6638060092926\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-81.55166997909546\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:96.93689558506013\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:96.64093293249607\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:93.79152145981789\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:49.50955173969269\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:97.28452701568604\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:97.27793192863464\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.11357242297382\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.03791752811522\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.10660641279537\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.07823070194573\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.025788856484\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.24248494608328\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.06949124168605\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.0278599394107\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.02309260698968\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:98.86894986350089\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:98.89976269304752\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.05656975060701\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:96.05003103688358\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:92.00708019584417\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:92.98932519308292\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:84.67469426319003\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:92.42369075752794\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:93.83003241531551\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:70.44923765081911\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:75.10153144374489\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:84.0288341505453\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:87.68815548429265\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:75.6960463501513\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:47.999825031310316\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:94.95467739105224\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:90.38181853294373\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:94.54107308387756\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:96.48017818927765\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:97.75880930423737\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:86.37038526535035\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:99.06776652932166\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.07192841768266\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:98.82788824969903\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:98.14070742633194\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:98.99322286844253\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.04106083689258\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.07245518825948\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06189048253\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06744907125831\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:98.99702091943473\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.07011467916891\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.06896743550897\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.05545237213373\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:98.88999031088315\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06288931518793\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.07344160748762\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.067504619807\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06940328255295\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:97.71905871108174\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.52200737353415\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.58899725079536\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.48219404481351\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.4679792009294\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:91.27237120345235\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:71.72214988023042\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:82.9867272711941\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:66.25821800380946\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:66.26424332335591\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:77.87973902113737\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:74.78945441544056\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-64114.55360577106\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-206434.89764957427\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-185435.99379470348\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-121737.07300362588\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-204295.87347664832\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-123064.22475926876\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1498.6050205990673\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1030.6012292966245\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-66.64316403567791\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1230.4488549381495\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-696.1849231049418\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1248.5254213646056\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:74.50124810775742\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:82.49140010215342\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:71.74577086046338\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:85.04799846690148\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:82.78006637003273\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:73.27329946123064\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:84.53594562001527\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:62.00522416830063\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.22022891938687\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:76.55627441182733\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:85.5428548982367\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:70.47483913600445\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:68.75860483348369\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.00736295282841\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:85.23884690441191\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:75.21421097964048\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:84.77737856274472\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:69.90738541521132\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:71.16467064470054\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:72.45055611431599\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:83.11767223030328\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:62.65668893717229\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:77.27970464900136\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:74.81087182331831\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-85050.66561553479\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-75151.90637981295\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-96662.07846553327\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-75251.57284893989\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-78188.86009440423\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-72075.96829781533\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-269.1293023318052\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-466.74004045426847\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-971.1422630250454\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-311.80631234645847\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-292.18833701610566\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-277.8378556460142\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:94.15979766491802\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:93.83525514272041\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:88.14017980936914\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:96.01964252772741\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.58689069747925\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:94.63674186496064\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:87.5173125360161\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.87210638541728\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:92.88769752383233\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:89.78653015829623\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:80.87567589096724\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:93.65393565110863\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:69.0231194972992\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:83.64612902626395\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:77.07286591231824\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:67.2938649699092\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:70.32642733706162\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:68.40569805502892\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:73.90006530918181\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:83.70053487159312\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:60.382216605544095\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:54.89981630221009\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:79.00873264623806\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:60.36447393335402\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-6807.017602062226\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-2016.789393568039\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-17506.644735383987\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-23544.571997356416\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-12775.67206439972\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-26777.378997898104\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:50.24350571632385\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-255.6759872972965\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-138.28697987794877\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-105.94292669296266\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-131.08108453154563\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-3.2998108863830478\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:97.32122595123947\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:95.39115858264267\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:94.37855207985267\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:96.90626296924893\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:92.48000837117434\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.16759092006832\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.68819708265363\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:96.63427899843083\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:93.65382530093194\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.36811899328605\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.91586351990699\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.44574825540185\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:89.28332749325783\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:86.72325795292855\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:70.00643075294792\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:77.8138674736023\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:78.17125903964043\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:59.96574736908078\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:64.61748066022992\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:77.94258443266153\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:76.962393797189\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:85.33226268300787\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:61.86935552060604\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:68.3631785016507\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-5364.094974422455\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-6912.44303226471\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6251.205616903305\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-6237.090429401397\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-6291.937922906875\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-5114.726509857178\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:32.19366817474365\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:36.14893987178802\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:56.928337049484256\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:6.009971666336056\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:60.197184050083166\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:39.407041466236116\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.6723656415008\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:97.93389423659536\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.06953092766926\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.09478567847982\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.57979514375329\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.19790280219168\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.60944357421249\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.39227124731987\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.38203275501728\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:97.97140756547451\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.69705797806382\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.16906240805984\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:80.40103848800064\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:85.15576889924705\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:88.9778054367751\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.70803189277649\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:86.20585312694311\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:88.73700708076358\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:76.25532829640433\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:62.97769317813218\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:69.65938360206782\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:85.29554714495316\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:78.40434115417303\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:67.22134018093348\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-135.43487784862518\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-493.2436205387115\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2072.96634349823\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-283.3599308013916\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2085.024563550949\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-40.98888182640075\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:95.31034750938416\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:95.03895073756576\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:95.71634992659092\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:92.761670422554\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:94.35511679649353\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:95.47462985515594\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.04852866400033\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.07740119099617\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.0686904408969\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:97.71194656530861\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.00802732370794\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.07358492519707\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.01057564243673\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:98.99304707180708\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:98.8992152556777\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:98.96336540151387\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.05664501190185\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.06412152145057\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:96.78064597006887\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:93.69485984481871\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:92.07229376845062\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:96.29332455489784\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.39302450492978\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:96.50852061461191\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:81.35080174952746\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:82.43383059240877\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:73.6553084887564\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:74.3145181817934\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:66.45108425244689\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:76.22189047336579\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:99.0514108657837\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:96.83977184295655\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:78.30425605773925\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:99.11629343032837\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-19.591581892967213\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:94.9152889251709\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:39.068211543560025\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.07100313901901\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:78.47837841510773\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:98.79594159126282\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:66.77561696171762\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.06068741977215\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06894953623414\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.0621775784064\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:98.68889990109018\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06749415397935\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.0678033992648\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.06983656724915\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06752509884537\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06729884222149\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06881527490914\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.0683099295944\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06749001443386\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06751351505518\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.68714880533517\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.62283116281031\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.19302602559328\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.28022948512807\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.15915132910014\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.24545800182969\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:85.3607987898402\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:85.49099090658127\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:59.66262556761504\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:79.7124827053398\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:76.84864765182138\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:78.74727778062226\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-136248.83124246597\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-207183.33881583213\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-55391.437921929355\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-61496.14247786999\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-52164.51107738018\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-195199.44732038977\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1191.224644164741\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-713.884277638793\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-571.2853992775083\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-642.1421724900603\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1204.6651101484895\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1088.4866854354739\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:76.20731144957244\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:59.7361826444976\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:78.924972894229\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:74.71579325944185\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:68.7320679590106\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:74.68576674852521\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:76.93012287467718\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:72.8593750923872\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:83.02520525790752\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:63.04874502569437\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:68.06825210116804\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:81.67900952813216\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:73.45605020299554\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:73.25237729344516\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:85.65407255319879\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:78.7501939676702\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:70.93983239494264\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.45685832723974\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:64.89220349565147\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:82.44622933547944\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:63.88253660649062\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:72.70525989830494\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:67.68612615391612\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:80.6858925383538\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-111368.25684938431\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-34016.62643947601\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-83903.08152308465\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-83176.74227266312\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-93225.93081269263\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-79711.55397529602\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-607.5798723340034\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-750.6283991843462\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-347.3598766922951\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-250.19059745669364\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-251.5906845867634\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-287.8141098409891\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:92.9198388318997\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:92.41282949168234\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:93.37970948773436\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:83.07018991569058\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:96.37278792103753\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:93.00245091458783\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:91.10607266612351\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.71494406834245\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.21881850529462\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:92.80825537876225\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:86.43415539301932\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:88.92121609933675\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:80.4635972643271\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:62.748018327355396\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:68.35138037353754\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:88.06155828386545\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:81.85739583373069\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:71.955062005762\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:70.71198593005539\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:65.19495010450483\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.0265294637531\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:67.85770523399115\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:72.21723026409745\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:60.94514640644193\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-16301.159937477112\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-26142.787098598477\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-24106.912725639344\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-16984.9287443161\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-10247.581347942352\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-40093.527336311345\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-213.16514607667924\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-34.065576669573794\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-40.98058096170425\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-229.82371733188631\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-14.36883910894393\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-85.49719979166986\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:97.77577241826802\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:95.79960055109113\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.90551138510928\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:97.13740434935316\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:95.68427208438516\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:95.98727957643568\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:93.02678201906383\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.53787454664707\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:90.98887684755027\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:94.50689114462584\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:93.77343970015644\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:95.59596502445639\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:80.16350864619017\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:85.95940566509962\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:83.9507330215536\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:81.37271571503952\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:86.18711010143161\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:81.71771899946035\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:74.81993747763336\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:66.8227493119426\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:75.04673723839224\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:67.39656835868955\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:69.76882876753807\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:59.20480284318328\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-3906.8230203628536\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5145.542377948761\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-24497.361977076533\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-7003.209786665439\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-6978.451237773895\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3623.805585694313\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:43.36597072184086\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:57.02928739786148\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:55.10575444698333\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:36.28115807175636\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:69.35355262029917\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:10.69467177987099\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.52252649851143\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.87197451274842\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.89496097508818\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.31816032063216\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.71869616091718\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.7116038904991\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.5967157078907\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.33185585793107\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.83314074478112\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:97.63897444512695\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.32777126189322\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.06854080185295\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:96.7926948454231\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:81.87602479271591\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:81.64939393978565\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:90.42824944704772\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.95200900305063\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:92.46411045789719\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:44.18917265534401\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:75.34513436481356\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:63.23771524317563\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:74.04739634133875\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:72.02105153203011\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:79.52261716686189\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-392.95489234924315\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-256.0098423570394\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-472.06828365325924\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-419.03939065933224\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-379.4004371881485\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-97.55151319503783\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:92.00177272558211\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:96.85907833576202\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:95.00640657655894\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:95.23913861545734\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:94.73005730696022\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:95.61989720687271\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.03808308653534\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.06993068614975\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.04857520870864\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.00376898478717\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.0534011863172\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.98755857581273\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:98.96703060902655\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.03242901228369\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:98.99908114895226\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:98.80932522024959\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:98.86718831434847\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:98.85181816434488\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:76.91399412229657\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:92.6250988015905\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:95.21332309544086\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:91.00072286017239\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:87.29708050191402\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:93.28007056042551\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:62.41826307289302\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:64.36650468632578\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:88.87455895701424\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:70.28519453033805\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:74.16653348468245\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:76.7631385728717\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:97.20783452987672\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:49.02997961044312\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:99.07814922332764\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:95.57497997283936\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:99.01534767150879\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:98.93684883117676\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.72264441363512\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.06822971105575\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06122000217438\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.05165416598321\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:96.54883953332902\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.03789203166961\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.08566811047494\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06563348900526\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.08450960107147\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.05656566414982\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06982921058079\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.0378027273342\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.05594482049345\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.04470348190516\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.05667109740898\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06831445246935\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06860433854162\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06753090582788\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:97.24705831371247\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.29429388511926\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:96.73101194277406\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:97.54309117868543\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.67956117540598\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.74505458846689\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:81.58853717371821\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:60.15077894106508\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:68.02729412261397\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:79.92217467427254\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:81.22045527007431\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:80.00019128676503\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-140079.75967943668\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-58777.251433897014\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-251988.87955026625\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-118101.20354623793\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-128584.17289862632\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-65874.31436040401\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1337.6760176971554\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1445.4528268888594\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-115.1420623496175\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1290.0718597978355\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-369.49756229221816\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1980.0624902039765\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:80.59448459744453\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.21727147456259\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:76.26889660209417\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:71.36311828158796\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:74.43561316728592\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:81.33630273193121\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:69.7676323696971\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:75.16982950866222\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:49.81809974387288\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:72.40285614393652\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:80.10243407823145\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:75.09847396649421\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:58.59132060855627\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:62.95546225290746\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:57.96958302706481\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:64.06391618400814\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:83.0025774460286\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:81.21699187371414\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:66.50666427649557\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:80.16037627029\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:64.48587566167117\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:74.79546468891203\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:85.54579688087107\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:61.26446564346553\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-33632.96801891327\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-61005.942295265195\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-34699.45095310211\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-91418.43745417595\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-99834.09771835804\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-84208.42228859663\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-265.944793304801\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-698.409982830286\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-392.66781294941904\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-316.24849904775624\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-304.83034644126894\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-619.9887766182422\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:91.81291634067892\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:93.0908212822862\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:95.37252992000431\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:93.20171658024192\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:94.59288024445995\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:93.25610784413293\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.06089960485696\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:93.57281926907599\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:89.57789261415601\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:92.05428957641124\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:94.04623792618513\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:87.76884172037244\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:72.10004014372826\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:78.7285628028214\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:69.91216896055266\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:78.74901808630675\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:87.51182727776468\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:59.05769529640674\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:78.76039409991353\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:73.18032242105838\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:67.02469747886062\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:79.12789562195539\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:60.979839843511584\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:69.31087568700313\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-16698.771616840364\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-8573.49536962509\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-7146.049010658264\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-19195.698508358\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-7587.816484165192\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-6673.291841697693\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-296.2843529999256\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-114.52668210864067\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-8.382711076736449\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-229.39703142642975\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-239.07040765881538\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-38.788098686933516\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:95.50746794026345\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:95.98892771936953\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:97.77845132499934\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:97.46809824602678\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:97.38610642552375\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:95.82931560720317\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:93.98538027200848\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.07057179175318\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.76715750135482\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.0158939048648\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.9529898468405\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:93.39269215427339\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:73.75462669804692\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:79.77901248550042\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.89837850928306\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:86.39577285610139\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:69.18618503212929\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:76.14033834934236\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:56.56812823414803\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:58.46336318179966\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:62.757559957355255\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:56.01112721040845\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:80.65632835086434\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:79.1806711657904\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-3859.9148876190184\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-16715.374527668955\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6850.353776597977\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2134.031739091873\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-5360.660544919968\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-4051.44054107666\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:19.014668270945545\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:55.65119740962983\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:49.53660869002342\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:61.164187246561056\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:59.632963019609456\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:10.990256804227826\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.45838614944368\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:97.98936824512202\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.4300523911137\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.73690855214372\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.58383251484484\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.44942108206452\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:97.85308830626309\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.63346784040333\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:96.87412515170872\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.42756628207863\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.50397728458047\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.72250078245997\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.45291509963573\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:91.79052435895429\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:90.97980534406379\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:88.66088515203447\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:92.90505084246396\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:87.61521500051022\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:73.76390127632767\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:82.33337441971526\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:60.04078263305128\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:64.74982229173183\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:82.40087512880564\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:63.48893338963389\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-79.14490737915038\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-37.84534021019936\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-325.2956539154053\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-234.86147763133047\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-356.47686977386473\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-287.26760049164295\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:95.0576863706112\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:97.95101970732212\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:94.4366746544838\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:96.88266559392214\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:97.15146396756172\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:96.33425779342652\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.03694860944525\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.0409913579002\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:97.79887842946918\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.02648839331232\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.10027678571642\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.03196335732936\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.0730782788247\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.0141536789015\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:98.86190079599619\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:98.91321968815755\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.05913062293547\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.07144595608115\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:95.56231435355731\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.4844823568128\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.0418450921774\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:96.60186544060707\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.83768029659987\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:90.06633168421686\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:76.71384085081517\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:65.45823403149844\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:72.24152134098112\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:83.8976801507175\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.988361869752396\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:71.83378206491471\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:73.44455027580261\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:97.27784752845764\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:96.76150453686714\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:99.04824199676514\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:97.11999015808107\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:99.06905879974364\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.19129123687745\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.07111353874207\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06719164848327\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.06704909801483\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.06676177978515\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:98.894797977712\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06716251857578\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06929275467992\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.01802445910872\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06912788474\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:98.8579958582297\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.06820951085538\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06856313801836\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06765468344092\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06261298470199\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:98.98275207951664\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.07041303999722\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06751885748454\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.11074001025408\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.0599334552884\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.07604330405593\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.06169477775693\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.22443673908711\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.82887216322123\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:86.25678865779192\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:66.66597439609467\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:73.61174444183706\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:79.363835054636\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:83.03834184370935\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:72.52025844790042\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-65025.28884484768\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-120773.39844641686\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-61113.449500036244\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-270166.0649749756\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-139241.6362612009\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-55509.9462751627\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-534.2878422170878\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1332.807528820634\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-313.5142828911543\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-609.7095960229635\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1421.7444460615516\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-934.3487707734107\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:71.4785593047738\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:76.44250705651939\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:71.71380865056999\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:85.89274040237069\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:73.15490323696285\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:86.80206118552015\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:94.03379654800518\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:77.11707011908292\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:77.57491482011973\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:73.34610387049617\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:56.895307653211056\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:79.04044647375122\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:65.04824443999678\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:61.82412048391998\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:60.59844241887331\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:59.89266900345683\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:80.36634194701911\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:67.21106166094542\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:87.66800148366019\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:64.73606141880155\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:69.54088696278632\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:81.17000751355663\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:82.14753219597041\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:64.2895327180624\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-96670.48613693714\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-78974.14907143115\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-83630.06477961541\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-78894.9452562809\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-106854.27990336418\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-36973.528507232666\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-330.02411263287064\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-604.6796459585428\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-103.9379197835922\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-332.82141289710995\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-316.017725622654\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-262.9346981525421\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:92.50626065470277\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:90.34504322232678\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:93.96503950962797\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:89.85757746649907\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.52881711847148\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:91.46880404707044\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:92.78126607192681\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:94.67162295514717\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:91.07398065179586\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:94.38682024050505\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.82706378661096\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:93.22465594746173\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:70.41899594143032\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:58.52719776555896\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:72.11282327845693\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:68.52633500955999\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:82.59580118596787\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:66.00473186150194\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:77.9064047433436\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:65.08869636142627\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:59.36151336580515\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:70.85186174996197\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:73.94389193672687\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:84.92801259607077\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-18805.839343452455\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-20079.213998556137\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-25488.110106277465\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-27643.379810523988\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-2293.3747043132785\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-27287.220193290712\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-610.3551025271415\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-0.15424230098723957\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-235.76111479997635\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-160.02063366472723\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-102.37541899383066\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-281.8599209070206\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:96.34704332072288\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:95.99265132257715\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:97.47507439032196\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:94.55982539076359\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.15865801181644\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.24289701441303\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.19997062431649\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:96.76030728239566\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.37373124798759\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.41906084790826\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.10697186179459\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:95.05701303817332\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:71.84441633820533\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:80.8594189085532\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:82.37031111828983\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.608046772330994\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:85.05480738915503\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:65.32408230230212\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:82.43922452107071\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:78.12276617828758\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:65.25695304777473\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:63.50397604443132\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:63.983123566210274\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:69.57419758762698\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2151.635137963295\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-6516.541965484619\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-20677.904059791563\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-7994.930036044121\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-10069.204561662675\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2603.966005474329\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:36.51172600463033\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-11.546277117729197\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:38.186420558392996\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-38.551782169938086\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:48.51965490579605\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:73.11139916181564\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.57060387921518\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:97.7140188338235\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.02721766401082\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:97.4229858011473\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.79475988545455\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.0042512911372\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.57495548650623\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:97.51841374002397\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.7189662287943\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.78849469274283\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:97.71994111817331\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.4145121127367\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:84.44913191273808\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:93.90744330585002\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:83.2784595347941\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:85.76572196409107\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.06040476998314\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:83.40125920921564\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:62.18560328856111\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:61.969270236045126\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:75.25445751361549\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:71.68489317819477\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:89.94323271624745\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:60.8238894123584\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-220.60214347839357\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-280.619210934639\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-124.44598293304443\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-371.7680811882019\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-299.8603214263916\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-449.3661811709404\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:90.79011731147766\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:96.6035468518734\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:50.314564323425294\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:90.92183241792955\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:93.49565488398075\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:96.70964612364769\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.07726127300411\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.98848319044336\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:98.99662100195418\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:97.6310415921267\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.0608566854149\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.05269144796766\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:98.95059857293963\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.0131325095892\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:98.49502561865374\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:98.72223787531257\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:98.96120051038451\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.01582358777523\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:96.98659712653607\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.41646554768086\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:90.68307228796183\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.67287528011947\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:97.00650221854448\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:89.340406447649\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:85.14616365311667\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:88.6972150172107\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:68.44827373698354\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:86.25623399373143\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:71.58581707179546\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:64.12469660006464\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:99.10016746520996\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:96.78765602111817\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:35.757526350021365\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:62.88738870620727\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:98.96824295520783\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:99.05760788917542\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.84775398373604\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.06808051466942\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06688053607941\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.06769104003907\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.06774301528931\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.0675916671753\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06768232639878\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.0703515808913\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06681641181932\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.12811158522963\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.0416383116506\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.06514464244246\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06823625285178\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.07017076537014\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06893624775111\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.05020540654658\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06150144711137\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06481154197827\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.5318586654961\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.08064208365977\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.75944004612974\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:97.66407599411905\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.05180457606912\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.38901650644839\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:76.79131685830653\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:76.52098278999328\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:80.40010687783361\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:70.59834759533405\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:70.51182445399463\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.08762172763237\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-185937.55478267669\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-127158.92094402314\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-181361.70642089844\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-318357.681990242\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-174262.61116137504\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-52786.25409476757\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-246.45214448869228\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1608.7965626791122\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-290.64376184940335\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-338.9727691918612\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-639.9967716649174\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1513.8934867560863\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:46.99515195209533\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:38.91996376849711\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:55.30109923891724\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:44.28400587849319\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:52.017505776789044\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:46.22575216144323\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:90.5449090906419\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:65.08515214249492\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:64.74156155250967\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:86.9941459373571\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:80.22089412733912\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:89.58172171078623\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:83.02494170293213\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:60.519496869668366\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:57.533231059554964\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:73.08631756976247\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:65.41664182711393\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:79.30685494169593\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:70.47886100690812\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:69.80997226163745\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:77.17462865989656\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:70.12855749540032\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:73.47895529475063\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:76.91718510854989\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-147145.93087263108\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-155214.09519929887\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-152571.4613113284\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-231813.41747641563\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-195946.39679079055\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-154164.34709410666\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1507.562021134794\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1229.480887246132\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1073.973965678364\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2121.1637140370904\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1163.2274107098578\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1090.7991752386095\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:92.07228550845757\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:87.92095728293062\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:90.18417910705321\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:90.18417790271342\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:88.11558413365856\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:88.8565477868775\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:94.60749685019255\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.43546924535185\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.10731878653169\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:93.34244931731372\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:91.958719984442\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:94.79385786503553\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:74.39569979943334\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:80.66467284597456\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:79.23860638877377\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:77.49787415172904\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:88.2600431367755\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:87.72588052228093\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:74.79551172740757\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.99768573828041\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:71.37246448760853\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:75.98307746257633\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:83.43539518900216\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:81.99637379031628\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-18498.74403810501\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-58404.318968200685\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-128041.52997317315\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-49116.024515199664\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-6509.66131439209\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-45083.185832786556\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-582.8093170702457\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-729.1830480337144\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-390.3861842393875\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-230.17634948790072\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-11.383998674154272\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1072.0310345172882\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:95.49753961339593\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:91.81455857674591\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:96.39573969300837\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:95.63337177187205\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:95.18010377066676\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:94.49528758740053\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.0555648567155\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.66622427590191\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.5306537732482\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:95.67735095229\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.67120043486356\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.28852380141616\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:81.45688797831535\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:87.27542179804296\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:79.41835974100977\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:89.39032266736031\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:84.16791518814861\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:85.15837985761463\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:76.99921926669776\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:78.02682343609631\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:65.58179003985133\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:74.21412609051913\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:87.0893428158015\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:80.20798183083534\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-9001.648742198944\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5439.7352362632755\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-13918.19910826683\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-10984.692868232727\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-6178.868435573579\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-44518.77938840389\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:35.44957474470139\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-24.56419644355774\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-78.33833905979989\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-49.24780930876731\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-17.3869246095419\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-26.917767120152703\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.34034553077072\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.10925709069707\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.51229805778712\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.56423917841167\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.2998900725972\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.54538347972557\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.80454876609147\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.80887305811048\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.0331812735647\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.66207895260304\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.43411648357288\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.28928895397112\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:94.49322297237813\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:91.34788458757103\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:88.28642186708748\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.78547094836831\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:97.78625525161624\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:93.42987871393561\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:73.81174662820995\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:77.88715143762529\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:72.49488029498607\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:73.78259213576092\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:75.59546847697347\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:82.35922253681348\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-766.4158015251159\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-4797.408043313026\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-251.03604378700254\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-637.778148651123\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-21513.412542963026\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-30.122329235076894\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:93.37760223150254\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:93.05557526350022\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:93.86950993537903\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:51.25292813777924\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:94.29092190265655\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:94.16145272105932\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:96.60330494754017\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.01509297350421\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.09310988597572\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.02202261947095\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.0748822633177\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.04929941976442\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.0299077179283\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.0593422677368\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.05133411586284\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.06436595395208\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:98.882746681571\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.03186266515404\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.84021318424493\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.8781231291592\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:97.00971572361887\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:97.19166914448142\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:95.55897881425916\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:97.07866161186249\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:84.07499324483797\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:79.71320539470761\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:80.09817279987037\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:82.37401649057865\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:81.91993456892669\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:85.73463581539691\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:98.89947319030762\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-2.153785204887382\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:98.84358806610108\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:96.20433006286622\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:98.94376792907715\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:99.0708683013916\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.96502412557602\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.06707462072373\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06628633737564\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.05788050889969\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:98.81604200601578\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:98.82950323820114\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.08701891668606\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06974728778005\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06723594665527\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06799600366503\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06752030551434\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.06775666787289\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06765427831562\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.067510189116\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06750847715885\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06761033385992\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06741097457707\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06752028763293\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.06990121765993\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.75320606380701\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.06752472147346\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.32368328049779\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.93470936146332\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.92099466389045\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:86.65547880940139\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:90.72213286943733\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:69.76191343069075\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:85.97421236298979\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:68.10039977151901\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:79.26061491556466\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-306536.6882383346\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-153073.6792906761\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-286004.8041224957\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-371300.21789298055\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-113958.42771389484\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-243618.46793231968\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2155.9403231978413\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-226.83052748441693\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2557.001705366373\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-457.7932677537203\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-773.7441029265524\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-409.61358441114425\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:66.66754911746831\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:26.146378745883702\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:70.8556746984832\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:64.05494075901807\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:43.19045075923205\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:62.57127379747107\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:87.74544540736824\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:81.13231948651374\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:80.57503509679809\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:79.02309322841465\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:85.35336794918403\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:64.75046547651291\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:76.48676604479552\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:71.70497087463737\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:62.82594865635037\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:78.75173907214776\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:86.13420880082995\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:69.54343880899249\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:81.41045698150992\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:71.45985160460695\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:65.0215138360858\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:77.49255805029533\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:82.16065302714706\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:61.71307562254369\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-261175.45811429023\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-194679.38089270593\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-233453.4267509222\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-88276.76236114501\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-207616.45477695466\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-12032.656968736648\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1244.7950278788805\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1165.5200552910567\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1331.8369405820965\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1026.9013652205467\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-2068.3689335823055\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-605.4930438756943\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:90.86547730369493\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:90.3716851002071\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:84.27673291219399\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:92.6594612604007\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:87.70716881882399\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:85.08751519471407\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:94.30237321499735\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.95810411329148\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:91.20216554775834\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:92.78172992318868\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.07235061582178\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:91.63826678283513\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:79.87196085667237\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:78.47138152867555\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:72.26620608530938\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:72.43581435233355\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:74.02802411238663\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:76.32682142145933\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:71.4163648782298\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:75.45989439524709\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:70.73533475920559\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:74.39231612533331\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:72.97931650374085\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:73.14578378945589\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-48359.00928907394\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-5423.1761927604675\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-41948.30788669586\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-32786.88527002335\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-10047.520113945007\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-28947.708286476136\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-413.7454452753067\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-556.8238633066417\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-390.6088841855526\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-164.46396985650065\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:21.28529369831085\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-222.27446390986444\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:93.97015427481384\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:93.68993749609217\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.77990786805749\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:92.58923807926476\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.85223870500921\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:95.85305274948477\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.3025748589076\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:96.02394825606608\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.84874740187078\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.07553349118679\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:98.42508020922541\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.84551883321255\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:90.61128294914961\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:86.07222228832543\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:88.20476578958333\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:88.2426775176078\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:87.7274931691587\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:92.82402473017574\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:81.8015424212441\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:83.28651365935802\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:87.352712854743\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:79.09576202221214\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:87.37557729631662\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:73.56860850788654\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-13305.642202425002\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-42295.01562464237\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-40589.52681894302\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-13029.775549793243\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-5745.059956359863\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-15421.166407108307\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-82.05647694170474\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:36.33045472502708\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-17.261001539230335\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-46.72356406450271\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-92.43405278921126\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:32.77892073094845\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.3393346216879\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.07901880796999\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.496305589471\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.53575372882187\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.03774581205799\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.67842944674194\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.3331853408832\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.5480406396091\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.67704903250561\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.45744033381342\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.55521641485393\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.21825404576957\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:96.22324343957007\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:92.30397389605642\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:97.71945516262204\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:95.29310477674008\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.48890600241721\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:96.65084147267044\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:78.8555181177333\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:80.3399179149419\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:85.42572481483222\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.40023608282208\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:60.140490872785456\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:74.12761575197801\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:15.661641407012938\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-708.6333872795105\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-607.2714723587036\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1492.0961109161376\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1017.4295097351073\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-240.24155349731444\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:88.9884090781212\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:92.3204820215702\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:93.3387633919716\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:85.31231783032418\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:93.38330705165862\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:91.81167278289794\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.03280165828764\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.04740384235046\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.08704372271896\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.03158908791374\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:98.74870004770347\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:97.8863567315042\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.05300211700377\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.06880833432078\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:98.98715684078634\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.06121516153217\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.0609741769731\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.03699504341931\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:96.24030551807955\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.30236198231577\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:97.76907898038625\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:97.1834439702332\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.0514261258766\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:97.97769412323832\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:80.66416220515966\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:78.47547867894173\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:70.81734555661679\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:76.2291358564049\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:84.26733917091042\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:80.32380922660232\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:98.25246829986573\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:98.85934562683106\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:96.65919332504272\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:97.2874972820282\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:95.96494064331054\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:93.11515176296234\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.90957109928131\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.37160931229592\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06098582744598\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.06603317260743\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:71.7035487383604\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:98.67723066806792\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06773314662277\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.10652056103572\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.0674799606204\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06734819831327\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06749833957292\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:98.82095847791061\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.07065859548747\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06747405799106\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06751117035746\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06752638816833\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.0675175616052\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06749125942588\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.9945448320359\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:97.2327354144305\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.66486440524459\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.95817192345856\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.07663585012779\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.02500572763383\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:84.92211701124907\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:80.14152691215277\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:92.50372183825822\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:85.4649494068697\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:85.23816127292811\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:84.82802352719008\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-116129.6753465414\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-304200.78485884663\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-63350.25572123527\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-346862.4183035135\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-259588.95211458206\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-491578.9661399364\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2413.9316919088365\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1010.0845321059227\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-649.1080048531294\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-229.9458238646388\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-2519.4439104259013\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1484.152860993147\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:41.2774791488424\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:71.98667733808979\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:48.41901495438069\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:57.46145752016455\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:62.64733871333301\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:60.40782590806484\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:81.1024575477466\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:88.30388723146172\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:74.04830184355377\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:71.97108148820699\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:74.73337568677962\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:62.00978784449398\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.27018613256513\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:60.130976122990255\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:78.4852173820138\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:74.76801710724831\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:88.68458520248532\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:85.41098978184164\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:67.94977639056742\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:73.50449247434736\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:81.66452819257974\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:68.47150658424943\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:61.118502031639224\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:63.915532153844836\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-65878.03340015412\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-10981.82534570694\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-208529.25799546242\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-207612.4880004883\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-247531.8444024086\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-13093.071354866026\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1046.0643535509705\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1473.505085092783\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1705.1824291229248\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-573.9610150657594\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-885.3654487818479\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1734.3725239396097\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:83.70556013025343\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:84.03567710518837\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:90.04468252565712\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:87.26944843698293\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:89.96017824080774\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:89.49366463217885\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:93.0656869603321\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.57161857052705\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.82094345372171\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:93.01987760160118\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:90.99940452426671\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:92.52661568820476\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:80.74976015817374\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:75.47827421315014\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:75.00641943197697\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:69.69562959522008\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:88.68244912410155\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:81.76049464279785\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:77.91058546081186\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:75.87497353181243\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:71.1070282170549\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:76.6739505853504\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:74.30432980358601\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:76.77814587857574\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-39339.70982189178\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-29831.204852294923\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-48573.98244843483\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-20271.688627147672\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-4155.602507686615\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-11212.495222330093\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-834.377467803657\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-82.16582601666451\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-567.7951308608054\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-192.85423886477946\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1229.1030338853598\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-327.66480503678326\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:94.31912429053337\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:95.10202937051653\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.67738850796596\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:91.62758652251213\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:91.07933732233941\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.05373967345804\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.25690465122462\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:96.21751920748503\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.6296790646389\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.22141205673105\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.83535530790687\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.19035216160118\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:93.14212153004482\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:94.94295799210668\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:90.55667198076844\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:88.54955808408558\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:85.60050090663135\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:90.1268459726125\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:77.86831558458506\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:82.95413866150193\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:73.53748869411648\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:70.32667619846762\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:60.3601911937818\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:79.72229225002229\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-15701.419957828522\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-7820.30322599411\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-7104.210842037201\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-5172.254278373718\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-43714.48046922684\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-11846.649342012406\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-8.512211191654195\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:10.81222953796387\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-27.81786540746689\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-298.36289344727993\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-22.416175270080572\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-14.970895406603812\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:97.9832620373927\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:97.88706028219313\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.82075383132324\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.53890214934945\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.28747623628006\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.9228326452896\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.98694672128185\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.89128303956241\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:97.951900325343\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.4073883600533\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.38394122018363\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.68874556198716\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:94.79324248526245\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.1481692539528\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:92.35440053548663\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.34548078700901\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:90.54758424777538\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:71.80927967652678\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:86.54473054930567\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:66.70741649791599\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:82.24991272836924\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:72.02532941401006\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:76.57690592594444\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:79.22869987878948\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-4805.739893770218\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-241.7396209716797\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-5395.937947893142\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-11198.458048892022\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1670.547984981537\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-502.924695110321\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:93.09395372867584\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:91.2896696448326\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:89.81959598064422\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:98.36796907782555\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:94.79195313751697\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:87.51703063249589\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.03207252984868\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.10463906226215\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:98.98665806353092\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.01272790953517\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:94.3869086066261\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.04353636801243\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.04449431747197\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:98.8289625287056\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.05941310338676\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.0778321175836\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.04078784845768\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:98.99363225270062\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.01197129879147\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.12205342533998\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:96.28624663315713\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:97.85051883533598\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:97.73918350972235\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.84072681963444\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:75.950053109508\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:72.79477858971805\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:85.58497150316835\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:74.25668657384813\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:69.01530473642052\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:77.78441919665784\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:96.89729986190795\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:91.6939154624939\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:92.22716989517212\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:94.61938047409058\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:97.37372303009033\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:90.32713871002197\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.98551671802997\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:95.38654451370239\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:79.47102873325348\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:97.90859167948365\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:98.56678009331226\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.07016506195069\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06873909141868\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.04516491517424\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:98.94248878341169\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06749780229292\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.067775526084\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.07367933196947\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06758675500751\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06752545535565\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06751931905747\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06741756610572\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06745899878442\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06624201014638\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.04924800246954\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.7256475542672\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.0992658674717\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.46634315475822\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.80290609300137\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.06623181812465\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:81.50359135288745\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:90.07093648649752\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:82.60156787633896\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:91.75550451241433\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:86.63542723692954\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:96.23414862677456\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-359208.88314399717\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-253655.0634867191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-63803.08342905044\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-59400.98965654373\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-65105.94912536144\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-185224.49281070233\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-656.3300111472607\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1681.944426447153\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1005.9613159999252\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-681.2429656952619\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1880.5520944342018\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-334.83177428245546\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:57.30271625518799\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:29.945957161113622\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:85.5454681721516\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:54.78230786547065\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:24.060824009682978\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:45.333824867196384\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:77.39029862694441\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:86.56275667296723\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:63.5111466627568\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:78.99537427388131\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:84.1605403939262\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:76.2290351819247\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:71.59515570998192\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:75.59953372068703\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:74.70186115093529\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:68.10011232979596\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:83.59089820012451\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:69.07708410252818\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:69.83600400201976\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:70.04835803033784\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:84.38963609747589\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:74.21587674776092\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:65.84410752616823\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:61.08624712750316\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-221706.31966819766\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-144297.55996456146\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-164965.3308107853\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-204715.28823814393\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-138534.70075523853\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-155665.94704937935\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1326.6548845350742\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-977.5630849182606\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-940.5348900698126\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1103.1961220130324\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1255.7160460829734\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2191.1505510330203\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:82.74275309573859\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:85.29469241388142\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:89.38351841717959\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:86.25579492021352\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:89.24701781533658\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:86.14585055797362\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:91.06663618627935\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:92.2587487220764\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:96.93034899961204\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:94.02719711158424\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.52827434763313\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:90.50673084110021\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:85.23080174773932\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:92.20770025271922\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:82.58516163602472\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:80.7955810535699\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:76.0130871705711\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:83.57751378193498\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:87.1107164978981\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:73.00509815104306\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:78.47650227360428\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:79.5235632866621\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:65.46277362555266\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:84.24812081716955\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-59361.72325191498\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-44324.314773654936\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-8370.385717105866\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-128873.09688858986\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-29175.927888107297\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-10891.01502304077\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-332.3160120725632\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-491.09500784873956\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-673.4951658412814\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-427.2165569037199\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-245.52381298542022\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-312.17623021602634\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:95.00518078971653\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:92.76333807101473\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:94.92801789417862\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:94.80920835607685\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.27315007071012\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:94.16694686859846\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.9050100684166\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.4964178211987\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:95.47760139666498\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.3787112377584\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.9417837612331\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:94.96893331557513\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:90.0960148618964\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:88.34167926972731\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:89.38859650501982\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:84.06345757059754\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:89.52803883068263\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:86.69486499875784\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:64.74867036826907\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:76.87701178174467\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:76.5979112342\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:84.75939503377303\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:67.7969329752028\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:64.89164406694472\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-3385.2842920303347\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-8949.722722339631\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4910.568852424622\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-4191.168178272247\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-14788.658634662628\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-13428.665923738477\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-49.82602125406266\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:39.90879866480827\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-77.26212116479874\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-85.76148276925086\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:11.210151410102842\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-143.9143390595913\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.67948908396065\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:97.66038068206981\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.50310861244797\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.24518339382485\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.062719376944\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.19124621953816\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.47942930199206\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.54092447422444\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.98262971267104\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.31656909477897\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.49213984720409\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.33979902714492\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:95.19755226343405\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:88.24071272313596\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:96.14355775564908\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.44980036946946\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:95.77639373247511\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.22725416719913\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:81.60580110945739\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:88.6683889662847\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:75.12220139526762\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:59.08669285476208\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:77.03414534823969\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:72.5806830804795\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-768.736367726326\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-584.2388723373414\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-689.0819957733155\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-721.3723885774613\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-645.9488321304322\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-340.6939498901367\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:78.55417037010193\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:90.76774717569351\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:96.88876869678498\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:94.5547149181366\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:95.64557296484709\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:91.08495140075684\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:98.76934579908848\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.0817059058696\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.07804252945353\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.0830195121467\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.08357546385378\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:95.4850617866963\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.0367989375256\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.01251965761185\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.08035295326263\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.01225432492792\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.07718513458967\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.0788512852043\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.85543916784228\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:96.56736663412303\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:95.59540295302867\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:97.71274729091675\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:97.22099378816783\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.07559798881411\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:80.62917997296898\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:76.47979128099978\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:68.84940148964525\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:86.644090451207\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:66.01414056867361\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:69.13777415426448\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:97.49705734252929\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:90.57196707725524\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:78.917227268219\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:35.43360500335694\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:96.87932214736938\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:97.56585426330567\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.94660449028015\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.04817720651626\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.07107722759247\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:98.438482645154\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:56.7770851328969\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:98.92246262729168\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06824058424681\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06842967210105\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06752102710307\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.0692726565525\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06752222329378\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.06735267052427\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.0682666644454\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06752313151955\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06848312281072\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.0658285357058\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06751350238919\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06755167748778\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:97.0368328936398\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.68738580718637\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.13173104161396\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.77439792975782\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.50945165324956\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.97267152518035\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:74.37084381096065\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:89.07238476611674\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:92.95719932317735\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:87.13947472041473\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:90.55909528024495\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:86.02664783596992\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-196649.7034652233\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-51537.5498265028\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-240417.42091674806\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-442827.31531414983\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-304118.6549071789\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-273111.45113382343\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-3037.867661464214\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2182.1963598608972\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2555.451000159979\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-4136.591906967758\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1398.5792581647636\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1941.912161308527\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:21.840775984153147\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:19.90658965464681\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:29.813755045086143\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:48.735792862623924\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:32.34915816597641\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:52.03062619883567\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:80.16314249057322\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:73.7976164684631\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:89.51373127251864\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:82.86492378897965\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:90.90954440543429\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:75.98413458345458\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:74.23044076208025\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:57.99000907503069\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:72.19653460178525\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:74.88035290520638\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:77.91238362137229\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:75.37863251231612\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:75.92133148480207\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:76.769125378225\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:65.30944217629731\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:90.18907370036467\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:73.73068522848189\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:67.71382871633395\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-238516.1221738815\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-54218.9446562767\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-75100.90620241164\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-207872.31575396063\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-297318.2579232693\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-239537.88114695548\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2711.51867057085\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1564.007217204571\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-517.9508041888475\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-621.6363914072514\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-672.6707726821304\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1682.9292440265415\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:79.42698936015368\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:72.71595675237477\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:71.19210306014865\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:79.0891329165548\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:81.84944740943611\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:69.9823691593483\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:90.90690949950367\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:92.87300998251885\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.26122524654492\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:96.22239351663738\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:94.18138104975223\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:93.70510267112404\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:81.18094019554556\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:82.14196036942303\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:84.6814923800528\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:81.7025066088885\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:67.92496538683773\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:75.09786107833497\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:67.75111980754882\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:74.41682239444927\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:82.30788469109685\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:78.73257266394795\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:71.10517615377903\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:80.62957760132849\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-49401.99224576951\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-25718.220964241027\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-16485.43438549042\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-54533.124279499054\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-67160.51912488938\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-158687.86811562776\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-183.18177944421768\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1193.114184063673\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-992.6200086832047\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1302.6296966791153\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2139.9009819895027\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-833.9405312478542\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:88.93770138584077\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:89.3274937234819\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:89.29038752065972\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:93.40134862698615\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:92.85429264865816\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:87.66866084206849\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.21469579804689\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:93.8489792637527\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.4753830783069\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:95.34017986003309\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.49168909427243\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:95.3767717897892\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:94.99720358941704\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:88.88091396391393\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:90.3300607226789\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:92.98494601249695\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:92.99616043157876\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:77.04950066749007\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:75.24463428631425\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:90.16770998481661\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:91.61147235287353\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:71.75753633640707\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:75.55284428005106\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:81.17105416078121\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-56297.023150396344\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-13792.022030067443\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-12376.916492843628\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-14921.593330192565\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-39298.00495653153\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-55493.94455480575\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-106.19949660301207\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-74.83053480088711\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-174.3079679608345\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-484.00947568118573\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-204.65246785879137\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-366.7419157981873\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:97.13305334709584\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.26847012769431\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.88625132422895\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:97.07527387777809\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.4433666984085\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.31523001901805\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.13480581045151\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.5699825834483\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.9515155909583\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.80422453731298\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.43891106843948\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.67544752955438\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:97.38223782032728\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:96.86954387202859\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.6095189537853\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:96.38184425821528\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:96.70662959516049\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.19468839820475\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:85.76736184563487\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:75.17251198459417\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:82.5186579838395\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:79.67655737437308\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:85.5341383535415\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:86.19005320873111\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-448.772248840332\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1693.491441631317\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1812.8241041183471\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-756.718991279602\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1417.8881256103516\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1231.8772426605226\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:47.21161103844642\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:65.72997963428497\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.34790439605713\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:82.22373561561108\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:78.32106580734252\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:91.50617091059685\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.00619985572993\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.04674221128225\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.06872169636189\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.02502591209486\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.03317617308348\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.06234808582812\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.05998126193882\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.07971652597189\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.06956560506951\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.02610070351511\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.05976313762366\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.03381874961778\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.92734193708748\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.41838727011346\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.81919441614299\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.06698756329715\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.50375651791691\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.89331439808011\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:90.39012787612155\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:77.25527898226865\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:77.89772387193517\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:75.92355112042279\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:88.17377919647843\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:78.24762678518891\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:98.75177822113037\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:98.5499921798706\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:96.46770877838135\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:98.14373168945313\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:98.63738212585449\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:98.50286293029785\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:99.06272234916686\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:98.71646542549132\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:98.9122152686119\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.06943545341493\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:98.68379008769989\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.06695100069047\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:98.79622994214297\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06771280355751\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06755280280485\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.0675355874002\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06761626154184\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:97.83613100852817\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06751471217721\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06751019209624\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06752128787339\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06751385480166\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06752988044173\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06749764960259\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.46752782426775\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.06749401912093\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.93873797021806\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.0152344174683\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.96413099896164\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.92017409056425\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:89.5723894899711\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:86.01150222867727\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:90.86449631247669\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:90.04903136026114\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:91.26158541850747\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.82544691590591\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-280693.55555729865\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-278924.22430729866\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-527053.9349846363\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-116811.025329113\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-236715.8363348961\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-180698.03722081185\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1801.3140401005746\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1319.3199129223824\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2869.5731367379426\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2781.839090821147\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-2444.293791681528\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-4269.683253625036\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:14.12015558741987\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:30.176857165247206\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:29.407599588483567\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:1.5146550216712074\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:30.766592582315212\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:51.525303387455644\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:84.07588767725974\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:78.01522968467324\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:91.01504233013839\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:88.1035824721679\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:80.08227160489186\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:82.59546146839857\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:69.7515195224434\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:72.64123931545764\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:79.89378183409572\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:71.8452218970284\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:77.80584034528584\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:75.56771956086159\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:72.63384290784597\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:76.00278324689715\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:69.02813981892541\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:80.80606403988786\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:65.16979300873354\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:63.057263816148044\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-436618.04038064484\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-201157.2465303898\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-404841.59952440264\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-446412.69595413207\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-64221.06588563919\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-492645.8762896537\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1367.9516358196736\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-804.1334565728903\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2478.2104574412106\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-3764.114507304132\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-2969.3758185505867\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3897.4955048441884\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.69676593765617\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:74.74319171588868\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:80.31341857500374\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:78.75770063269883\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:78.01086108395829\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:68.0005907798186\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:91.79126191008837\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:93.99286318444648\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:96.95678090779111\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:92.23332750424743\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:92.79632967789657\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:94.5374931799248\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:84.11586821302772\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:69.83347188830376\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:86.88177719842642\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:87.93602318237535\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:88.79674973040818\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:85.46412150301039\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:70.75642940756516\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:70.34838715419174\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:82.72384617794305\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:72.0426427975297\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.96282828077674\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:72.45749740451575\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-113668.48815212249\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-117193.36871557236\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-68820.42563343048\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-12600.359174728394\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-58264.33186063766\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-56911.368575382236\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1153.2069466412067\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2452.966394352913\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-502.5194653481245\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-571.1371671974658\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1561.6056635066866\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-367.0018023014069\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:93.4275103604421\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:91.39059131629766\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:90.02490580957382\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:87.93657405748964\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:92.75026646740734\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:90.43946721935644\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.88237852677703\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.0246734596789\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.12606455534697\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.58791525624693\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.37452686335891\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.37012840756215\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:94.51168819367885\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:89.13221817985178\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:91.52310400921851\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:93.97554893493653\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:96.14362410828471\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:92.09678504746407\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:84.29240419901907\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:70.83666106760502\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:71.92496601194142\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:88.4864753745962\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:79.73091974947602\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:76.55309851979837\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-32067.943642997743\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-28788.114192008972\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-76720.43065457344\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-14605.970442199708\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-67698.68186769486\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-44368.83913812637\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-187.21392952203752\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-333.24275267124176\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-113.87958466038106\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-18.687282967567455\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-363.37150886058805\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-33.20835293531419\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:97.71018497347832\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:97.41925418965984\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.03371330555528\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.10454429835082\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.36303071724251\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:96.93583508711309\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.66653609433779\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.79600470662116\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.88884168155492\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.72135202214122\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.48377361111343\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.59576504603028\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:97.69716951809824\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.8465584140271\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:97.91665259227157\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.08847219822928\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:96.38543769605458\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.10827881274746\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:93.97655946537853\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:89.13791462182998\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:75.23314106091857\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:75.69271856043488\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:71.12889566831291\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:68.59062517136336\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1152.4305606842042\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-10754.033777737619\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2361.1498161315917\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2017.2815473556518\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1862.886804199219\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1691.3042964935305\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:82.78135306239129\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:74.7050006866455\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:85.44560743570328\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:76.91623961925507\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:80.95664109326898\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:86.13053756952286\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.04045182503761\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.07860830463468\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.04418934583664\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:98.99226899594068\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:98.35112221762537\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.12254736684262\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.09464736152441\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.03521019537001\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.06391451042145\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.11520355306565\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.05632636416703\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.05683594012517\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:96.32149246782065\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.4344106500037\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.07962779253721\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.32070258194581\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:97.38135861046612\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.83596238568425\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:78.47282123565674\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:90.7138644542545\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:81.26760980915279\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:83.8215164111927\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:76.23334292434156\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:76.0731539780274\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-51.74770135879516\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:98.98261432647705\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:98.7059398651123\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:87.85668573379517\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-118592.49559946061\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:4.906630516052246\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:96.32676734030247\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:98.84109137058257\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06636106967926\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:98.56833238601685\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.0665680885315\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-651.772152775526\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06760308183729\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06750105526298\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06751465210691\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06789218471386\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.0684571519494\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:91.52299061929807\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06752100549639\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06751665081829\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06751648392527\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06750846537761\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06750402003527\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06752265677787\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.05743557903915\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.04368547946216\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.99975969307124\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.8946644970216\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.06603899896145\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.93894609287382\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:91.29915161253884\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:95.41196114942431\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:93.87302167732268\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:94.16696944609284\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:92.83771408684551\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:91.07402288541198\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-476689.24565834994\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-764416.2545336246\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-409148.5342446327\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-205134.63336396217\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-487055.85064172745\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-555177.5274896144\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2300.5612851411106\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1366.4660096466541\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2008.2645747125148\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1322.7385852068662\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-2755.5108156472447\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1146.7150992631912\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:20.577758543938394\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:12.813583466596901\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:20.978687511011962\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-9.68331372588873\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:6.43934762980789\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:21.040714945085348\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:80.48233364075422\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:80.64498346652836\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:92.73057527951896\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:87.24744508117436\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:79.50517207449302\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:86.75017554787918\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:71.57302491422742\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:69.07063868306578\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:75.14382087141276\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:81.12449048040435\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:74.2805004607886\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:74.45324017480016\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:73.61533219590784\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:65.68634381368756\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:78.17674604803324\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:63.45624253917486\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:80.55645505739376\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:71.69147789105773\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-383958.6145582199\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-295209.2638626337\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-487954.1937058687\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-77314.16930019855\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-76155.60153684617\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-208978.89234933854\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1046.5117372721434\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1481.8261471316218\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1205.6963660329582\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2916.5594235777858\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-978.2030032277108\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-262.3057973474264\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:77.0613121196162\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:74.18152380576358\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:77.42160004954786\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.42350897174327\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:74.15140442065895\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:83.16128643918783\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:93.12326787868514\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.6205827139318\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:95.83325841929764\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:92.86498105768113\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.02663863115012\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.30463207084685\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:83.15541795965983\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:87.89298732765019\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:75.65525062568486\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:82.24283035257831\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:85.44345144825056\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:82.13406690359115\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:82.90227404143661\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:74.58367043733597\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:73.86809780448675\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:79.07390511517879\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:80.55164191313088\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:87.66332712769508\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-87560.41865243911\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-64894.18575325012\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-9041.092006015779\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-28599.9006360054\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-31218.027549934384\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-95759.45643062591\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1018.9935624361037\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1525.8694272994994\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-561.2635651946068\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1272.6960706233979\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1053.2145264983176\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-377.22014433145523\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:88.79717612564563\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:94.32878062389791\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:91.92063848744147\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:88.99531258903444\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:90.07614073231817\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:94.00344760972075\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.9717755489517\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:96.80067627038807\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.98678609281778\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.63185210939264\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.72059110957198\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.14780945256352\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:95.10935885962098\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:96.34473184905946\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:92.84931318257004\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:77.83284546770155\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:85.24595465138555\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:97.262585259974\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:75.30861664824188\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:69.48788290889934\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:78.57693177582696\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:70.88793371021748\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:73.07624852303417\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:76.8929003212601\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-8039.2088792800905\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-28217.046247577666\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-7240.730740070343\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-35067.740721511844\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-32760.754561424255\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-85658.81688354016\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-93.65056202411652\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:8.256429028511047\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-304.30424447059636\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-52.13362788558007\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-286.0144311472773\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-127.72402331829072\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:96.91352383168415\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:96.83160196933895\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.26834481945261\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:97.27066432284191\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.48710669754072\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.75105449254625\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.07604576917365\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.88448486421257\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.5242577018682\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.6401583513245\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.90046425461769\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.6925846066326\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:96.60590953975915\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:97.38405266152694\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:96.83443575743586\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:98.0733095921576\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:98.31653549559415\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:96.58545342031867\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:75.39825039412827\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:81.53146338313817\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:81.72881562202238\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:77.91270359288902\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:81.11102982119192\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:77.61671761404723\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1930.3326825141905\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1309.4504749298096\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-865.4939476013183\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-393.47389106750484\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-5271.428615093231\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-59.71966609954833\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-29.96586919128894\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:87.14881984293461\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:87.38102855682372\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-646.2526763916015\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:86.29959420561791\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:73.11610043048859\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.03345697000623\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.95176963310223\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.10688257403672\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.01572657320649\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.06708895425545\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.0210771211423\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.0796463979408\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.08312292546034\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.06071730069816\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.03943442255259\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.01073325164617\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.04781335983427\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.60414629476145\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.44778645820915\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.69069873020054\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.72137061208487\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:97.85442760679871\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.83235042095184\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:83.34562227306887\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:90.5542061669752\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:81.37815582118928\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:79.31536756008863\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:83.72003974150866\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:77.95252040270717\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-385.9503464221954\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:98.13160285949706\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:98.8316692352295\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:98.67288703918457\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:98.50884571075439\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:89.81687030792236\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.70522853136063\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.06046228408813\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.09440649747849\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-698.8523835897445\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.07013792395591\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.0666690826416\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06746537275612\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06752245984971\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06913176774978\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06760755860596\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06759420922026\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.07102545973612\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06752357520163\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.0675145091489\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06751984003931\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06748527809978\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06771694775671\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06750397384167\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.06102322340011\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.07486372664572\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.9746347675682\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.01983369998634\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.07100421190262\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.04842884615064\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:93.44915648456663\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:82.83693494498729\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:91.41454282142222\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:89.06334395706654\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:95.53180451393128\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:87.4224604960531\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-530159.6551181078\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-367283.94759922026\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-424088.7826129437\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-517029.76254744525\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-309761.7311408043\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-187872.75830349923\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-856.1550009727478\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1624.0823306828738\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1704.3293244063855\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1246.6849972963332\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1611.07030210197\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-4078.819959434867\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:1.9131782480515502\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:8.350158757157622\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-22.467038759589197\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:35.250446044374264\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:41.71575434356928\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:13.931014027446508\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:80.47745771072805\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:78.2554839130491\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:80.8774407895282\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:86.26096518244594\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:86.69651909666136\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:88.17456173934043\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:80.97074231337756\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:70.6907015254721\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:77.87296632360668\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:74.21283130673692\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:64.88726807851344\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:77.22181833088398\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:75.92283820454031\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:76.52639164878056\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:77.4141826722771\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:62.78108983188868\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:85.65011807959526\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:77.93405385399237\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-87600.69433953761\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-325544.18085618014\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-422351.32663602824\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-282084.6128648281\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-65947.55766658783\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-466548.29829850193\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-959.6734416007996\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1648.6161177575589\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1701.5705170094968\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2035.2771239101887\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-2232.9192891836165\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1111.9457166545094\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:75.22783424928785\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:91.37890487825497\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:78.61477015130221\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:79.18928169868886\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:82.01390899196267\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:75.56992892771959\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.54680714420975\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.57468019649386\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:96.7375319209881\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:94.26299765040167\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:92.65512786097825\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.61897117644548\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:88.36113977562636\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:79.9269170049578\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:89.08073602803051\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:86.69117849785835\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:94.48586961477994\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:81.38525901790709\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:64.92674999162556\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:70.89954578876497\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:78.64063290078192\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:80.71469577280804\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:58.452099238894874\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:77.36101653538644\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-203841.3908143997\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-17589.591269016266\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-19821.037781524657\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-156531.51733875275\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-38888.47661561966\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-14713.614826583862\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1558.2485104382038\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2150.845279252529\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-820.1545820355415\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-700.491679728031\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-881.7764467000961\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-822.5696873188019\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:93.79865110516548\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:91.34757618512958\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:92.55657703392207\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:92.46905605401844\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:92.7292302723974\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.94652399979532\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:95.9637297026813\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.65494191441685\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.41635531745851\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:94.73473771354183\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:98.08485809396953\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.49138180520386\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:93.10530899129807\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:94.7273371537216\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.64920240473002\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:91.30272966958583\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:90.52930782735348\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:92.88913802169263\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:81.93894561547785\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:79.30843344852329\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:79.1792960256338\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:85.69500148240476\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:69.69946805909277\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:79.34879679470323\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-39103.87997875214\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-37872.573691082\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2965.6394101142882\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-83275.7493600607\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-21028.324192619322\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-31050.53468208313\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-151.56252230107782\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-455.58167867064475\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-268.574368301034\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-202.7052386760712\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-145.802235352993\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-238.62306181192398\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:95.69199385866523\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:96.93958380213007\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.72651323210448\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:97.91604254506528\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.30803676238283\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.07753809951247\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.85759425219149\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.83744053153787\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.83512054807507\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.2454511128366\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.7559792689979\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.75799484476447\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.97714698445053\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:98.30552809983492\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:96.60821004416793\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:96.00446527451277\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:97.48341992134229\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.18098730240017\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:75.76317192632705\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:73.98872014554217\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:88.61742833219468\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:68.59635993447155\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:87.71824621483684\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:79.62596827298403\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-2106.8823802948\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-3336.7468439102176\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1065.5729049682618\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-32997.220028162\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-831.9646173477173\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1728.9604378700258\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:76.59640076160431\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:91.92510353326797\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:71.95644609034062\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:84.59088000059127\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:79.77045602798462\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-883.7281238794327\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:97.89380913721398\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.03148468416184\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.06210880246945\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.11787535287439\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.04151495229453\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.05620967540891\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.07516873013228\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:98.96298688203096\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:98.99452428668737\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.05495202541351\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.03340154532343\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.04613496549428\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:98.83846193440259\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.32677396838552\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.63030055128038\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:97.97080160435289\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.38558201396373\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.54830485731362\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:92.71433473518118\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:85.83411177454983\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:89.89074658993633\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:86.30174542255699\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:82.36218188628554\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:89.21796679422259\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:98.0818935394287\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:98.52406902313233\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-649.517267036438\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:98.66666927337646\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:97.36621837615967\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:91.46777849197387\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:96.60641315579414\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-287.5293866038322\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.0674470424652\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:98.73415545225144\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.06940076351167\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.06982069015503\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:98.72757076264824\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:97.65383499003947\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06748314511496\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06698729842901\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.0674754280597\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.06753441561014\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06752330400049\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06750720385462\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06751710958778\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06751620769501\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06751751797273\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06750762639567\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.75791999809444\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.02424347829074\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.05595537386834\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.05494401417673\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.62338973183651\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.06950062029064\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:91.45457212217151\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:92.00467221888248\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:94.58039422258734\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:87.35335942078382\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:93.22942418009042\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:91.29075413970277\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-402606.5570164681\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-355467.4824309588\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-225261.8920167446\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-494577.80815210345\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-555454.3091699124\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-252611.41367607116\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-749.6902338773011\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-5022.99004432559\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1595.0603137373926\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-837.4599298804999\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-3718.8242062479253\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2369.085890156031\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-26.106374878436323\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-27.662722308561214\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-19.548170870542524\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-33.47989839874208\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-57.11612236006185\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-5.238054304197437\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:86.38304721061141\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:90.10508415549994\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:85.89843689538539\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:81.2531908074394\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:92.0825202669017\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:77.02638432197273\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:71.08633524961769\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:81.12462260760367\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:65.52786984313279\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:71.21527238804846\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:73.38039994277061\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:75.51937234580983\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:61.97346938569099\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:82.78144890805706\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:68.04289155360311\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:74.36786896809934\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:62.13912906106561\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:59.48499426078051\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-61092.21724672914\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-237325.60636873246\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-143143.8090557575\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-39400.79011951089\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-190723.89886317254\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-66436.57027447224\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-4971.346947634221\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-2974.0003009051084\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2427.826868081093\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-8764.757613396645\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-6922.917849916965\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-4539.192409548164\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:70.15654796976595\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.929399308376\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:57.3670455340296\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:85.22223942540586\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:55.40365132400766\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:65.54802876412869\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:92.38803721889853\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:93.57404929492623\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:95.57859988184646\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.81674918606878\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.2030349612236\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:96.35874484740198\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:92.99113535378129\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:93.27827683109791\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:76.47160469125957\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:88.5880732582882\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:92.93646422047168\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:94.11739882156253\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:75.51353985946625\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:81.27063470305875\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:75.48305792305618\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:78.85244739400224\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:79.55361575195565\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:78.05508483294398\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-202398.11970062257\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-62791.02500948906\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-254272.35638751986\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-405362.4297906876\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-14803.210313796999\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-296271.99540557864\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-5033.7401561189445\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-4806.604857248069\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-3558.187487965822\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-3474.1751205086707\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2332.261527901888\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-4817.704668909311\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:82.78600038588047\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:85.46555668544025\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:80.2548082433641\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:80.58515963926911\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:79.36962774060666\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:71.6101625379175\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.57426216118039\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.0189789365977\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.92921887515112\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.49254062301479\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:94.48555004447698\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.10185953518375\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:94.92606230732054\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:97.40254680849611\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.99089171234519\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:95.0979038327001\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:96.07997878566384\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:95.71011631935835\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:78.25660269260406\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:80.33575673997402\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:84.97926627416163\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:73.02866357266903\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:82.04398729773239\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:67.47074869424104\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-95734.99938459396\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-65515.09135656357\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-59806.35836400986\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-80792.04342844487\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-72961.18094596862\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-37498.428241348265\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-1048.5127591997384\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-850.0466453045606\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-19.29164343476295\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-955.6993774041533\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-536.2880264997482\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-238.82791416645048\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:94.34208824113011\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:94.84397483430803\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:95.36628131810576\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:95.39769984576851\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.1529614686966\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:95.29708195244893\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.75751960650086\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.9683276633732\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.64059326304123\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.80573488492519\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.91330769825727\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.49915466592647\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:98.59790929816663\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:97.74722922295332\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:96.17289294174407\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:96.99953253259882\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:96.8039737790823\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.34164263755083\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:77.3113306194544\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:80.16531934672967\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:79.37817202378065\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:78.84019173672424\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:82.8691164985299\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:73.38573534712197\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-7366.142718076706\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-59012.05458230973\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-10388.34088397026\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1380.7975147247314\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-759.3630384445189\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-5367.577113246918\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:67.20651969313622\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-4089.997943880409\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-51.765623056888586\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:90.78620488643647\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:90.31677010059357\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-43.946888256073\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:98.7220582947135\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.79200159311294\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.12195505052806\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:98.81397902071475\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.05119465366006\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.91823735907674\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.05836204364896\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.07192723825574\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.07259032707661\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.03357110396027\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.04886467237957\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:98.98277272321285\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:98.90729907955973\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:99.05837353728711\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.73089966960251\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.0492513909936\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.76077862763776\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.46935838386418\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:84.40473544467241\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:84.22438849406318\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:91.85970418844373\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:83.87787980232389\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:92.16804900541902\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.81840625740587\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-3148.6780807018276\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:98.29968376159668\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-910.0636194229127\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:97.02114696502686\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:99.04930038452149\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-1233.02574262619\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.7910361945629\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:95.44522975683212\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06639332771302\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:96.37415761947632\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-2920.4834544360638\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:97.2145046710968\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06754011586308\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:98.40543403849006\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06751746013761\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06745043471456\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06748015582562\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:97.68888369705529\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06751044047996\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06749518234282\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06750691665802\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06750914938748\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06751344893128\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.0675202421844\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.07163277477957\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.06972128283232\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.0593875022605\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.06970569621771\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.06824116548523\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.05831208825111\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:97.72945133503526\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:95.88098837696016\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:97.07112852558494\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:93.50615731589495\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:95.85519976420328\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:95.2671429047361\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-415058.3866306305\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-193552.51086692812\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-608887.6965915203\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-281945.30949530605\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-180875.76234431268\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-42323.04252557755\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-4710.869946590065\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2847.178178265691\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2310.7372511655094\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1934.132924425602\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-6773.705889418721\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1812.9337739616635\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-52.40144958309829\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-25.480975236557434\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-22.97277668826283\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:25.166132550733167\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:9.705123488605027\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-42.13256147149951\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:88.12750062625855\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:88.66428317110986\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:83.50731723252684\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:86.80516042662785\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:87.38049201490358\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:91.85528271198274\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:58.1583343923092\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:75.46502135912888\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:77.94376007458195\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:71.41781008709222\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:80.42001887615771\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:76.37209545187652\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:72.30102382516488\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:85.8279327686876\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:72.02424104250967\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:64.80573316197842\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:74.17687815204262\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:73.2511711653322\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-1093345.3422763825\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-96274.97422308922\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-466180.5250368118\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-1117106.8110992908\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-326128.7456270695\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-1074428.7541910647\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2607.16400324069\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-9647.21688324511\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1363.7460695192217\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-5875.57179261446\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-5648.020928925275\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2315.6940837204456\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:27.021855549514296\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:55.23163627795875\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:57.498243561573325\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:76.7148565985728\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:62.95097765317187\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.73703639507295\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:92.53582335426472\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:94.28665134562179\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:93.73563969461247\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:90.03878405602882\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.36199921835214\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.09131314810365\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:86.5089282377623\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:87.50413247430697\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:85.87219146210701\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:92.78276689546183\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:94.09652632018552\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:93.88367859981955\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:72.95477946922183\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:78.34889842886477\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:71.85268881376832\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:73.54622244555503\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:79.12418916858732\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:79.1637051384896\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-311169.2850756645\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-291453.3565676689\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-19416.505597972868\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-432331.53054256435\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-509529.98680722713\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-276661.03248109814\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1844.096125072241\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2028.415029990673\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2150.689785295725\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-3474.587426149845\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1691.418790972233\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-2064.0993854403496\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:85.12070524059237\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:76.66157427057624\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:85.95569119863212\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:78.4290387134999\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:78.97554896622896\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.87867430709304\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.27516664233991\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:96.50311674401163\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.76721818641526\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.69555728230625\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.76110234993394\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:95.63247516332194\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:94.51684002503752\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:95.21049428544939\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:96.4377029587049\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:97.5331274388358\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:96.1577193774283\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:93.25257355514913\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:85.75573525317013\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:80.81174753755332\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:89.71509407842532\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:90.43963013244792\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:79.20938089741394\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:80.42135375961661\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-102823.13098611833\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-164000.52270443438\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6958.681158828735\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-37108.4642455101\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-25610.317992115022\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-55197.76451129914\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-977.4346798062325\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-1297.335315167904\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1311.954009771347\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-1198.6949355065824\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-625.4194367170334\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1023.6029565870762\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:94.93438413925469\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:96.00844267159701\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:96.56683331932872\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:95.03383525758981\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:90.42200148031115\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:93.46444008499384\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.73145412712184\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.58919019177556\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.71108724889346\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.4459260724485\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.89519422613084\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.96179004972801\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:98.3986029581516\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:97.2132801245898\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:98.07452641483397\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:94.98002567794174\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:97.80307094608433\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.01746028221679\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:72.82506630681456\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:79.1243142216932\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:81.39552175030113\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:83.70028698062524\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:85.77627023160458\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:74.33412484657019\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1307.2427136421204\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-3087.4261457443235\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2995.791558074951\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2901.4662892341616\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1735.6350715637204\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-4127.355479907989\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:39.83807239532471\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:70.9195256471634\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:72.9514658987522\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:41.85891077518463\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:43.51359810829163\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-3311.108097189665\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:98.90470144152641\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.04839696586131\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:98.94678275436164\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.00714986510575\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:98.79880544915795\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.14191596731543\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.0291797965765\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.0440578675829\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.06692414544523\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.02223246917129\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.07028940916062\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.07384865721689\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:98.4383285226766\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.54314531870186\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:97.98928039502353\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.71300085261464\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.8729083164595\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:99.09492407692596\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:92.11334254834802\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:89.8050914558582\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:90.1738790488802\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:89.84406734472141\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:85.85764363240452\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:81.69382477412\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:96.71114196777344\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:96.43543796539306\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:93.85102443695068\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:93.09774122238159\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:90.98307838439942\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:95.7774161338806\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:99.06432685852052\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:96.06245291233063\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06625062227249\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.07273582220077\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-751.1039236888289\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:57.7508126795292\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06748978346587\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06756948158146\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.067518915236\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06749418079853\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06752319037915\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.06754715070129\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06751218801364\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06750753074884\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06750412397086\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06750890240073\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06752279810608\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06751540414989\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.06025357954205\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.06736838724464\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.068547680974\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.06723553109914\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.07130540611688\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.06751009477303\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.71171473078431\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:97.55315228978289\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:97.71098996098154\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:97.39411022868008\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:96.86548432819545\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.37153181787579\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-345413.84943346976\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-422049.68022990227\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-398853.0034854412\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-909074.4235487462\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-868095.1683195115\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-189600.92894558905\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-3113.0884784877303\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-6821.994347342848\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-3357.903355935216\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-4768.80463976264\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-4866.895133578778\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-284.34173318147657\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-35.93620047140866\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-0.7838228080421672\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-73.70326867848635\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-40.50901902643964\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-17.662713403906682\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-11.50724817663431\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:85.13742747739889\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:79.44290592158212\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:88.03385917195119\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:87.34793027993291\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:89.48615729603915\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:89.7183242900297\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:82.43693504072725\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:77.70920533239841\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:72.55105048692785\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:70.7720571372658\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:73.33216216191649\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:82.53226435082033\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:76.68813854455948\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:82.77968800766394\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:76.36948935445398\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:81.66933745667339\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:84.33847205103375\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:69.82737632002681\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-519794.78609383106\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-197707.7730473757\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-954330.5420608998\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-388431.81151485443\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-913262.1587832451\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-226445.16091588733\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2062.3605843037367\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-722.7426913380622\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-7568.73038021326\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-858.527795612812\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-8496.376175129413\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-4314.103819614649\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:74.33329823464156\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:69.1846050882712\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:65.46737614497542\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:59.4693675192073\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:49.57532000243664\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:65.10016686469316\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:96.6177671631798\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:94.99205270633102\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.56138159241527\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:94.76822882313282\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:95.38163160197438\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:89.92798176687211\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:86.17863059137017\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:89.9209161547944\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:91.47832262339071\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:90.95462000593542\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:89.08412259109319\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:88.51633777841926\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:78.20233620908111\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:72.42450278922917\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:79.03026591390372\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:76.64927008822559\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:71.20647012246772\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:66.28655821867287\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-454419.8057335853\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-385085.5615318299\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-241065.86280770303\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-171454.2578824997\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-100968.61039619446\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-421303.40595777036\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2736.2832562804224\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2665.6588171541694\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-3877.263049131632\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1951.848362350464\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2146.481210148335\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-195.68316741585733\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:78.34188807308674\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:77.64097822718323\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:78.54983768938109\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:73.38659290075302\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:87.59105634838342\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:75.80187841821461\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.8499842600897\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.04385866075754\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.28550043795258\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.64429045296275\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.51127217861358\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.4519353788346\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:96.7353192925686\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:96.0304123362992\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:97.60186499729753\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:94.51116712875664\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:93.89542878884822\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:93.67468294203282\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:85.68334169881419\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:77.02386265750974\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:79.6974028173834\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:83.33791991453619\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:85.72046119538136\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:88.87763632498682\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-56065.79778308868\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-63126.38944454193\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-80050.78941659928\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-41138.879397964476\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-103722.07185134887\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-58765.64361476899\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-807.7840326309204\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-30.634438216686256\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-556.3857084974646\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-433.04902042746545\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-206.71753242611882\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1182.3722357451916\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:93.70906594805419\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:94.42777689248324\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:96.12475564815104\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:94.10683332756162\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:93.92311341613531\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:95.97247329652309\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.85869156736881\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.51986229438334\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.90072636683472\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.64379577545915\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.01442387225107\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.46958232186735\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:98.54103790782392\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:97.81176836788654\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:98.13652934851125\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:95.6292657898739\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:98.27563537913375\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:96.97671541832388\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:83.16667397804558\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:83.29197007361799\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:60.829192515090114\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:89.90977198816836\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:84.99967986680568\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:78.14563342165202\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-14022.52339167595\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-3250.407669353485\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-10818.624131393433\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-4089.157642269134\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-3141.1153000831605\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-4689.272268486023\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:0.40924031734466126\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:10.880836462974553\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:55.12777378559113\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-782.3939807832242\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-514.4456797361374\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:36.175919890403755\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:98.88092116899789\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.87724793553352\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:98.86911735013128\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:98.95511248856783\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.05510611506179\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.86780651248992\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.06472727153451\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.06854508020915\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.0689578325022\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.07962524071336\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.07395307794214\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.07571219019592\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:99.08333868198098\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.92772904019803\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:99.01143772965297\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.37921317503788\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.66983100632206\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.18643202427775\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:76.52761954590679\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:76.58453002106398\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:83.04225095957518\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:93.52378385160118\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:85.96894307509064\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:87.27426082715392\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1768.2508979558947\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:98.08674621582031\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:96.67888278961182\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:36.76181907653808\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:98.07639446258545\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-199.09648056030272\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-236.165377753973\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.0670674085617\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-1341.4843627154828\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.06633863449098\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.05626931190491\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:98.57739810347556\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06754056140781\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06758542247115\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.06749966442585\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06748795099557\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.067541064322\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.0674336515367\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.0675226087682\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.0675103972666\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06750185033306\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06750396061689\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06751213781536\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06751522328705\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.06726081557572\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.06393167232164\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.06052436046302\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.02335122078657\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.07088810987771\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.06745015289634\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:95.34567383024842\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:95.19845480895601\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:96.17865951798159\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:97.21078932639212\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:90.95677684247494\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.69276758462655\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-519968.05903887755\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-100194.92575662136\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-616773.8360609055\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-531193.2364151\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-618631.9094398498\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-550552.5173896312\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-5461.448432070018\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2095.7941021949055\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-975.5934219598769\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2624.709046280384\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-765.9397318929434\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2943.6501708716155\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:6.118530407920475\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:15.957175937201828\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-80.04694769866765\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-13.521698110923165\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-37.356358711794016\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-2.4636546231806333\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:89.39870292600244\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:91.42143150810152\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:89.18800910552964\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:87.77171263219789\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:91.55799442883581\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:85.45515306126326\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:79.73294789455832\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:80.61117734517902\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:71.70752943335101\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:79.43208450339735\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:85.90228940807283\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:62.41582945836708\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:81.29482429940253\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:83.62753275865688\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:75.73296723999083\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:78.32941843708977\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:80.94862235793843\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:86.24365350171284\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-436178.48570194247\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-501800.59222049714\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-275284.0067027092\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-659788.2429815768\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-898497.6052628517\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-515325.71790208813\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-595.571040892601\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-3121.1118024975067\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1677.136645888537\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-8936.361197137834\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-4209.3203057944775\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3555.8048607699575\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:63.27156793549658\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:80.7451162436977\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:63.60089055579156\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.56814858671278\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:54.874490614980466\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:34.58927276143804\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:91.54497880185954\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:94.23666222747416\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:93.4431643795222\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.93668736293913\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.51513385809957\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:92.0500577061437\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:89.70113984774798\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:91.09442828008905\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:87.13824506411329\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:94.53415066385642\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:91.88844000883401\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:87.2614908296615\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:68.48241641102359\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:71.2533529786393\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:60.94851901223883\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:69.25576039217412\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:74.66635643430054\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:79.6402163730003\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-523234.2322957992\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-433950.36252204183\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-634224.0491510332\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-248511.23358962536\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-236153.30566215515\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-507884.2333230972\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2063.043311935663\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-3035.284761452675\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1827.8525766819716\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-481.3371370255947\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1623.8761107325554\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-2962.7331778526304\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:78.807418942824\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:83.51896462142467\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:76.93991752723231\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:79.2844258164987\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:83.78974362388253\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:76.93672820031642\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.16114071067423\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.19366758549586\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.40628799982369\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.129792445153\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.51615072423591\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.39117553057149\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:94.74177778763696\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:97.33114538541994\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.19484692558181\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:95.9116945253685\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:96.62572112167254\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:97.25222346964291\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:69.97971032913775\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:63.42203821986914\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:81.11635138057171\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:86.80248060300946\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:77.32419036515057\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:84.68331079799682\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-54948.50864439011\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-37149.21248226166\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-37272.451445007326\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-65501.91974449158\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-68432.81558876038\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-116049.70142269135\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-172.66468301415446\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-307.6454555511474\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-245.3018460571766\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-702.9452027976513\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-392.49930993318554\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-433.02555979490285\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:93.64688687212765\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:94.03934613019229\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:96.16121300347149\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:96.12508993670345\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:96.06168660260737\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:95.17927878936753\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.58406497463584\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.97799132689833\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:97.94548305608333\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.83487034155988\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.84687038846313\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.62152681094595\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:96.5456944416277\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:97.25739933764562\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:98.28465964067728\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.79854056257754\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:96.88833628376014\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.56978172073141\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:84.2543677188456\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:77.62107339613141\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:77.46672701686622\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:85.66047753756865\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:82.93597343955189\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:83.64867878928781\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-6726.2497447967535\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-15440.014004325865\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-3782.458933162689\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-102144.13864240645\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-381347.9920290947\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-14662.123646068574\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:52.6066437959671\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:74.44377665519714\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:79.07174490690232\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-929.6276473879814\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-396.83250452280043\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:18.16910257339478\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:98.98651428446173\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.07839269302785\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:98.76464317515492\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:98.873086579144\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:98.99761883988977\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.05276654288173\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.08978831842542\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.07486207373441\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.05447981115431\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.05706251133233\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.06035308334977\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.07309677866287\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:99.1168012689799\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.64464658740908\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:99.00459515210241\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.73884875085204\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.68599943108856\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.75381327634678\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:87.50529260542244\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:90.7794905906543\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:86.0290679696016\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:91.33855039309711\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:85.25542388428002\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:85.85680263293906\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:97.84103717803954\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:93.99273719787598\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:97.1988353729248\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:98.7264539718628\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:98.55023727416993\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-79.67543921470642\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:87.27665426731109\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.08045645952224\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.06421096324921\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:95.07860636115075\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-0.5001226261258207\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.986396586895\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.06755912937224\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.06749623659998\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.0681695509702\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.06758027924225\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.06745642349124\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.06755631566048\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.06751370616257\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.06751058511436\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.06750553771853\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.06750379391015\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.06751811243593\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.06751430714503\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.07109779082238\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.06976069463417\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.0715387227945\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.07158305170597\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.8922231277451\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.07152148596943\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:96.52352015869693\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:88.64992087539285\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:93.53297138726339\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:98.07449333434924\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:95.54923442024737\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:92.87894396781921\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-48088.869065094\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-51444.52865219116\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-3190.8430363655093\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-48909.8933517456\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-5767.069134521485\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-5827.140413856506\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-48.62887183427811\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-304.1579666733742\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:29.011051478981976\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:19.31823707818985\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-371.08353869915004\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-340.4124336481094\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:84.55998584702611\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:94.69012799412012\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:94.50010770559311\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:92.86655842289329\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:85.04505935758353\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:30.251870810985572\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:93.9766511451453\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:87.78259797450156\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:92.23107514157891\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.41024233996868\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:74.05949414744974\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:47.00660021603107\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:83.23357154270634\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:26.37362938821316\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:90.16326232179999\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:34.5394212514162\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.85536267161369\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:94.36145859211683\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:62.60330677777528\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:92.19937592372298\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:46.084711669385435\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:83.05658644884825\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:95.69185779504478\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:34.59442040324211\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-3225.70683965683\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-8116.915816497803\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-3349.0708581924437\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-9306.405369806289\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3537.411986732483\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-19471.18855743408\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-83.68738801479341\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-144.29685616493225\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:53.93815089762211\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-408.4925357460976\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-302.1426300525666\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-184.75386708974838\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:83.42176490277052\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:80.51713662631809\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:78.72208958342671\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:92.98686148151756\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:88.97696632836013\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:85.59519235938787\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:89.09579567294568\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:84.4079921104014\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:84.93582031652332\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:93.46957246121019\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:82.18071045726538\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:92.51766614243388\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:39.561615692079066\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:93.5820078233257\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:92.54845228493214\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:85.05289166085423\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:43.029455700516706\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:90.273932839185\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:78.31624856367708\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:88.75133030191064\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:46.31314539015293\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:75.62117062602192\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:89.04422048255802\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:81.52226416245102\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-4780.252327156067\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-11058.861179256439\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-10821.818309783936\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-3697.9653518199916\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-6655.460029792786\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-2631.3988181114196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:87.34429378509522\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-6.479601651430134\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-16.11354990899563\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2.6626692771911653\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-34.50091019868851\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:25.201760363578796\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:95.37493378855288\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:92.52831871900707\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:89.65948628149927\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:95.07759832795709\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:96.30448665842414\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:90.58506844509392\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:92.22446472495794\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.32300686612724\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:93.85866394564509\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:92.95054146945476\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:90.0284597031772\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:90.03731405436992\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:90.90815940275789\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:95.4372873250395\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:75.31955228447914\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:86.47965625226497\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:63.753699319064616\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:93.56722831493244\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:75.00766299813986\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:76.00580125525593\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:29.018448156118392\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:47.63297029882669\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:89.85065514482558\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:91.90458648912609\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-3759.8841560363767\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1048.1944933891298\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1185.4839708328248\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-620.6130119323731\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2536.833666849136\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-4127.0246097564695\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:66.96052198410034\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:71.60133051872253\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:74.1595447063446\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:89.63778624236583\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:64.46785741448402\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:94.09693697690965\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.6792875463143\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.71799946445972\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:96.72922524847091\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.58716235384345\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.07412948980927\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.39309045262635\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.06233602091669\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.77298957819585\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.23472867757081\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.98370365202427\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:96.10190481990576\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:96.74125366955995\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:67.77055467441679\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:56.38506786003708\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.09859323725105\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:86.52621622569859\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:95.20773891545832\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:92.877020807378\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:26.825792598724362\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:18.02559175491333\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:-14.659865850210196\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:34.686555945873266\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:85.68014801815153\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:90.9857957996428\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-128.07818145751955\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-183.5804515838623\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-370.3918174743652\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-23.705634307861324\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:43.4276403427124\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-146.4710433959961\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:91.31860798597336\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:98.24042251110076\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:95.16213847137988\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:94.18819190263748\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:91.13814910650252\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:92.06335606575013\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.55356243457645\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.65874083638191\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.53128922879696\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.63977359980345\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.37331332266331\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.60985499322415\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.28972738981247\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.35486954450607\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.50725565776229\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.59468381255864\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.55487369149924\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.48123594373465\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:95.0101518554613\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:93.80374237038195\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:93.38445351887495\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:95.55709687396885\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.89670709073543\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.82587874680758\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:81.59856515061111\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:69.57067197486758\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:95.2580923720263\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:65.31530180498957\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:68.19208354577422\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:58.24445176422596\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:98.7478147506714\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:99.00649795532227\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:92.4939754486084\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-31.082228851318348\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:95.93444290161133\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:98.88763961791992\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:99.19967778921126\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.29199521541595\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:91.24459123015404\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.03861025571823\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.81108741760254\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.7093790769577\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.50345119535923\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.3240889981389\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.77006349787116\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.78431359380484\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.78085352629424\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.7800916738808\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.73964156210423\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.76218779683113\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.7527446616441\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.73625692427159\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.7453389108181\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.74500937834382\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:94.43070215880871\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:95.28849608413876\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:94.2809195265174\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:96.25051571130753\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:95.04465326145292\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.74552998170256\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:64.19817704409361\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.927758537232876\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:90.33306051623076\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:94.43105782270432\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:93.06521238610148\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:36.45578854680062\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1600419.7613983154\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-2018289.299994469\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-63087.02640323639\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-1383382.2032300949\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-2252100.308657837\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-805965.7186656952\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1085.5119634866714\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-742.6888779073954\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-345.618444815278\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-524.2620115101338\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-3111.9447502851485\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2696.798773384094\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:77.45717425644398\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:69.98040483221412\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:87.54578826092182\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:77.73741889223457\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:67.72069677636028\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:44.8677075907588\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:81.15034297183156\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:58.761805161833756\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:87.78360294476151\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:82.48323960006236\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:78.49459609910846\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:87.4980108525604\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:78.39693479761482\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:95.79869700883282\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.60106479600072\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:41.30559593439103\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:86.32514295242727\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:88.31386808604003\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:90.23184994012118\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:80.86147795021535\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:73.73979703038931\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:78.03327594548463\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:55.631065499037504\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:93.39854968804866\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-599344.7436168671\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-568091.1406953812\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-57851.21918945313\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-90632.84212646485\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-113562.67614135743\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-146829.37972812654\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-591.6847516983747\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-761.6565693736076\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-473.0718069314957\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-195.35501509904861\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-157.7479878902435\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:12.839945226907734\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:95.30284046866\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:93.52691531702875\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:95.05892281401901\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:96.55301170200109\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:92.75526217855513\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:92.82262748656794\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:79.50552969500421\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.6183089133352\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:93.54221867471934\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:96.63987788986415\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:92.6278550826013\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.9025311216712\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:58.973179464787236\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:87.07991223186255\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:89.63997185528278\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:67.21283956095576\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:92.42921241298318\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:92.0174934733659\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:63.77631199881435\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:62.29465634524822\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:83.95273042991758\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:67.47120358571411\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:51.354213485121726\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:38.274115963280195\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-12555.543868255616\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1880.4011642456053\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-42354.05709838867\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-142095.4742422104\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-32597.431622314452\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-88599.63178749084\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-194.01152369976043\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-25.50262765884399\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-74.6751998245716\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:28.697201642394067\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-25.358384394645682\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:45.14687642157078\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:95.72018689140678\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:98.12373813204466\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:97.32178889010102\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:98.34103086516262\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:98.18908597170375\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:98.09213546402752\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:94.73842963119968\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:93.16558006200938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.09737777039409\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.47677947841584\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.72333318442107\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.2028350578621\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:85.45911756120623\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:92.87867464199661\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:47.648460467904805\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:86.12292599491775\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.02837133780122\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:59.47382434606552\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.463656920939684\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:88.17200486324728\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:79.74858395680785\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:46.34742687642574\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:79.1432486988604\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:66.1199341289699\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-988.8158386230468\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-9797.601084136963\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-12985.215507507326\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-16799.51075372696\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-15599.427563476562\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-30878.36811580658\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:48.13330748081207\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:17.968556308746344\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-15.39124794006348\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:34.290697252750405\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:93.4342301607132\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:72.38758674860001\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.5409878494218\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.53413503915071\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:99.16173617392778\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.55836366787553\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:99.02098943926394\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.7385282350704\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.82139305826276\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:96.24994575791061\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.14368055537344\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:97.43816093951465\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.41195726180449\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.83564317850396\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:52.45271949023008\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:87.91887718215585\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:89.97690380811692\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.63509339439915\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:71.13206938877703\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:84.59056702516973\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:84.93479976709932\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:50.61836067438126\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:71.63826036155223\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:91.38352190628648\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:61.79986549839378\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:91.84109082445502\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-44.812720489501956\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-741.1461350440978\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-675.9378845214844\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-330.98236618041994\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1307.4884002685546\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-614.9635665893554\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:90.64744732379914\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:92.97837973088025\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:96.3247477799654\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:92.22553251981735\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:94.6241272687912\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:90.0559852719307\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:98.8636419981718\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.40940544810147\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.17571765035392\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.42426027469337\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.6250832729973\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.87613034918904\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.24656258150935\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.14912027418613\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.10179074704646\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.16469000726939\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.39589456748217\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:98.53591611674055\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:93.74071831293405\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:63.01361730024219\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.88656615354121\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:89.08633885532618\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:96.41246185861529\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:95.12159073706717\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:91.70884624421596\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:86.69197304397822\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:94.8325851202011\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:62.72535322718322\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:81.63000148534775\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:76.33884626179935\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:93.48119049072265\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-1643.432901620865\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-137.63853178024291\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:15.403512001037601\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:71.67520599365234\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-52.70623111724853\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.63633649349212\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.65640892982483\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.50580073595047\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.48576309680938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.08993016481399\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.36722922325134\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.63315559960901\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.54516585916281\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.63812955319882\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.36479792371392\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.3811635040678\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.65978693859651\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:98.66347851540776\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:98.75819749757648\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:98.93486226461827\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.52918186411262\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.46801703944801\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.61529693379998\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.86706557646394\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:89.274041056633\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:97.84195515806786\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.29510194286703\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:97.72901447936893\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.05955995246768\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:89.71655045449734\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:94.07181205227971\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:64.13790664449334\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:79.88331841230392\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.48736248537898\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:84.00309729725123\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-4227.153128051757\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-3982.197524261475\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-4102.283755493164\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-4965.394911193847\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-35079.70196685791\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-76437.51777038573\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-246.48083662986755\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-374.3777286529541\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:29.902896344661713\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-196.8955732703209\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-775.7233758449555\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1057.491248703003\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:59.85359894633293\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:88.52727869674564\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:69.91927718967199\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:79.91443496197462\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:58.698189827799794\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:90.38963003158568\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:67.6421356625855\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:76.88565855436028\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:41.987381792068476\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:38.3903757840395\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:95.01068883873522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:77.97580063715577\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.08145309090615\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:93.33859427124261\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:56.221676382422444\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:73.88496740236879\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:88.18802150394768\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.713797231018546\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:77.42066636085511\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:57.137308222055424\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:77.30393120013177\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:39.540802541375164\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:57.94964815676212\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:80.49820777997374\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-30632.268762969972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-27884.676154327393\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-4863.231805610657\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-22457.700803375243\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-28523.08388156891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-13519.35776810646\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:1.2312615931034054\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-293.95100487470626\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-27.067762887477876\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-125.4320392847061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-84.86249263286592\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:0.5102733016014049\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:92.83590405657888\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:83.88877384588123\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:89.4619238294661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:87.83685853835195\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.97576748784631\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:94.98047145269811\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:81.98337573558092\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:93.16877356376499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:86.72989653833211\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:91.34156813696028\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:87.82497677654028\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:89.8528162561357\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:88.51717757284642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:89.89115531034768\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:76.94096554517746\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:80.6767409492284\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:63.11943841427565\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:65.06379294469953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:58.35184301584959\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:81.32166157811879\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:58.13091856390238\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:62.86550463736058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:66.97378136515617\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:67.14299006834626\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1111.1391046524047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-16023.984229850768\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-9743.839255666733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-5396.854211235046\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-11975.131312179567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-7732.275784873963\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:21.411333405971522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:47.329521942138676\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:22.467785812914375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-14.964034497737888\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:53.214136514067654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:21.392952927201993\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:95.53335856571795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:96.09924147296697\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:96.09263617172837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:93.81785813383759\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:93.76902551501989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.85020241811871\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:95.9353594534099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:93.14247336015106\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:94.35715306550264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.35928445756436\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.01701508313417\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:95.46778639089317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:92.92971256580203\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:37.041490188241\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:95.33897749260068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:65.56809674054385\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:83.62141177281737\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:89.17963474616408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:40.676303099095826\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:93.23491475954651\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:89.43951667882502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:65.6422886043787\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:68.2150113157928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:65.385009598732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2904.6458145141605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1115.6406660079956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1087.9885700225832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2463.1690798282625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-4609.604620361329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1954.6722032547\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:85.21146260648966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:54.84454793930054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:82.59810433387756\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:74.76169898509978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-100.98452903032302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:83.37316842861473\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:99.15867709219455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.5354791097343\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.22227785512806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.93541376441716\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:99.01355658099055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:99.0463048800826\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:96.18840832822025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:96.61898244842887\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:95.48607062473893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.8321757826954\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.39752437919378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:94.07156420126557\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:86.06838107649237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.4730187870562\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:80.22079069465399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:75.0803193874657\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:85.64444781821221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:58.73067626953126\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:24.048990350961684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:58.04603389501571\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:66.44220644533634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:58.23502326756716\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:91.53044639453292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:70.06775453463196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:26.29303741455078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:8.42144088745117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-229.4856683731079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-88.18106346130372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-8.221543502807616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-19.54165992736816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:96.49689180850982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:93.14294764995576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:98.94134349822998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:98.09668236970901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:95.02144000530242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:97.91777166128158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.20707516670227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.72069143820555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.55191660039127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.31445432305335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.75871831253171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.28540946096182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.64488181732595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.61771342530847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:95.23401080453769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:98.69816024303437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.71485608611256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.67672894150019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:74.2093980230391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:93.93074565976858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.68207533359528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:72.97983130067587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.0835267469287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:91.72783240042627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:89.65605197399856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:93.66878416389227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:68.52793730497359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:46.66389147341251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:77.56278042718769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:80.82836602777242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.14647979736329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:48.91625556945801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:99.36872291564941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:97.50420112609864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:77.8305516898632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-825.2957113265991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.84591230154038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:94.32786118388175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:97.59587507247925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.84849691390991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.15511646270751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:77.2867793276906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.72388510257005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.77093578949571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.7904566667974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.8044637106359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.78979075327516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.77073838915675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.76521900445223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.77421157807112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.74664346277714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.7254641868174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.73946280926465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.74361685439945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:95.45183082148434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:94.49761209338904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:96.51708118692041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:94.81022338196635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:95.48288553357125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.50590382949449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.47083322852849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:71.74374457746744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:88.12535817585886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:86.91067655012012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:87.05729106068611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.47862468250095\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-27008.783555817605\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-33155.81143078804\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-1751.2072136878967\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-3314.937105178833\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-39078.11398220062\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1698.022867536545\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-258.48370123803613\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-766.2879788145423\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-233.51960565149784\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-84.64440757930278\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-325.321166497469\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-213.15154283046724\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:74.55796973258258\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:80.94185953624546\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:83.10648470595478\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:81.12700094264001\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:78.17341896779834\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:86.11732871644199\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:79.64079344645143\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:82.61976947188377\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:77.70336372293531\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:88.52257866864093\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:92.9757844183594\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:54.58225593045354\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:76.82112844884395\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:58.311277455091485\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:45.41210607960821\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:85.6633795183152\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:76.58493582382798\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:89.22431313302368\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:92.12273170780391\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:70.55722136944532\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:40.253839451074604\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:86.62681378163397\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:75.71924194544553\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:80.71706515811383\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-20075.389747238158\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-14868.377530479433\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-19994.84762868881\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-17654.306739521027\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-17350.744239234926\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-15861.785851097107\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-34.61606626063585\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-25.39555017352104\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-115.97381175160409\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-126.58755892217157\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-102.59961544275282\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-59.33050422370434\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:93.24520103149116\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:91.59864409975708\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:90.85900579197332\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:87.39115440919996\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.83661301592366\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:94.25522893061861\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:88.60135733820498\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:91.11467703673989\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:89.53032070100308\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:74.93689145520331\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:95.67462546899914\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:94.53404794614762\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:90.36725858885329\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:76.82263057809323\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:24.95494169145822\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:68.86073922589422\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:90.61802333751695\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:87.70018057972193\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:75.94795285314322\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:46.31388573348523\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:89.1616335278377\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:67.3792703345418\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:81.31728420816361\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:82.78106743022799\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1645.3781953811647\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-7153.185033893586\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-6359.656888961791\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-7341.794012832642\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-5893.493800354004\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-9073.93541698456\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:2.63093459308148\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:55.25599217619748\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:43.078354807198046\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1.474742445349686\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:30.632735919952392\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:31.12986565828323\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:97.32361961826682\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:94.79797038484831\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.4265449564904\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:96.68427681922913\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.02314450666309\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.53004097621888\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:95.86544622164219\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:96.74942586831749\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:95.42014137003571\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:94.77654498405754\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:89.87609408665449\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:95.98442418277263\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:92.77304364740849\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:79.95892051421106\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:89.61061910334975\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:64.68803145885468\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:70.11747806444764\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:62.40205398350954\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:85.53738435506821\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:41.491181117296215\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:87.42049515917898\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:63.497419568523775\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:62.86203000172973\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:35.572265204042196\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2866.6193500041963\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-953.3802384853363\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1756.2088922977448\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2469.613880324364\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-729.0189806699752\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2271.587481307983\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:68.9737841039896\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:62.10660068392754\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:80.24512087851762\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:89.51953484416008\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:85.40998028814792\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:78.23748641014099\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.52783094123005\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.43103647604585\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.28180000782012\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.74433157909661\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.68219392336906\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.90414113998413\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.35717351436615\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.30245915204287\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.83528627408668\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.2363346222788\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:96.47180592790245\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.06010870859026\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:94.74427666123957\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:74.73707106932997\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:85.07797945961356\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:69.64291036371142\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:70.43841881230473\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:91.97029814869165\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:65.11118865013123\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:88.33339331373573\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:88.63306076861917\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:87.6778890401125\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:73.53431763947009\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:64.06754596531391\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:36.89489181488752\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-21.13968124389649\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-9.185031223297123\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-39.762924003601064\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-91.11882028579711\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-32.856254577636726\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:97.69954271316529\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:96.3650868177414\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.94638862609864\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:91.79202501773834\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:92.06480221450329\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:93.42501709461212\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:98.68765343725681\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.93347931131721\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.66123503744602\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.744073658064\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.63109431713819\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.58966645896434\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.50485135652126\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:98.76745022833347\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.48355977907777\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.5668046461069\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.38742904476821\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.59264822453261\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:95.45291335526855\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:87.8089655181393\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:92.059256926924\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:86.8864986486733\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:73.6070286143571\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:84.53110549896957\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:69.65705794766546\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:43.23398264944554\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:81.78034062422812\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:60.57587035894394\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:68.92079662382602\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:84.79105449467897\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:92.06172561645508\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:85.0044099509716\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:91.33843063935637\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:93.53172883987426\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:91.90739221572876\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:92.72528533935547\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:88.06836874037981\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:92.15473605245353\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:92.09396196007728\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:92.34377949936315\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:91.34972763061523\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:90.98346176445484\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.68623093352653\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.14010330736637\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.23898288942874\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.79952518641949\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.70040558055044\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.7625125154853\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.65174672156573\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.74924488663673\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.71260468065739\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:98.84352654218674\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.7160841614008\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.58430740013718\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:97.89741823896766\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.79209237415344\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:97.9132877394557\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:97.81481746956706\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.08435993939638\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.95401554964482\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:87.91565302573144\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:92.52706960523501\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:76.12955122366547\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:83.34395314045251\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:69.87352277636528\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:72.40943477600813\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-114129.19982910158\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-279617.8769104004\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-10419.943295288085\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-181004.36651611328\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-380974.993371582\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-89151.87709350586\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1162.4024449110032\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1976.2733023643495\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2771.326577758789\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1282.3459051847458\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:46.042162132263186\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-139.63132216930387\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:16.764238762855534\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:23.30821868777275\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:25.398335248231884\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:32.64523170292377\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-15.635017237067217\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:30.44644328355789\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:74.62788953632116\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:90.58897407501935\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:87.17045380324126\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:65.49037200808525\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:67.76640323400498\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.95599634498358\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:82.60258231014012\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:62.10025935918093\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:71.42957468777895\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:79.84614492896944\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.816818732023236\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:86.91968637555838\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:87.77853822372855\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:87.65768676921726\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:95.1438937089406\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:87.34262350425124\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:93.61191471517087\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:59.44618816003203\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-82234.19823608399\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-106683.84674491883\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-77416.67880439758\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-23223.0802406311\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-83576.74815979005\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-16283.338272047044\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-425.23667175620795\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1710.9079359531404\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1658.5938768863678\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1341.3327733516694\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-725.7609436869622\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-684.1387601375579\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:84.34759441316127\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:70.76197624355555\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:79.23101023361086\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:86.0241915838793\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:66.37762696631253\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:86.80263455957174\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:89.83023740649223\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.47675146982074\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:82.0487606421113\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.75765282586217\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:92.71991349980236\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:88.38096106741577\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:81.96186572238803\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:81.08775445781649\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:92.99790603090078\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:89.96378982048482\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:82.48151537775993\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:74.48547703363002\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:88.16932984814048\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:57.48101492673159\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:93.33245195262134\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:82.61794423311949\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:45.93702460229396\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:92.01038613840937\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-9796.70110874176\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-31521.862984657288\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-56458.892959594734\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-14869.270123004913\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-26607.52212982178\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-29321.142986202238\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-74.7885168850422\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-271.48547570705415\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-150.45860859155655\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:47.68205877542496\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-170.57895607948302\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-168.94175958633423\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:90.42028420567513\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:90.86485558785498\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:93.15054100900888\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:88.91971722990274\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:95.7100881876424\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:92.77728112209587\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:91.70553607866168\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:96.05942696779967\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.9013276860118\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:95.13018009215594\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.20814115218819\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.57057348866947\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:88.88631830848753\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:68.23887480944396\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.12982556037605\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:90.81402417942883\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:89.2958972543478\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:69.39621063172817\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:39.86789579093456\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:83.72810733467341\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:82.34417389035225\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:87.55061480626463\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:95.36676641330124\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:93.25006435066462\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-5302.446709251403\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-4315.248753166199\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-10190.604794692994\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-4412.492946815491\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-13849.850242996214\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3873.9952344894414\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-10.414243066310892\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:69.60053308010102\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:19.724366331100462\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:51.145621705055234\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:31.603436309099198\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:12.925675284862514\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.30782133608591\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:97.7196877207607\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.90607271455228\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:97.10824319422245\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.96696039922536\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.13539749605116\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.8711492061615\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.988060233742\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:96.32710209190846\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.02525999173521\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:96.1253776654601\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.92998575922101\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.0525858826004\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.27671735733747\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:93.05353837125003\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:95.32000959962606\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.9233928170055\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:92.79737674742937\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:88.38114281222225\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:65.23479575440288\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:59.95485262349247\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:93.78304313383995\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:87.93945951275528\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:68.70261130984872\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-92.4682300567627\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-827.7080795288086\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-820.8840790748595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1005.8831512451172\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-488.3213119506836\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-454.8636443138123\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:91.52596840858459\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:94.56797611415386\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:96.841942435503\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:89.5571252822876\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:92.82390794754029\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:95.17524316310883\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.0101062119007\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.60773612484336\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.4750494968146\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.6045255124569\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.41600993983447\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.30217353925109\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.52587235718966\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.58385405037552\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.6330441519618\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.56045442149043\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.63854387253522\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.59067217372358\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:94.50366594120861\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:94.26278672460467\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.45944915749132\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:95.51976616196335\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:95.41068836972117\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:96.09552496671677\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.34211427792907\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:49.798474149405955\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:87.37722664512694\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:85.98137025609613\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:79.64027645178139\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:84.7815697811544\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:99.19885015487671\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:79.5236385345459\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:95.12709655761718\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:98.88285007476807\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:99.03557929992675\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:93.49570503234862\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.49896778464317\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:97.63123563751577\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:94.23647119104862\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:98.93217899799347\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.0636186361313\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:97.93729716539383\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.71634586639702\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.74430813863874\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.72746911421419\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.63437187075614\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.68972569443285\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.75019202046096\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.74645312875509\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.69700361341238\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.706165189296\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.69228638783098\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.7209780909121\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.69046678096056\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.04918391555549\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:95.82142011597753\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.57556116357445\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:94.62209309339524\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:95.68771119564772\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.91475496664643\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:93.92699495963753\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:82.9914041472599\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:78.6789819277823\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:92.79989271238446\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:95.01707169301807\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.93406691467389\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1939650.4118225097\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-140552.11823477744\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-178262.27659311294\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-200269.01716270446\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-4440075.005221558\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-3486359.161700439\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1816.0518082380297\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2325.364591217041\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1824.2114421129227\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1527.7141106635333\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1235.7894546538591\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-394.87473281919955\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:90.59992297124117\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:86.09592091105878\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:72.2926273535937\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:58.210820303857325\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:84.19581029601395\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:68.4394068866968\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:75.48268060944974\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:81.24491295218468\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:92.26498062424362\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:78.08801794722676\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:54.651818609237665\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:89.35545640215278\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:78.29199699684978\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:66.81792351230979\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:92.5212022037711\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:76.51761012002825\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:91.21479646191001\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:76.05281690098346\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:77.20226123407483\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:87.04044560156763\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.01971010640263\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:91.9135995965451\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:79.00519989132881\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:78.90773855186998\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-427786.0278930664\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-535551.4681274415\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-72661.34624938965\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-1930264.3830055236\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-580010.6005011558\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-536634.5295501709\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1764.0283680856228\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-3208.164373391867\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-633.8786477923393\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-3633.9421291232106\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-743.0204101324082\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-366.94437606334685\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:92.05967784933746\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:95.1210970794782\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:95.31172131430358\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:94.72090512160212\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:96.73582361526786\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:95.30565687641501\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.8770307956962\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.71824315600097\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.42801755033433\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.01002212613821\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:94.15940533131361\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.75334779061377\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:89.54746356457471\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:90.8217579467222\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:71.1392798654735\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:69.52955408915878\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:85.27828697636724\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:91.5314954880625\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:90.0668885326013\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:85.5544219456613\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:92.22029199814425\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:89.80658796206117\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:62.210380918532614\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:70.25967939719557\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-110762.21051635742\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-146941.57682037354\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-329187.71988191607\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-458465.4400547981\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-213066.63093185425\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-168020.86108293533\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-171.42499809861184\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-466.1119340419769\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-307.90826270580294\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-246.63978271484376\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-41.211862951517105\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-170.37913260757924\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:96.29857041034847\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:97.13739913608879\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:98.1379064832814\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:97.55179834906012\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:97.16969971619547\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:95.76185609893874\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.22181587591767\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:96.83450263729318\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.01413931772113\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.84569864720106\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.49844295242801\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:95.70114092454314\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:78.23084025159478\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:94.49008357860149\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:90.64672210887075\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:93.93548478968441\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:94.9494882684201\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:93.6274441562593\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:56.550861618667845\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:78.63921990469098\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:79.16742861606181\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:88.91814164370298\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.03747323825956\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:89.16597252013162\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-91427.92391357421\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-98474.88705444336\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-27613.078349304196\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-24382.04607619643\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-27614.509814453122\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-55932.16575317383\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:84.77998442649842\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-75.53551650047304\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:9.039000809192654\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:16.692268824577326\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-18.745356273651126\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:82.89981136322022\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.97846177443861\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:99.06227903664112\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:99.00846776636317\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:99.28742661159485\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:99.11067960634827\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.31384307816626\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.34541556462646\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.87020069919527\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.77736644148827\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.93401783667505\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.4966620770283\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.05257518003346\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.0148808863014\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:92.68675998821855\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:96.36306473873556\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:90.49368532374501\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:92.54468134567142\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:95.59333292413503\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:77.47699029669167\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:88.75232804771512\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:80.83448588326574\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:91.17674020631239\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:83.79017512612045\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:79.12758674863726\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-6313.06190624237\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-578.4173656463623\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1597.0498626708984\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-4642.762606811523\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1408.9077262878418\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-9990.737215042114\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:89.34217660427095\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:81.01942902803421\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:77.55541292391717\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:91.22301869392395\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:94.73814153075219\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:86.14601440429688\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.5383707933128\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.43806122392415\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.36160456473007\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:98.75927101448178\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.5587140545249\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.97277877181769\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.03329434078186\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.20973044503481\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.23574001789093\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:98.73750594584271\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.19841687660664\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.34333410039544\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:92.90818378161639\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:96.07757553197443\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:97.64706871509551\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:97.24303192123772\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:90.46597727090119\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:96.61994040831924\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:63.85649510324001\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:89.72823616056704\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:93.97977512981743\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:80.6389060843736\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:90.49333445765077\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:73.23142008259893\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1354.3005409240723\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-677.8651508569717\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-1559.6113726615904\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-318.7066686630249\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-678.734673500061\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-5214.1042375564575\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.69096140861511\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:91.68710162341594\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.69330090284348\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.38744847774507\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.08262394666671\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.51225094199181\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.77603319119662\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.68277964536101\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.70421758703888\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.64530577273109\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.69831891776994\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.77239594897254\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.49132800847292\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.63990323597099\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.63452889621259\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.68089329712093\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.52522229328751\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:98.9503262847662\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:97.36249885465949\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.55812030676752\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.53814847506582\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.60166285540909\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.15062794908881\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.04893514467403\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:93.4444650535239\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:92.51081038936972\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:76.02671052627265\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:92.12857947982847\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:86.9305380500853\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:83.24545347988605\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-42848.724259948736\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-14443.336263203622\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-75176.52935485839\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-73870.55512390136\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-114344.1215637207\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-45987.52978515625\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1221.037479352951\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-434.4333000898361\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-293.7569829106331\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-792.8697683334351\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1179.3381533622742\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-874.1428160190582\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:86.38557197004558\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:46.03418793417513\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:54.49314904510976\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:71.66916673481465\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:83.05438648387789\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:56.68902984261513\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:79.77632318474352\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:95.39157924260944\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:92.20516399890184\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:95.74333345927299\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:95.4131298808381\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:83.77697333358228\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:81.63012261092662\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:79.45539860948921\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:80.28377275019885\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:95.33253304697573\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:70.1484585598111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:93.55795316519216\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:90.49453116673976\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:76.45656509138644\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:79.6899037361145\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:93.11490184888244\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:95.31438716780394\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:94.11559441629798\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-27333.330052185054\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-24569.844057464597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-41828.83296356201\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-54158.52931671143\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-33314.59376754761\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-64898.92909545898\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-363.8358931064606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-85.66294025778771\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-353.88592948392034\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-309.0725207209587\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-248.27511982321738\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-14.194803553819657\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:91.1327129010111\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:86.53741862699388\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:92.03901602216065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:95.45305235162378\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.1158397346735\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:82.10810397639871\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:85.36697327941656\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.675663775485\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:90.93770260065794\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:96.0796229209751\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:91.7880104959011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.20891681946814\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:93.41428251042963\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:63.935590126365426\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:83.60247823521495\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:64.70540026798844\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:62.24168507009744\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:88.19003975726663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:70.56070654019713\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:92.0769947241526\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:48.81954134553671\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:87.1843748703599\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:90.15167440138757\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:85.38502670694143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-7492.883110046387\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-17555.105380249024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-22369.189349365235\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-11710.599142456054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-17120.86676154137\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-18419.46195898056\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:32.70707555115223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-137.90416301488878\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2.4221989750862205\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-3.1201559543609703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-85.74552427530288\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:25.15465757846832\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:96.64495082944632\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:92.19090578500182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:96.12768372669815\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:95.06342274527996\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:93.61430101552978\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.11722865011542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:95.9396872252226\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.85798595026135\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.40487241186202\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:92.76103617101907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:90.45934326127171\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:94.27663036379963\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:90.45083474367857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:90.30014252662659\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:80.65208277329803\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:85.97615702524782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:91.0013118930161\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:60.20454490929842\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:73.04953129068016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:58.13805467188358\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:73.09640225619079\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:87.01251939982176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:85.41039927005768\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:94.32637970801443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-9818.855208206176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-11203.519174194336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4339.8723361969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-5419.062216567993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-10944.197995567321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-5557.359802937508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:73.00800843238831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:42.02183706760406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:66.72568299770354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:49.76515092849731\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:68.55913418531418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:47.135837006568906\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:99.20165999010206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.67868154544848\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.45071946876124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.47722246609628\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.40077424789779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.61159701049328\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:97.4493598036468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.22146929576992\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.0696293078363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.10549237616361\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.52386274859309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:95.09811720252037\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:87.97744809538126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.16210339572281\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:93.4858384538442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:92.97750171339139\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.63603283837438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:93.49250999316573\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:82.90461182296276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:78.53347771987319\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:93.91590367406607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:75.19541032537818\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:90.01143382489681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:88.09066338874399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-210.14979572296144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-347.004301071167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-7654.593060684203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-34.50088100433351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-9300.618222045898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-510.1205184936523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:93.4266733288765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:94.85670957565307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:95.13944631814957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:91.28650552034378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:90.42101793289184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:91.85368303060531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.6874098431319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.78011469952762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.63115782625974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.68692161142826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.36755219474435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.35401144772767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.51653827447444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.65262002944947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.4661494102329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.63532960042357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.58102653771638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.58083410039545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:96.56258177589625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:94.78852258790285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:95.6250086190179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:95.07536867000162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.84744821824134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.17224746569991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:70.12496882528066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:83.15412318706512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:90.95535421669483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:94.93587413188071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:92.54272272326051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:88.77047792933881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:99.30362281799316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:73.30431022644042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:41.40794191360474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:95.59401819109917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-853.4978964805603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-4351.410453033447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:96.44385447502137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.89452188014984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:94.3725937128067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:99.80910366773605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.66972247362136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:97.94946520328521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.78401894122362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.79152765907348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.74161022640764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.77583694979548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.74967095479369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.77162196338176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.73579414952546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.73388157375157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.72376096919179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.6905187085271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.68542068302632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.72386197242886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.18258232064545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.03878909796477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.00564023852348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:97.05172132421285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.17797398716212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.23301946874707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:95.45066666342318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:83.94866274222733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:71.70051743611694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:95.65921717956662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:89.05469875521958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.51926044672727\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-47761.416710472105\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-287651.91643819807\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-6420.225370168686\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-66625.99039859771\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-94284.15935077667\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-32575.263930892943\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-112.94043366760013\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1785.1003799170253\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-122.43149755597113\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-412.80199375748634\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-250.84469804018735\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-800.5119105026125\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:86.96752945631742\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:80.63611271828412\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:81.29491065256298\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:81.97613377794623\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:73.78440995151176\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:64.53177419900894\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.16290174424648\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:71.00287460312246\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:90.67696222811938\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:86.149360853713\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:69.26096268333495\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:81.74181576892734\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:63.98875986337662\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:78.42433059439064\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:75.47714386116712\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:78.38207742013037\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:81.8678221181035\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:84.8780622549355\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:84.04267569128424\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:86.85092625133693\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:55.3259661860764\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:56.82419401854277\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:61.70329454764724\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:78.84012545421719\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-113427.38929462433\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-79139.17624530791\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-57551.82875099182\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-85621.5212020874\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-82323.44205350876\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-87831.36724472046\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-280.73660360574723\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-536.802535957098\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-635.7230408638716\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-676.3089920520782\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-643.0052962243557\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-396.371360912919\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:91.63617963399739\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:94.73949831165373\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:93.43007385395468\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:89.57501584086567\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:92.38084672871045\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:90.50637978240847\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:91.67212907038629\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:92.0151419095695\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:92.7070971403271\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:94.08813870269806\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:91.1423132413067\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:93.99963439889251\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:84.62489729337395\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:88.24762438759208\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:66.70537108182909\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:44.57317862845957\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.74894551485776\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:83.9149363067001\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:42.57716495022178\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:80.1171722047031\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:82.49669782780111\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:63.07325939387083\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:77.68640647595748\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:86.1324345418485\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-27003.207603454593\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-20928.64843606949\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-24210.420749139786\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-29650.97485237122\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-11673.434124565125\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-28727.434589576722\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-116.74639523029326\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-76.07876411676406\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-114.05557163953782\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-50.785006147623065\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-55.512443295121194\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-230.2445164382458\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:95.71383680717554\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:94.89456593170762\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.98699099831282\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:97.69576986692846\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.20274283774197\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:97.07036528249738\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.1100802563131\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.92064987830817\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.2896694511175\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.26197735100868\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.46220857910812\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.22197976731695\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:84.48417961671947\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:83.46703495215625\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:84.57314070072024\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:89.65768371894956\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:92.38146885912866\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:91.62029731795191\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:91.47697893306614\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:74.97117685545236\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:84.92556016333401\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:79.6804499283433\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:47.73745160922408\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:69.62527315206826\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-8356.680504417418\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5976.829219007493\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5517.5267719268795\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-8821.907382178308\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3635.7708395004274\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-6937.769935798644\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:25.469655561447148\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:22.944320771098138\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:21.153679326176643\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:53.29699138104915\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-58.52628560066224\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:44.026083779335025\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.55000615715981\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.30974540524184\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.02795947231353\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:97.89655274730175\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.15985680222511\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.1548799396027\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:99.10867501944304\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.91648828461767\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.25665879342705\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.44376289099455\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.05798868350685\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.76157217025757\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:86.20373361632228\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.16308601442725\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.77706103716046\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.1712065118365\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:95.11203735396266\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.32986969910561\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:27.05545862168074\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:86.3017976809293\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:91.89702079854905\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:91.24050593264401\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:86.89063890636899\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:91.63317241817712\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-150.25962337851527\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-141.68090400695797\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-399.1008866786957\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1231.805003643036\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-165.6264078140259\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-261.79502363204955\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:90.20776192396879\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:65.9297396980226\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:83.53643543422223\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:90.20108398199082\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:91.07652754187583\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:77.25162224769593\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.22753161974252\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.5506269030273\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:98.48792284876107\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.62004672959446\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.62284639608116\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.65741205140948\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.14934059120715\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.2759632974863\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.51197705045342\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.31425141841174\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.49636572673917\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.02124374732375\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.58569464609027\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.76564642996527\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:96.80340710859745\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:95.82029452100396\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:96.34536832757294\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:95.17069356478751\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:44.400004147738215\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:86.56239893985912\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:90.13959839032032\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:92.50788590200246\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:80.9869021628052\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:90.17356930486858\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:91.43706169128419\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:91.31509056091308\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:48.98393061161042\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:82.93813934326172\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:63.97291526794433\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:90.31053853034973\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:88.13914375901221\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:90.43836408853531\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:92.10503625869751\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:91.18785965442657\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:90.92760680913925\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:97.2158891916275\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.25897770933807\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.74363386482\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.69872633479535\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.62838424574583\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:95.41146470606327\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.65775547102093\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.66754450835288\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.72545229494571\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.7257325232029\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.65521899238229\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.55360960587859\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.68156157284976\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.36565631362609\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.04214356094599\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.01909379810094\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.93280240632593\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.523866051808\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.72676706537604\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:93.56857231855392\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:81.71806199625135\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:91.58481231257319\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:86.01007204093038\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:91.25099731199442\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:89.84263890348375\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-197263.1787475586\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-186589.22225341797\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-333948.8653808594\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-331234.4778930664\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-882582.9951660157\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-331557.2316894531\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-4274.573768424987\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-258.23609282970426\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1600.5151168346406\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-4121.2345870971685\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-2260.811424922943\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-898.6987753391265\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-89.64015286564826\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-140.03042018413544\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-60.791721701622016\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-36.538617962598806\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-150.71437433958056\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-213.0934693098068\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:94.83682390339673\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:80.54539528638125\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:85.21617483720183\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:93.69597595632077\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:93.74457525033503\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:93.23779185879975\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:89.1589913520962\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:93.33157990165056\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:68.20746700465679\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:90.13447487726808\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:68.94256261959673\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:92.31594034396112\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:94.02414391685743\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:64.47374191060662\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:91.43523241523653\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:83.38340055011213\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:90.09810418896377\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:94.29337602630258\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-65420.47044138908\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-474431.3675201416\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-54665.922189092635\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-360785.496685791\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-128040.67402207851\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-149359.84841156006\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-3757.84399137497\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1763.9611401557922\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-4296.770112800598\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-3775.459786748886\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-4560.089967632294\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-4104.495512676239\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:57.08941946178674\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:52.00936250686645\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.86222101151944\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:36.72547176033258\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:51.69039497971535\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:44.58034668862819\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:90.56406131517141\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:93.79308160524815\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:88.91592518389226\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:83.58760827742518\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:90.5571681091562\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:88.22205020561815\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:89.93401097096503\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:95.27062006667256\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:93.53991432199254\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:94.9125256843865\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:95.2844302393496\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:94.24494092073292\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:89.72176732234657\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:86.28711193073542\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:93.42076134830714\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:81.85347390137613\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:65.13324899077415\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:73.99119917526842\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-138140.1685119629\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-33057.413067626956\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-118287.3210334778\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-150380.46470947267\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-69576.82185153961\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-45755.81427545547\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-594.5093438625336\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1613.5342747211457\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-388.4781216144562\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-349.86041636466985\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1271.5133860826493\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-856.7359315872192\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:72.42626347839833\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:96.06989320516585\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.54114970453084\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:79.06090101599693\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:84.73498929738999\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:92.66174086779357\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.5335941426456\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:93.59349147453904\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.38987492397428\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.23695336207747\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.5208669993095\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.50880929660052\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:93.90567561537027\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:95.0167980261147\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:94.68607852458953\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:91.61359078660607\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:93.65591843463481\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:95.29490919634699\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:73.10911786034704\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:87.2743233518675\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:93.620941620972\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:61.58127919435501\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:72.04101085532457\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:65.27155221812426\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-15628.06665248871\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-37148.01685123443\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-10079.297623348237\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-4754.104482650757\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-52942.908467102054\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-34494.52693748474\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-124.98353455066682\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:37.61732490062714\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-152.0359633922577\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-84.41573860645295\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-81.80475463867187\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-38.452826237678515\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:96.32406510263681\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:93.41588818132878\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.28720062077045\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:95.26861027553679\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:95.79737055972218\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:95.80184152051807\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.33272776082158\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.62336873983732\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.4856869265437\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.32716885842383\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.00660620257258\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.7951198812574\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:95.05431467965245\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:96.40208389759064\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.63858650363981\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:96.71780302375555\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.45731308404356\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.47965995594859\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:85.86780258323998\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:79.05951724909247\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:82.0635913785547\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:70.25642601773143\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:67.56060578636824\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:92.76886904548228\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-826.1992493629455\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1875.9113302230833\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2428.5685230255126\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2682.055315685272\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-3523.4503721237184\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2795.5310167312623\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:84.50676352977753\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:80.64090731143952\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:89.50825569629669\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:78.48646609783172\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-277.16866036653516\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:74.91927847862243\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.06540828794242\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.48140442967414\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.24156271666288\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.36070613414049\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.50192774496972\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.27584986686706\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.64034427721053\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.65019378876313\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.63006390668451\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.6580268137157\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.63238475397229\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.66702098101378\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:95.72792747020722\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.32204050999135\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.30782252270728\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:95.47496311292052\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.65676159560681\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.9486524278298\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.6683961495757\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:94.42927960939706\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:91.02627219371497\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:93.21354127414526\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:94.7820248330012\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.51408495819196\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-659.2105736732483\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-1015.3586467742921\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-1244.367771911621\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-29.407228660583495\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:18.57831306457519\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:67.1208571434021\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:97.75487698316574\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:94.28106684684754\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:98.6136135816574\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:97.12077755928038\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:98.73580260276795\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:97.72007771730424\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.40390140116214\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.57226750254631\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.59423738829791\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.47621694654227\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.70533522516489\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.52088558226824\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.71226503551006\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.71212298907339\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.70612819343805\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.71301292143761\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.68054905766621\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.7183608867228\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.35347529277206\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.28147151321173\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.36365079283715\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.6150702290237\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.75933298654854\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.47986892461776\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.82721473127603\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:94.02506622597575\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:94.10023359246551\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:93.8258496383205\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:95.54496142603458\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:82.395925289765\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-3714028.7196166995\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-231259.10643196106\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-449237.6383666992\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-1852688.0421722413\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-5501387.838482666\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-8196762.690551758\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-9130.54188632965\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2877.943359491229\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2941.2868608236313\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2497.40179502964\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-10680.085165596009\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-3360.6432474195954\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-33.139758136868465\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:78.23427161425352\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:24.67142328098416\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:16.562971253693103\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:65.296373101091\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:39.00227468013764\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:83.6223653446883\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:92.56141700297594\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:86.79139424450696\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:91.76633760370314\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:93.7147605742328\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:87.4728566115722\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:83.68618239834905\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:93.84457499459386\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:88.99296307377517\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:87.7827814521268\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:84.39403099492192\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:91.32194629823789\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:90.31685861721634\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:66.72332047708332\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:82.03042803313582\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:80.88447150699794\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:87.53586126589217\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:72.06636330857873\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-5755035.812946225\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-5345943.96473751\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-541733.9028320312\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-1916550.3393558979\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-4568783.100163126\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-2994202.6314255237\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-3241.178737592697\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-4144.251483917236\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1830.4395875558257\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-724.4532281011343\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-3134.394295603037\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-6522.922736500203\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:78.93167445994914\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:89.70130051523448\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:87.45773934368044\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:79.3315434679389\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:82.26485866568981\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:88.37758580297232\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.73721697963774\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:96.71827961429955\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:95.42392743974925\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:96.15130374040454\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:95.90224895179271\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:96.1694149877876\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:81.43574029244482\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:81.46817897632718\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:90.40582384169102\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:84.36050308905541\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:92.12114185541868\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:88.09508888088166\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:90.46125564267858\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:77.33122480362653\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:69.4656198810786\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:89.36178376150782\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:88.42386135999114\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:83.63668787125498\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-682055.6817537069\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-911971.5770696641\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-913164.1290609359\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-407829.63084869384\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-629485.9170473099\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-605740.1938064574\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2321.3391370058057\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-598.2190671443939\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-3040.5074686408043\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-783.9628141880036\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1255.8580355584622\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1249.9594641923904\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:94.46897039599716\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:96.02983879093081\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:96.10370798967779\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:95.16397831775248\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:92.24682189077139\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.25750706195831\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:98.13898053136654\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.956215106952\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.89664541329257\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:98.03771291188895\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.8499094441533\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.8767201513052\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:96.34222801607102\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:91.37449907865374\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:88.64803890008479\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:94.50422881245612\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:93.33898146115244\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:94.78961472697556\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:84.33993908800184\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:84.72383513189851\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:90.40760063752532\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:87.09044693075121\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:87.35849583782256\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:90.74540651366114\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-153084.13825359344\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-125824.01737003327\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-167395.02623653412\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-80939.49270396231\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-483835.8645992279\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-106802.4452987671\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:86.975093460083\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-748.4160376310349\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-247.33292870521547\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-248.76042523384095\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-140.22330625653265\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-79.1326339840889\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:95.762182787247\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.42168440595269\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.93917030841112\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.63686972409486\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.55750885307789\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:99.02206410774961\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.71624191626907\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.07497414164244\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.79392920229584\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.24493589974009\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.24345810031518\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.08569105267524\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.60961737558246\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.8812361408025\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:93.99279769733549\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:96.1846018422395\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:91.85994554720818\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.14577630832791\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:71.33067138716578\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:91.71232354864478\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:92.6883507154882\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:82.11150911673903\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:91.81423080451788\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:82.53455669516697\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-10507.888198852539\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-5998.5064929962155\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-23305.14520072937\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-10451.890460968018\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-16140.320130348206\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-15036.455811488628\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:55.896644830703735\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:39.43048313558102\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:83.92284237742425\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-7.796092718839653\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:70.04341084957123\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-65.72932797670363\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.42663887664676\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.5262384980917\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.59759362190962\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.52323708105833\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.33263840493746\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.556324804225\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.30846824850887\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.28358805179596\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.44723046272993\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.44875530414284\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.36673134099692\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.35923196058721\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:95.85221630223096\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.50008518993855\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.20344317257404\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:95.39962446056306\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:97.64532842319458\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:96.46718479990959\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:86.7104438956827\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:76.32759323902428\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:90.65268347803503\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:95.48727492876351\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:90.49863301925362\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:90.7483253796585\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-228.91239055395127\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-2133.6733047485354\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-33797.80358695984\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-8714.281267976761\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-4993.08763422966\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-10383.509943199158\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:83.80829548239707\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:81.30104468911887\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:88.05676807165146\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:88.69431534111499\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.58723330497742\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.69753794968129\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.68755671977996\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.569271492213\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.76658471822739\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:98.46908709481359\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.70360575988889\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.75547655373812\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.67098984792828\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.60268075466156\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.44854378215967\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.53696854138688\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.53463342571631\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.62830399498344\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.85396772846579\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.72366091944276\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:97.91098785996437\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.87500862628221\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.55476203057914\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.58464383780957\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:89.73297329768538\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:93.55788964554668\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:88.7686796080321\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:90.97052190667019\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:90.30863153063692\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.97441725227982\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-72400.33407287598\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-6846.004223632812\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-72916.99873962402\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-108925.99739131927\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-78402.1113697052\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-7064.721557235718\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:57.85452715158462\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-245.05478353500365\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-12.650661778450022\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-942.5435252666473\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-125.09944434165953\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-211.3435598373413\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:31.316214308142666\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:64.36568674743175\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:43.89006408602\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:46.99279694259167\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:47.414988473057754\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:35.30111012607813\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:92.25662330575287\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:61.09842270910739\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:96.29073070036247\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:96.05333335865289\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:92.97393481619656\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:90.00091583225877\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:63.93761674910784\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:79.14391949176789\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:74.84623989388346\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:80.7305570539087\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:84.0377612259239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:71.03112297579645\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:91.87378902249039\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:66.41926447153091\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:72.61574806571008\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:68.96235227733851\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:82.5638837069273\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:84.64549514353276\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-86094.66485743523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-65838.66985549926\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-33678.342098999026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-21787.874606895446\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-20133.336484241485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-36561.032198715206\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-47.847158098220824\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-579.4931476831435\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-658.4309689044952\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-474.4694114685059\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-479.9270806610584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1168.4798527717592\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:80.61824540272356\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:87.41040404327214\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:89.09774799495935\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:90.68316085096448\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:83.12626639679075\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:85.05377567261458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:86.95874406620861\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:90.9957222931087\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:90.71587052084506\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:96.63602079190315\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:96.43971434906125\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:94.38506828360259\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:87.69648279044777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:86.02490358762442\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:92.80787337310612\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:96.06396922916174\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:94.90971231237054\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:88.20603641010821\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:67.24879098385573\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:78.3337115779519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:77.10525199845432\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:88.98779441621154\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:76.55836491659284\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:87.99249913915992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-41448.851424407956\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-32803.22879419327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-19895.370336341857\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-45949.99870147705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-12433.281567001342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-33224.95782470703\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-189.4363934725523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-136.0718040406704\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-167.26297841072082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-263.1302502632141\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-174.19655361175538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-168.1355672121048\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:94.1635361643508\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:93.16777218095959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:93.12119512204082\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:98.13977912287228\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.4272577341646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:95.87291929870844\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.49644050449133\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.36825065733865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.44509530067444\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.51589655335992\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.18980865497142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.9319503992796\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:91.16353396326303\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:77.09303184077143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:92.66120725981891\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:94.43474903404713\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:90.7650937024504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:92.18655257169158\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:78.50802125930785\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:73.6076061733067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:86.83788782749325\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:83.99380971454084\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:93.82482102308423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:87.93195504993201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-17504.32081737518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-10199.58414440155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4919.760774230957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-9406.414003372192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-14625.055092239378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-4453.210784721375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-256.27030045092107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-785.0224699020386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:57.27535257935523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-104.43723254799843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:74.80813438892365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-46.23565783500672\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:97.57387382499874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.83244818868116\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.69512711735442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:97.58263557683676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:99.13327191676944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.51895400695503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.94109118431807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.22759119346738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.00190151706339\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.31810022369028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.18870156295597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.3727020777762\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:94.39638588130475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.00034730061888\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.71769081670791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:94.65815203040839\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.70289976913482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.78111458811908\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:93.94842849448324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:93.743108473951\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:95.54858491248451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:93.69334351047873\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:85.75972291119398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:77.85214910358191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-33447.63607597351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-3661.890737915039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-21880.515460968018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1012.0552331924438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-560.5946865081787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-754.0868232727051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:89.66394385099412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:92.28415337800979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:93.16898663043975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-175.52498223185538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:82.67841255664825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:95.99427962005139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.67889961766777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.73130832128227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.70571464896202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.67422046661378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.70898341163993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.62536922097206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.50722914040088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.62370639368892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.6019153685309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.51973927617072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.6098503522575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.61458554118872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:96.61151889730245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:95.5563905633986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.81106038764119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:95.1714192679152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.96278506089001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.83580720610917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:84.03482894040644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:84.35155437402427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:84.30832565166057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:92.6549587795511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:91.81491227187216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:91.27322698924691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:91.72122173309326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:87.49446258544921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:29.72523689270019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:83.43809127807617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:65.73701934814453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:42.18876762390137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:96.980716919899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:98.83100266456604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:51.51371054649353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:94.15777988433838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:94.05950423479081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:99.29279495477677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.72080343365668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.75455278083683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.70286847408862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.75368619132787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.74771572723985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.76325006783009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.70200702995062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.70712559297681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.7140002992004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.70480705872178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.71780287176371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.71631542146206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.88755435720086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.81129857636988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:97.57588092014193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.27474452033638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:97.9458592351526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.83475394137203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:92.76656753867864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:89.53040850162506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:94.20817385381088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:81.95943890661002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:93.15402210876346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:85.43382700942456\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-93350.99671931268\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-425383.6389038086\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-117815.17953062057\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-191725.77182431222\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-58233.60899572373\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-99230.71951556206\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-195.2965486258268\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-139.87081560194494\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-895.6266645610333\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-842.7073056727648\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1740.247758179903\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-4038.5610052615407\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:59.11805088482798\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:44.99006818849593\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:40.96363329254091\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:72.76943111810833\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:54.6590766955167\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:54.73095661476255\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:90.57009712392464\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:77.14875284321606\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:90.1575572565198\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:86.89766959045082\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:88.45158105809242\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:86.56377001702785\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:89.41525531169027\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:79.0270369154401\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:85.36887760981917\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:79.28663192600943\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:85.29870701376349\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:80.08457518331707\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:84.55952135641127\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:86.82487606446375\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:58.54653115570545\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:77.88244718965143\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:85.05227758074179\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:68.86127654090524\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-199098.4757472992\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-498824.19855918887\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-352577.57666072843\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-375707.33256802557\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-201663.0344959259\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-191940.3813199997\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1546.7299019575119\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-3465.947942316532\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1672.7979819774628\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2619.052802026272\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-4102.333044147491\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3018.11567414999\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:88.06327623017131\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:80.3521180074662\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:86.8592633292079\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:82.8814254797995\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:87.88652688749134\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:88.18446539547294\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:96.00106079373508\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.7606389693916\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.98351527638734\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:94.95753305628895\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.76777498982847\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:96.05411064475776\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:82.56869036071002\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:77.44010071679949\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:87.02371575832368\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:67.51790070123971\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:84.67424785066396\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:73.16461817435919\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:69.93095485046506\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:73.33162034265696\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:89.23352700653486\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:83.82872383743525\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:85.3777401946485\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:72.26292338762433\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-48478.42338638306\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-93894.63613090516\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-45335.27821779251\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-146094.35921535493\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-200783.32217559815\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-122781.1339782715\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-735.2646697282792\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-610.8426625370979\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1027.1563180565836\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1170.9995292186736\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-964.8222467422486\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-710.1398205518722\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:91.38662345875055\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:90.53391588144004\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:93.35051198676229\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:92.8021180484444\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:92.82641060128807\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:93.77609785497188\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:98.07065130788833\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.85337090156972\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:98.39308531545102\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.9762665597722\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:98.30631389096379\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.16621798519046\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:95.80537469945848\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:93.3652288186364\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:94.29175992682576\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:93.56665604487061\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:95.88825781308114\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:89.48409034796059\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:69.79796328097582\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:73.46341157555581\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:83.51390882097185\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:90.48022372573614\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:87.20869479444809\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:89.9723905801773\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-32644.264427185062\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-29050.602559661864\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-15923.975679588319\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-19646.558441543577\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-8825.660121631623\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-25988.442616271972\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-107.86195808649062\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:44.3885138452053\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-29.172125315666197\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-44.230588579177855\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-89.80027932226658\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-7.551231139898307\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:97.14245087355376\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:96.92169472798705\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.10357209537179\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:96.5118403494358\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.49504481926562\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.34482849128544\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.9316888347268\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.81415463387965\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.08895326294005\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.02501472234727\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.11307013523765\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.95698887333275\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:96.81660575270654\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:96.2340516615659\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:96.41055766846985\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.49892640169709\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.82554241586476\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:96.68308612965048\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:91.27630387526006\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:82.61701145311817\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:74.71742210630327\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:86.34119767434896\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:92.6549896284938\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:87.23404874885455\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-36792.07396755219\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2556.2430647850038\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-5375.688238716126\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-264.5773426294327\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1704.7295345306395\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2286.053024482727\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:70.88188736736775\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:85.3275102853775\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:71.51431196928024\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:81.80357556343078\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:77.69127357378602\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:76.79485456943512\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.12079042289406\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.47335624247789\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.40073970407248\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.12764833718538\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:98.81833237744868\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.13361791558563\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.31609666496514\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.4600334469229\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.37497247755527\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.52801364585757\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.40445491038264\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.46724669467658\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:98.29713789168746\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.29011845246423\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.36447434965521\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:99.06129760253243\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.4786153256893\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.38681955747306\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:87.70106832254679\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:79.97670200169087\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:92.39790375344455\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:91.44926518425346\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.68161743329838\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:84.1509113021195\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-533.0684695243835\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-473.5337852478027\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:37.059919911623\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-256.2630410194397\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:92.13541641235352\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-327.5752992630005\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:94.77611966356635\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:94.99764859117568\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:92.54261113386602\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:91.50474042892456\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:91.99879188537598\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:90.16583683490754\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.72701962217688\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.58861061036586\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.48333120457829\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.43501803390681\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.70420814752579\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.31569684837014\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.6199822243303\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.63575600706972\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.65629415486474\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.63376373387874\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.6494969341904\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.63435306549073\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.80351846031846\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.12457298710943\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.13836460504682\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.08714449107647\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.81135161016137\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.19130251444876\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.74401553058996\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:94.41689421758056\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:95.42141794078051\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:94.80650936467573\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:90.19693529494107\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:96.17303525265307\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-250679.87352619172\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-43351.89494018555\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-57761.91511230469\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-1261786.714794922\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-1285374.7174316407\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-730470.0901611327\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-6187.351204299926\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-9853.404486083984\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1350.3823699951172\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-5334.322117424012\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1003.1800200462341\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-3916.654521369934\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-487.6455332517624\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-610.6081110477447\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-361.4832229852676\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-331.0903617024421\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-412.8748601675033\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-516.3042748689652\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:58.41772927939892\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.63091905415058\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:78.1854179918766\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:37.87081629037857\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:85.79986936571076\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.97345402240753\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:90.029118546471\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:81.07513559162616\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:93.35431589409708\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:93.4173974601552\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:92.86718534715473\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:84.44813305009157\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:83.15049148462712\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:88.30838458910584\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:92.0308297178708\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:91.2941347291693\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:90.16938600782305\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:81.4742723826319\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-1119554.1718200685\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-146982.11979460716\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-990482.0985961915\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-427803.6669974327\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-701318.2546281337\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-311422.8613523007\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-18337.595910167696\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-6265.853328466415\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-4960.664994144439\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-10845.410357284545\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1416.3850655715912\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-9843.211259269714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:3.9251985132694234\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-76.42301481962204\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-96.23749696016313\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:-5.130965572595603\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:18.52151359319687\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-2.46254141926765\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:81.11361424028874\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:88.75734095424413\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:76.39523562490939\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:75.69216231182217\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:82.47532514184714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:82.59368802085518\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:90.49098411053419\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:93.00288204103708\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:90.49737137723714\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:95.07372160013765\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:81.91797652766108\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:94.492928393092\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:81.36663636788725\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:93.86007654648274\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:76.11467095427216\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:90.39980471562595\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:73.4595577698201\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:92.86250296141952\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-65796.37697906494\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-111706.16841812135\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-270042.1945877075\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-223521.154650116\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-480196.41898956295\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-536141.8733879089\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-907.5890268087386\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2725.1982625484466\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1648.7062705039978\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-3945.6798625469205\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1109.5877624511718\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-2216.307048434019\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:8.230827850103385\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:74.26666984185577\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:80.9725290119648\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:71.66413867548108\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:53.241458715498446\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:36.49401228427887\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:93.29456555508078\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:91.27559803840704\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.4687376273796\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:92.86437052190304\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.38214748874306\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:93.79873030185699\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:91.90067280046642\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:96.51655333712696\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:94.2161690659821\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:94.6656334720552\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:94.93717378037981\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:94.47374628679826\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:92.43243970265613\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:92.89564460366965\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:91.79066009540111\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:92.60727788992226\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:66.7468545615673\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:87.5859804019332\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-107933.01380310059\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-33543.45020046234\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-61396.45661239624\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-58283.85723609924\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-27558.785364151005\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-117281.59578933717\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-834.5213543117046\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-428.0892693281173\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-376.2361582994461\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-558.968174612522\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-1690.098457479477\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-240.1910583615303\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:88.85985963046551\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:85.1345026731491\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:96.75933621525765\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:81.62277898788453\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:91.57468663454056\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:93.15735530555249\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:97.6446765869856\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:97.92254933807999\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.1527688242495\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.13594760335982\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.29803135432303\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.09556160923093\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:96.52410208396614\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.95396496285684\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:96.11304505746811\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:95.91414252594113\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:95.66485519520938\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.17494703810662\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:92.75807324266061\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:93.9701519239694\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:88.89345294050872\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:93.58611973412336\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:92.56157858558\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:93.4945072133094\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-2767.6715560913085\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-8004.083054733276\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-6711.696063423156\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2200.5984672546388\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-10335.054845428467\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-14302.331763648988\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:24.522037231922145\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:16.175363528728482\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:81.26351337432861\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:70.82746567726134\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:73.73803095817566\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-36.756944668293\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.05228649303317\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:97.84835708588362\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:98.32607141435147\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:98.3362076625228\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.01523594707251\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.68404060155154\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.64957007505\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.58399604558946\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.62833250798285\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.67553134933114\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.63781565204263\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.66410203911364\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:95.90168514363468\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.10099608153105\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:96.85856431387366\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.85672030355781\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:97.78127080202103\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:97.88066679351031\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.99449902568013\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:87.55309005975724\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:94.68809917196631\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:94.53755694888532\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:94.23693743534386\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.62759026437998\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-324.3209845781326\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-1199.7991199493408\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-3331.4362661361693\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:80.5109088897705\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-2077.66838760376\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-264.0580304145813\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:84.4926052212715\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:85.51587715148926\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.24271562099456\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:89.33534548282623\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:90.34546189308166\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:75.15723440647125\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.318047118932\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.5311100885272\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.51105439662933\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.1825004003942\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.3029945641756\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.3455677062273\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.72682003378867\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.69177624434232\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.73330345824361\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.71978918462992\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.72401205003261\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.72747036889196\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.53327589100228\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.47962868697941\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.52513176370412\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.40884198285639\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.50613415688277\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.34842181876303\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:96.7761597201228\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:95.70287952916696\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:95.85802683369256\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:93.49708795510232\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:94.02228728756309\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.6760999079328\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-21549237.290163424\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-17016496.51421261\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-1384529.155432129\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-7462696.332714844\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-25837913.134179685\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1701275.5946411132\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-14301.677595591545\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-33722.90755653381\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-17172.377204281092\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-15160.949774932862\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-20106.26520872116\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-23229.64298686981\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-88.03506992161275\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-149.31023632884023\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-163.82383586764337\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:38.00801111608744\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-12.328086267784233\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-148.04865068197248\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:77.41059120856225\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:75.42197490800172\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:88.6941239638254\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:92.02565155550838\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:79.17645964268594\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:83.78493464076891\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:91.23135377075523\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:89.63767855400219\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:91.06198977287858\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:90.70335431937129\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:88.71703173220158\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:92.77780176475645\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:83.97083321595564\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:83.14858073974028\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:89.77587028890848\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:79.584452278167\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:78.9259531185031\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:75.7348118338734\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-6170643.682705497\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-17035007.878302004\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-26383615.891333006\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-14286921.879528236\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-20669547.49165039\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-17578198.767178345\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-31145.398031997676\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-15773.569384488463\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2770.811350107193\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-17178.170679998395\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-29746.742258358\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-18649.85702176094\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:67.6122120346874\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:65.47473732605576\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.55755040235817\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:73.37443556189537\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:41.47667894288898\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:69.9812152095139\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.00021748798899\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:96.52371641388163\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:97.51374417776242\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:96.39299190919847\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:96.65238213129341\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:96.78600648101418\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:92.7571058661677\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:93.00837687905877\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:91.69283860661089\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:94.71281703589483\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:89.57496070507915\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:91.01769297951833\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:71.33430261462928\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:89.25261087752878\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:79.71978774983435\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:78.3932848136872\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:76.69881439693272\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:62.350425706803804\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-2451240.640394592\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-4105361.9599586483\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-3093797.941325378\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-8510006.792210389\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3858830.387322235\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-3022066.668003845\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-4663.709498119354\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-4483.7760222248735\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-6533.992980617285\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-11028.462653017044\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-3768.731909549236\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1871.977613043785\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:79.79388611242175\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:84.49070886671544\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:80.4466872163117\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:92.47620938643813\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:89.35991862155497\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:84.3696761444211\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.75348312593997\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:98.29954493492842\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.94034200571477\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.8980000225827\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:98.30486825183033\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.55565247330814\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:96.32320220712572\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:93.7390669921413\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:95.5687398467213\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:95.67639267891646\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:94.24032584484667\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:96.16037255411503\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:92.25584727562965\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:82.34436896648259\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:90.37053668126464\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:81.44473680276424\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:89.09266884345561\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:85.81138476990164\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-768672.6148687364\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-316759.1354980469\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-469549.2183637619\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1421451.2872642516\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-438034.59384841914\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-469865.57952690125\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-797.1371227115393\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-1282.509754049778\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-575.2175777077674\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-1009.5539015829564\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-1016.944039696455\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1067.1427902638914\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.02456409186124\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:95.74778705425561\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.61821693666279\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:96.80494728386402\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:96.04002450704574\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:95.32357161045074\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.9302979436703\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.2001249205321\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.90248745428399\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.581750711333\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.09459231486544\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.12441557573038\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:97.26865197252482\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:96.76399095579981\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:97.20431943386794\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.15451083285734\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:96.85478838440031\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:95.78803178593517\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:89.11146306060255\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:92.16643235487864\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:90.60214245952666\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:92.01866132733412\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:92.76783446790651\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:86.24731350578368\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-46181.59587631226\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-174180.44304676057\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-285833.6523521423\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-151424.12987270355\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-55406.58099060058\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-13011.100438117981\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-17.75000298619269\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-218.59865266084674\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-91.76288318634033\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-132.851713269949\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:38.43934824466705\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-136.19087088108063\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.30830714032054\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.54246147712693\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.28412338607014\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.19113300926983\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.19743969887494\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.03568845130503\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.37960827760398\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.44894079491496\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.35657366309314\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.36859487183392\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.16028105095029\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.31859420118853\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.45725511666387\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.56354588083923\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.60470267897472\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.08628045469523\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:97.68641964122654\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.46358109023421\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.25077036842704\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:94.72176236510276\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:85.93331264257431\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:86.90429078489542\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.15536739332602\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:94.01961229266598\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-2015.3775993347167\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-31868.15264492035\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-13546.255660438539\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-216655.43219718934\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-7309.835087776184\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-30770.284460830688\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:82.18990647792816\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-5.2882002890110025\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:60.32304911762476\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:77.97869639992714\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.1921200349927\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:49.69846286177635\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.64440793246031\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.43892616638914\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.59843420386314\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.44227025955915\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.48585128188134\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.56019886955619\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.5180830527097\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.5788886681199\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.58228640626184\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.57942952923476\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.555613161996\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.51688845995814\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.7586114938371\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.98756321966648\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.88202108573168\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.86615864513442\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.1439559519291\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.39184706397354\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:95.68480470404029\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:94.74469895735383\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:95.24449393060058\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:95.77853839769959\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:96.90169846415519\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:96.33079959172755\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-45123.42942905426\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-111448.24790649413\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-70367.5070098877\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-30745.120623779298\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-70877.71856384276\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-9014.9381149292\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1153.7155734539033\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-476.3594069957733\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-51.52547025680543\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-530.5609700918197\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-366.6978830218315\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1549.1233296871187\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-3.8588218063116075\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:27.391431996226313\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:17.780393987894062\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-2.367831560969358\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:10.73280162513256\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:11.328829485177994\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:94.03661564886569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:96.01587710008025\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:88.34229737520218\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:88.89812806863337\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:95.78385382145643\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:89.9331798452884\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:74.64960239604115\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:72.01703883856536\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:88.79869835767894\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:93.72757287994027\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:86.82211707010865\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:94.26082154195757\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:86.95193314254284\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:95.36398718799465\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:92.20683528697118\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:92.97465586606413\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:91.29416844658553\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:92.69633399294689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-174030.50425720215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-213364.46000804898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-150046.68869419096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-92674.4134431839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-137878.57625198364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-143510.09288101198\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1601.596252155304\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-786.0423166632652\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-583.3923026382923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1155.087717115879\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-538.5670712530614\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-892.7750867724418\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:74.75039770007133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:76.80089470818639\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:71.93316963762044\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:80.90598556213081\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:81.19258322119714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:82.90839082486927\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.86875574626028\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.61124551575631\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.97244694670663\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:96.53943820204586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:95.34690343569963\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:96.21146332938224\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:81.6304220918566\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:95.0125511193648\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:94.17267346139997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:92.35703180124983\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:93.88896647710354\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:92.83291690349579\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:94.51761985160411\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:94.20409626588226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:93.40812502019106\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:95.86518212398514\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:87.5836052723229\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:81.67801383882761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-27874.03340549469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-19164.538838386536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-41524.24226436615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-84642.29457626343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-84349.24213943482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-31766.317908477784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-604.630589413643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-549.5304634064436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-246.2090042591095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-385.14859249591825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-418.6710983231664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-950.2262433052064\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:91.09392566448078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:97.22724274247885\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.43581077605486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:98.04638718292117\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.93695982918143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:97.25129089653493\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.7623351994902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.1201944143977\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.23713790364563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.49008056633176\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.6690236511873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.90262370007112\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:91.85253000631928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:94.19635493867099\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:95.05949875069783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:91.65201462227851\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:91.73439848124981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:93.7478430702351\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:93.74884802522138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:93.72348181130364\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:90.36964628938586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:83.73841042071581\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:87.73581951335072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:90.86591523448006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-25911.682752990724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-6311.358176994324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-30157.340580749515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-8151.110053443908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-17474.16816329956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-69239.14235229492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-133.2611421942711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-46.61597003936768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1665.0572716236115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:47.180548310279846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-285.47793647646904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-206.0594654083252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:96.447240562737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.71500237751752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.39958034157753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.42194828540087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.35333898887039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.97632382512093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:99.17326033301651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.24713000934571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.28973161168396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.26808792185038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.12840058393776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.17064083740115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:94.63210888030007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.19832646790893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:95.07582494579255\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:95.053044645302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.6723450794816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.24776843488216\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:86.13614853397011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:83.88268626742065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:83.16919231973588\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:86.46944509223104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:89.34541784375905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:91.21091031841934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1728.197024345398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-467.6088500022888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1368.0079641342163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-733.5339500427245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1201.7898601531983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-3045.9684389114377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:89.28572326898575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:23.667614257335668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:87.42815327644348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:81.5491719007492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:88.42224931716919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:72.90809540748596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.65803366154432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.67856274992228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.60562835782765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.60076733976602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.69470784887672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.61771636903286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.6599996753037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.63608982227743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.68153802407905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.60788796804846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.66600559074432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.64420790448784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:96.49601260852069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.2261702073738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.62896890416741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:94.91265465393663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:97.05380977764726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.3032399110496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:94.8278913166374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:90.90277909860015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:96.44941055849195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:96.15256872037425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.85103394798935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.99551291204989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:92.81081733703613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-1649.107783126831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:78.47662086486817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-12095.709252738952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-643.3142362594605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:97.28137187957763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:97.7469850063324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:95.54953863620757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:94.94639201164246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:96.14887900352478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:96.31123778820037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:97.12452552318574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.72524153217674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.73416675701738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.71841239035129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.72830807566643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.72900424916297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.72343666441739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.70749142915011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.72141776829957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.71689941547811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.70788857135922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.70698405681178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.71640078313648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.07135459072887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.47310286629944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.3848968190141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.46818218305708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.49536819756031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.40355117172003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.12017635488883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:93.44804576747119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:95.68014481961727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:94.09549225009978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:94.17819553092122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.31290972847492\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-111790.77997446062\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-83226.69943218231\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-552508.5888767242\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-110890.48656249046\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-671986.7592834473\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-562309.2485595703\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-8594.550132364035\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2548.3850276768208\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1054.246851849556\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-10656.340273612737\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-937.6419242918491\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-924.1770093873142\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-68.32974169636145\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-33.38653467763215\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-29.722281738184385\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:5.2503855891525735\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:39.17654671738856\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:46.99674030728638\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:87.16645438820123\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:91.36701433397829\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:87.94414978905115\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:88.77303947731853\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:92.0752944227308\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:93.4728104067035\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:81.90851104725152\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:70.02969596423209\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:79.64221963714809\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:88.68797928020358\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:85.04252764717675\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:86.67621782124041\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:80.27322403527796\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:79.20885529369116\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:87.64507506624795\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:83.72482500765473\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:87.14631041043322\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:77.74609983228147\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-721824.2007400513\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-1078207.4410346984\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-954144.3833400726\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-770682.3984695434\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-704562.1905021667\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-880866.3981800078\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-8526.573335158826\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-7275.25474408865\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-8599.860349744558\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-11825.94360678792\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-14681.897185993193\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-9921.69275251627\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:51.06288528889418\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:38.875268608704204\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:31.945763899199665\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:51.76860476136207\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:49.763108231499785\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-56.15813674479724\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.1212075535208\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:97.26885729269125\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:97.27652715370058\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.1160388530232\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:98.05632458431646\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.60318171512336\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:93.11527032656595\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:93.99558378430083\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:93.16368409609423\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:95.44608622398228\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:95.14018840231002\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:93.48351687006652\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:85.03098421320318\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:83.21359670585953\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:89.60306066535412\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:87.36981624662876\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:85.48043327135966\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:89.42446846934035\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-441043.31646347046\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-338339.57081604004\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-407373.5964946747\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-250128.19179782868\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-322746.3519390106\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-280877.9210609436\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-4667.858885300159\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-4923.787815976143\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2972.7861908316613\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2792.385177445412\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-4540.663280439377\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-3333.9719558000565\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:84.36662070341409\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:79.10529450029135\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:83.83859741687775\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:69.17379444371909\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:84.24188162889332\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.2802086994052\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.96794078340754\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.42760080974548\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:98.00630695251748\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.75501877330244\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.6879588931799\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:97.7203349897638\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:95.87122992333025\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:95.45869219605811\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:95.37285022176802\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:96.24485342800617\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:96.04270220422187\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:96.64544927887619\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:86.81703461352735\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:83.83296698462217\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:91.87214872408657\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:88.40430312938989\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:82.75338224489242\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:88.88081367202103\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-56666.46018972396\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-89387.63415660858\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-118262.1453895569\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-93229.55648880005\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-108011.62826805114\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-19834.961928367615\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-426.53928910493846\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-1170.365086507797\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-394.4500236153603\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-276.31230101585385\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-785.8068390965462\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-183.47191319465637\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:94.24669012539088\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:92.96613399367779\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:92.81964863575996\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:91.85324398288503\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:93.07812556996942\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:95.04595112651586\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:99.19213160015643\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.93765746569261\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.07819099444896\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.13618202600628\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.03054075483233\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.0466728400439\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:97.7921310260892\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:98.1107306019403\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:97.43204804845155\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.66510802395642\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:97.81155505161733\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.77804026687518\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:92.87331143785268\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:90.30216232463717\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:89.8005622560624\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:86.88354119677096\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:94.500489533972\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:89.27261627055705\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-4549.313961410522\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-6792.695386505127\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-6800.708687400818\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-6438.161020278931\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-5531.391124534607\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-9904.564644050597\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:46.453660583496095\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:21.65632527768612\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:27.387381574511526\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:58.33319003582\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-65.32491800785066\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:12.247570493817328\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:97.86388514079154\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:96.19268961697817\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:98.49586202427744\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:97.87113783173264\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:97.7124405947514\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.48753059282899\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.36006284039468\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.50195648036897\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.46747434996068\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.38718860801309\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.42760254591704\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.55449850894512\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:99.0664046868682\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:99.05660582445563\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.9457386109978\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:99.02743699215353\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.79382661096751\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.51455024490133\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:94.93364811781794\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:94.87842244300991\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:95.10069522280246\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:94.09521866068245\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.95736619438976\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.90842906720937\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-2260.5582651138307\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-2922.696151161194\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-2916.1722917556763\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-2801.2103008270265\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:90.6096965789795\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-2446.2235309600833\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:91.98900365829468\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:89.23225944042206\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:92.28964021205903\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:89.84062308147548\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:91.015704870224\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:86.0157551229\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:98.05915650203823\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:98.97999258264899\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:98.92471222430468\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:98.74865690805018\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.05511807259172\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:98.87753794118763\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.62191132735461\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.66479020896368\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.64304682910442\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.61664729788899\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.66324603036047\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.65348670533858\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.30560189615935\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.23926598355173\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.20720470137894\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.30481485687196\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.2417467225343\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.19777398360893\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:97.22321633324027\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:96.52528360299766\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:97.68364543840289\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:97.32583347670733\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:94.87591205779464\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:96.38761181607842\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-4921982.921679688\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-3726395.252050781\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-1443283.3697753905\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-3863888.9614257817\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-1821765.6592773437\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1151780.4816406248\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-21706.18988418579\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-16496.05167541504\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-22994.39094238281\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-4463.495100784301\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-9172.41635017395\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-14154.742023849489\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-1117.250905561447\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-1304.7208516597748\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-1417.5139130592345\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-1148.9645232677458\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-1201.4255549430848\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-1110.5023042201997\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:-24.10139362215995\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:2.9464034765958824\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:-15.80256384015084\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:-4.5843851327896035\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:-20.035347884893405\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:-37.764926695823675\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:92.43785097156652\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:92.30865158904345\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:91.4057349935174\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:83.08661102503538\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:93.72525130845605\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:84.90860021710395\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:90.68872037455439\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:88.45848391149194\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.07640681564808\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:87.8476161936036\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:89.96257820669562\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:76.00560463741421\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-3182112.013114929\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-2094228.32711792\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-5981227.647729493\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-2173290.519234085\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-5127290.81815691\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-4499933.953771972\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-22818.607295727732\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-8577.114163357764\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-58430.6050403595\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-18397.872806549072\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-16653.584709781408\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-41610.973558235164\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-119.26500165462492\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-572.1021284580231\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-504.9789113521576\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:-402.2671651124954\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-432.8511953830719\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-186.6826311588287\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:57.938275003433226\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:61.24385574236513\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:52.92208425849676\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:47.86084431260824\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:48.02490411698819\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.950954449921845\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:86.10928804352879\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:88.9946698848158\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:92.26862207213416\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:95.49506209380925\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:93.4503871860914\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:95.7184744624421\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:91.93798500075935\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:94.08027862492018\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:94.99538295473904\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:89.81408882602118\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:70.09841121137141\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:90.25454143472015\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1192158.618647194\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1077676.7293803215\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-950179.1213863373\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1640005.4047981263\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-2372051.85119257\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1439562.2555282593\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-11842.471939301491\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-20740.276127517223\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-3987.6466774821283\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-15014.75012638569\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-20185.70284562111\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-26568.639347195625\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:49.64140132069588\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:72.08450669646263\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:-100.16296810507774\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:75.33122020661831\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:-92.37388740181922\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:-90.14504389464855\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:84.33854649439454\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:79.6462003737688\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:91.40657370239497\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:89.79717376176268\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:81.006695766747\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:94.33711900636553\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:88.36923977844418\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:92.20949230327388\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:95.55136584192513\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:95.78589507043361\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:95.96654789913445\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:96.98435886260121\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:93.24115977026523\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:94.507161430642\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:92.23196290666237\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:94.3614443231374\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:95.02016904763877\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:93.205161018949\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-323604.07110779284\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-227744.4707496643\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-637614.2055297851\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-187819.0348838806\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-346544.8394832611\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-302761.3547008515\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-5577.952453064919\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-6678.98573923111\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1074.018586730957\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-4289.113835847377\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-1483.603925216198\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-4819.6968603134155\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:92.52559294700623\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:47.17297510504722\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:63.762590175867075\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:73.68194855302572\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:80.52809556722642\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:76.17871147990228\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:95.92543795804959\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:95.91796939689667\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:96.53275213148444\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:94.62054062690586\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:95.99797377092763\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:96.08818745166063\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:95.55456673428417\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:97.26239773025736\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:96.10333911832421\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:95.3766369137913\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:98.9276364022866\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.55190010722727\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:94.62512644156813\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:94.74251189464702\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:94.16671251282096\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:94.26272393092513\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:92.11575675643981\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:92.89126052875072\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-41315.147332477565\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-84789.72870521546\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-17042.197422027588\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-53066.77702941895\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-23267.634200286866\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-35813.48675521612\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-51.477680623531356\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-114.65985411405563\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-43.09042420387268\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-125.47859085798265\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-16.26266798973084\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-91.25490138530732\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:97.57412461489439\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.04439090043307\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:98.16037366241217\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:97.28282696101815\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:97.99130052477122\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.13509867116808\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.33063061330468\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.56971461512148\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.29059924930334\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.51104132216425\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.33485474139452\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.51618349272758\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.94526216425001\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:99.22115819230676\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:99.09375989325343\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:99.31249166242779\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:99.37527504842728\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:99.3155625589192\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:95.719145636959\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:95.7316064996645\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:94.54513824759051\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:95.58592340690085\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.78969093570487\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:95.4096574831754\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-140.49163403511048\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-512974.905053711\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-683.1684755802154\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-2993.62674446106\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-5092.848107719421\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-707124.9520355224\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:68.35626029074191\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:66.5621333539486\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:72.04188351035118\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:31.69431085586548\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:64.19790363311768\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-25.611612606048585\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:98.73185276538133\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.011712731421\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:98.50152830798179\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.18811208456755\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.31038432940841\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:98.66985493153334\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.70479262210429\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.70459699574859\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.72651219069958\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.72000130810775\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.70842131208629\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.70915777850897\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.5057119240053\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.50612714029849\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.61879970375448\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.50231629051268\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.55178386978804\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.57616138793529\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:96.62981852935627\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:96.11541353603825\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:98.56810208000243\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:95.88665526565164\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:96.3131632482633\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:96.31916192863137\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-16197359.132812502\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-65980080.92050782\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-131559008.73125\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-45630002.59023438\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-10434843.051070595\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-102655630.35078126\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-39910.54146223068\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-23562.335507684948\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-39660.73380823136\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-26123.309705734253\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-21179.279764825107\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-81271.08387145997\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-965.1285923600196\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-515.1827178359032\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-659.3593108892441\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-385.9561175111681\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-472.73744395971295\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-274.6726195842028\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:58.072951954044406\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:36.83483366519212\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:74.29100947715341\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:63.113101909309634\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:36.870830258727075\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:48.903313872218135\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:92.74494571927934\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:92.13847401915119\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:90.47877622307279\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:89.01089197439141\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:89.72207502136007\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:92.79971954636275\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:85.68174906875939\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:72.49111823104322\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:87.98136361071374\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:88.29189363815821\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:90.47430262221023\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:72.25142242629082\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-6819233.813500976\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-9720616.992773438\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-44253613.980242915\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-80752609.8319336\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-6585974.51131959\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-94940043.6391325\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-17423.47334920913\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-44197.098255900295\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-196650.00638101102\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-77213.94800291062\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-66624.06509768963\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-239393.69907073973\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:58.42468232857063\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:32.62897316943854\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:43.58673346368596\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:27.19825683292002\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-24.283545221388337\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-37.18639552146197\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:85.36523066256196\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:82.68501385748385\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:83.27063162326813\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:83.66339493915439\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:88.14731153026223\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:88.05097262151538\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:95.18797804093919\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:96.445579279121\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:94.2094504883513\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:89.42824741527437\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:93.2772330377251\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:86.50651949122548\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:88.9485234471038\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:80.0131001599133\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:92.04725303146988\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:87.90166425909847\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:83.60732370093464\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:85.78573333565146\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-11971665.267417144\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-5326972.697851563\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-23357079.11696472\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-28356172.730973054\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-17881117.75436096\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-14571876.833013725\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-33237.145853185655\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-69565.02583823205\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-28677.346395087243\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-10754.114206176997\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-27423.37416571379\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-22502.437948203085\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:68.79775576535611\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:33.15737924277783\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:58.701333021000025\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:71.32046831604093\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:57.28208040893078\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:43.56305631771684\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.59236583020538\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.62369041731581\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:95.84964706357569\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.10689548626542\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:98.12508517056703\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.09202791664283\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:96.24649433670565\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:96.17452904246747\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:94.99227823521942\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:96.82996960338205\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:97.0181388475001\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:96.60663825478404\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:92.89654709361493\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:90.08642944414169\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:91.16848717676476\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:89.37148460708558\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:89.2842742648907\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:90.8373125165701\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2313383.7071243287\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-3273631.9205200193\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5094053.564474488\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-3400078.592534447\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-4839643.361407853\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-5094398.396435166\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-6972.710833215713\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-2146.0734175205234\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-4605.446308636665\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-2245.7959250450135\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-7277.817761427164\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-2909.216706800461\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:86.8101548962295\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:92.44770598113536\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:90.48320843651891\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:93.72723674580921\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:94.97649928107857\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:88.08433375880122\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.48905108517502\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.79882629825734\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.6578861963004\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.88146596997977\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.86019892599434\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.97973719742149\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:98.69332286790014\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:97.9975710041821\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:98.41642258744687\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:98.4676716260612\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:98.05658020097763\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:98.25437994599342\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:94.9671772427857\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:93.12095078229903\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:94.83454964123666\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:95.10043909382075\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:88.56406001038849\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:92.13283030223101\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1663823.214042282\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2162662.7622909546\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-440169.0604775429\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-961634.346373558\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-471469.4108657837\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-154477.50626552105\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-190.0703345000744\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-258.0610677480698\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-238.16894412040713\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-257.1648724079132\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-221.87626957893372\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-338.4238572657108\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:96.94073469126597\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.35112091521151\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:96.54138613529504\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:98.107359242253\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:97.18887054994703\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.00094200223684\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.23800990933087\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.30125288236886\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.15292315017432\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.35974194668233\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.32702536769212\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.22083436660468\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:98.67366303000598\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.71743545643984\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.77844885643572\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.78084352256265\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.71199066340924\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.61712362272665\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.83783717774786\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:97.09585336344317\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:96.89471410643309\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:96.41314627025277\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.28543572649359\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:95.5140983952675\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-513778.2805015564\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-13346.646929621696\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-16149.957201099394\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-19481.475489044187\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-487076.1475628853\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-57176.65777492523\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-49.671969950199134\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-102.09277254343033\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-157.15124008655548\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-365.6594402313233\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:29.471542906761172\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-82.93018794059755\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:98.4908946286887\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:98.41220317333936\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.05060270652174\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:98.85188981816174\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:98.89550297558307\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:98.59589539319276\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.5474785733968\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.55796420797705\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.57993140947073\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.52521357424557\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.52225524883251\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.49368007630109\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.01111845802517\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.30082275047897\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.1127050165087\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.22789175324141\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.15548595907167\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.0014598377049\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:96.79252965468913\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:98.03629213757813\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:96.4054521266371\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:98.15484883971513\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:97.67427666243165\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:98.07264007297346\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-66848.5619934082\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-212885.8950561523\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-67747.18915405274\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-131046.2216706276\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-27699.710391235352\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-8235.65103816986\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-3237.684567642212\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1042.7515009880067\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-3047.8059970855716\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-621.8065511465072\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1787.602530026436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-306.3826171636581\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-10.296783636510366\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-17.181358140707026\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-40.96396026462317\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-21.120840549468987\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-14.033726149797431\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-3.6642142891883944\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:91.29255391284823\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:91.28058819016441\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:88.2557915635407\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:92.39991197101773\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:91.6350454563275\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:91.18679760145024\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:89.20178207047283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:86.76023514159024\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:95.37590130455791\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:87.57529111430048\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:81.63282285258174\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:90.32844416778535\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:89.95565605349839\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:94.29167231135071\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:85.1865342732519\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:89.46680466663094\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:93.61905516926198\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:91.6406614350155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-324734.90005950927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-516157.2821014404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-352854.59545993805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-378319.0688232422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-243780.29082870483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-604508.7928634643\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2357.030579805374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-491.1740586280823\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-5367.858604478836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2473.9149556159973\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1646.5063013628126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2751.8925029575826\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:92.3459527399391\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:60.41863050423563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:85.84790713060647\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:70.49517448619008\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:79.59446402341128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.41593914553523\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:96.22939554457552\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:93.63780675176531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:92.8916578911245\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:93.10059334156104\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.51694958545268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:92.14642238020897\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:95.04157044673337\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:94.9662531254813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:95.13345215693117\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:93.86450247559696\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:96.268684528023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:93.80336555801333\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:94.4252378705889\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:85.07253346182407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:93.74305692575872\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:95.46923459786922\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:88.27324068397283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:93.58754153382033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-124855.37530078889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-161415.98230743408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-96089.01784210205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-146569.08782081606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-135351.03407287598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-88115.00467681885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1760.3336845874785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1518.1859701156616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-946.8417817682027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-431.88351788520816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1049.5900444746017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1124.740942233801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:83.43635231144727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:92.12866646461188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:96.36550298854709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:90.02628697231413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:90.04345749095081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:85.55961332395673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.10097975209355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.38142976397648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:96.31731088878587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.96281866263598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:98.01531787086279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.05056610805913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:94.91774447858333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:90.43853400684894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.33191471770405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:94.46230561938137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:94.04879517769442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:94.53377112913877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:95.63224412528798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:89.84640044011176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:90.3701938053593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:96.01905026258902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:91.50850667674094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:94.01868696287275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-57064.928886413574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-30836.485613632205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-38582.009782409674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-19914.776136779783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-9239.754891777038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-23531.77214355469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:16.472558391094204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-182.83652276992797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-258.64546080827716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-271.8192570924759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-511.67404515743254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-853.3033560276032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:99.32615312337876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.30658889785408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:99.22445347430184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:99.30128776328638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:96.66936312764884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.34216044154019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:99.21081847464666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.34475035145879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.17680708691478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.27292127031832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.92464455356821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.04212084589527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:95.2431535910815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.11659327140079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:95.24329229481519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:95.16181523101405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:95.10709337368608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:95.83153526298702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:93.76543798223138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:92.16666575111448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:96.62908726036548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:94.82615754213184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:93.83408880066126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:93.7852696172893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-2311.4040727615356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-15546.730355834961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-592.2567924499511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-3445.461449337006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1280.7442604064943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-560.0700981140137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:46.3987258195877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:84.02900953292847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-51.658896374702444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-107.01143821328878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:92.17187566757202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-814.635353255272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.70846323072911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.5195829704404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.58664864161983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.52278304174543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.70871337652206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.69722140878439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.67024892307818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.68723430950195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.66879493203014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.66573701077141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.70374550065026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.64399755652994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.87974018906243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:97.21838549003004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.03538536448032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.77191627770662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:99.09506353586912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:97.51269300142303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.80503998417407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:93.91205208208412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:89.86610439158976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:93.91388783287256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.91317966133356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.88235101457684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-644.56041431427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:58.10676879882812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-120108.9132232666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:79.94360466003418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:93.59821548461915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-66.97986054420471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-92.61361747384072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:97.96502423286438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-112.5224294245243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:97.38763217926025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:76.62672706246376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:94.51666004657746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.73030711077153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.71251566186548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.70931550280656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.72266125380993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.70026722252369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.6820072978735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.70834389217198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.72493351250887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.71614668034017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.71039804853498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.70545210130513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.71461343728006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.47966554779559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.57291816920042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.56437518862076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.58446427211165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.58182785362006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.59730287701822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.19080062080175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:94.70184840582078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:94.16653563380241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:94.18598452715669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:94.66924632117151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.44858245439828\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1563165.3180350305\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-98942.64696350097\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-542567.1298930645\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-736750.9528981686\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-205391.5346470833\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-28949.091715192793\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-22056.23447623253\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-533.9260718494653\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-3544.4799717634914\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-8022.408339196444\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-11162.806163954736\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-22418.656377238032\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-8.064393096417199\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-15.953396803420027\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-42.71832029167564\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-95.71139174122362\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:34.51493613831699\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:20.779145505279306\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:70.15241348110139\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:76.2983206002973\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:78.03735978864134\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:78.17816069968976\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:84.52544063497335\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:73.6954602330923\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:85.93343924675136\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:83.72781827561558\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:91.37049876507372\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:89.31349835405126\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:86.34648996703326\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:81.08702735304833\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:84.03074030801653\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:87.35091242473572\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:91.90189402364194\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:89.36873309779912\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:81.35445076208562\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:87.52865249667083\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-5895005.610839844\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-2164706.9185668943\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-3825897.89488678\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-5008415.424004173\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3780305.950946045\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-4486693.787823677\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-43556.07508821487\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-33654.84972352981\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-27631.47876124382\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-21117.6046739459\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-28989.18709602356\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-34714.27209379673\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-160.2532902471721\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-91.3723938398063\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-124.7030830357224\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:6.640052492171522\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-121.97915175927338\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:20.750452409684662\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:94.01933805141599\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:94.622186943423\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.00965726757423\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:93.50888871401548\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:94.33182931682094\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:94.95907616466283\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:94.44661682900042\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:94.44540187418461\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:94.81046730871311\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:96.07821070491336\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:96.42807704471052\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:95.64220903366805\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:79.74644988067448\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:87.67157006012276\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:88.80664860378019\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:83.65901306886225\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:80.90952126886695\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:92.78219747804106\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-2351471.2414924623\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1069890.6074234007\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1033324.9811401367\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1492827.3244491576\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1707092.7710741041\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1000044.7078365325\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-13677.471913838386\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-19981.345074796674\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-15211.254283475875\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-22915.764881563187\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-14397.071529126168\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-4478.95285103321\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.35542635191231\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:-2.4155109874904213\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:6.024713177978991\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:-8.349066402018067\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:16.694872466474774\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:28.886854404956097\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:98.15206652861089\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.90374635313638\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.87890236545354\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:98.18960389429702\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.91115029528737\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.2205523237586\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:98.05702462394255\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:96.74947803355754\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:96.59935211539269\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:96.51231029108168\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:97.45518165603279\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:97.63243683697655\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:87.79721428528428\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:90.88468775749206\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:93.95403497032821\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:95.41007553469389\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:92.79324717721902\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:90.85383668914437\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-420436.325945282\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-239215.68485889432\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-234548.13879985808\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-564497.7642869949\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-209020.3623315811\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-315797.099559021\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-8468.870722031594\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-4838.875678515435\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-2381.0499074459076\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-6114.855407381058\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-1665.7235093042252\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1838.3252028226852\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:85.72195271309465\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:74.53940316960215\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:82.06949815452099\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:74.36173231080174\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:84.96319440603256\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:85.54024073630572\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:99.13895903714001\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.12380714197643\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.00535164345055\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.88655484318734\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.01007250817493\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.0492740644142\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:98.37300730478017\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:98.67705894352402\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:98.43581650238484\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:98.70284427665173\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:98.68584415949881\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:98.55853945501148\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:92.76800842517987\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:93.68003383148462\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:95.56497998256236\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:93.67502321917563\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:95.25603918991983\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:94.7011006954126\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-21288.66579437256\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-29481.046721839903\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-35719.649978256224\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-61709.37539710999\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-25450.398361587526\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-41996.04288215637\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-1497.3326124191285\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-249.61047086715698\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-237.73528432846066\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-233.03735496997834\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-410.62029671669006\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-455.752777671814\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:96.02415636107325\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:94.38700758591294\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:97.54760310659185\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:97.45157859325408\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:95.85149172544479\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:97.92544184178114\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.51955398247082\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.4734345499659\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.53302370253951\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.5130265892949\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.52132072597742\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.5335032634437\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:99.04988199253567\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.88279917240142\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:99.03879220001399\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:99.16113350503146\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:99.19007308308501\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:99.20882805697619\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:97.35044663920999\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:95.09335682764649\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:97.53354915771634\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:96.64265117757023\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:96.56313861371018\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:97.57833752755542\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1264.0946437835692\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:86.86494941711426\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-55860.59401569366\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-50925.30029182434\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-7415.74111251831\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-2887.6399003982547\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-18.26232441663742\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:72.30801165103912\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:86.11107607409359\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:87.58069820404053\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-54.42224819660186\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:1.0341729640960695\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:97.60316402874886\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:98.32206250485032\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:98.81966659724712\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:97.84212375879288\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:98.14341812804341\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:98.52539183497429\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.62322749244049\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.59807465579361\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.64113315357827\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.55479354299605\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.62240423848853\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.62295355424286\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.43227797513828\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.44107253123074\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.47719052704052\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.35764488354324\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.34433524729684\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.2320512862876\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:98.42058370327577\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:98.24091612957417\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:98.20037849252112\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:98.13771534375846\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:98.69344858396798\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:98.71639721589163\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-22682.4839302063\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-3738.3499572753904\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-55571.56937561035\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-64310.74807128906\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-63908.5341583252\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-66554.60029296875\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-268.87488958835604\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:61.46780695915221\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-356.40344378948214\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-200.1475814461708\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:6.404013812541964\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-681.8784237861634\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:32.22832541465759\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:76.0525632813573\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:73.37631148993968\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:96.72205912116915\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:55.83781352639199\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:87.3189471617341\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:85.84356566742063\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:93.50515510886908\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:92.31400940250604\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:63.84730183184146\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:94.24347425829619\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:79.99089326709509\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:42.57372699379921\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:78.77438194304705\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:78.66595130562783\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:57.106050635874276\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:88.37184850499034\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:89.26291834842414\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:34.08040447831154\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:60.13776029348373\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:64.05043786317111\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:87.89762674346566\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:82.78331762626767\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:44.46241429150104\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-43150.59074707031\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-13284.384387207032\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-13463.183361816406\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-4474.593121337891\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-11893.186419677733\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-15318.632739257813\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-494.22793874740603\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-42.61991970539094\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-131.7687897205353\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-87.94247210025787\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:16.75663869380951\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:2.494367003440856\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:83.39912367016076\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:87.47416175156832\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:83.01569496914745\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:93.98273327834904\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:79.4377313002944\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:81.65313751623034\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:93.44216643497347\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:94.42226986512541\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:84.58592367172241\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:83.87061329931021\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:92.14670906960964\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:70.08427174091338\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:46.734261743724346\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:67.34636357575656\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:42.91879616379738\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:81.11928623765708\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:24.46875121295452\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:96.82377638444304\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:70.48766921609639\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:27.21729021966457\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:46.64269729405641\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:90.22058028019964\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:73.24101561680436\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:63.09613487869501\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-12256.68235473633\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-31416.86530761719\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-11022.869641113282\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-6428.768688964844\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-19667.097241210937\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-16249.453967285157\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-148.6515877008438\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-45.610389953851694\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:28.361669754982\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:44.56226876974105\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-31.26406950950622\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:38.123427557945256\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:92.00356307178735\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:95.8636952906847\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:94.44168306514621\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:95.35683375969529\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:93.36013510599732\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.28784160856158\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:88.47406126856804\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:91.24421615600586\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:92.44994186758994\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:92.42173791751266\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:90.8989260405302\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:83.60911988914013\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:77.29109705612063\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:93.65511415302753\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:87.13820679150521\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:45.27038549184799\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:92.33704996556044\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:79.14232674390078\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:96.84084617868066\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:64.0590210661292\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:95.9530164130032\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:96.53606135100127\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:64.40460808575153\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:90.22470903620123\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2993.405491638184\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-9090.607983398439\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-3183.5192138671873\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1448.6301834106446\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1737.8499572753906\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3350.67314453125\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:71.73037260770798\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:63.90817229747772\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:68.74489142894744\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:75.59174083471298\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:70.3466397613287\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:90.1398320734501\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:97.36594464238732\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.48218700280414\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:95.07405686229468\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:96.97728350535036\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.08681585863232\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:95.38909075707197\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:95.58860038891434\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:92.87170360833407\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:94.57284833639861\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:94.32520628198982\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:97.9645393744111\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:94.06078451573848\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.74893474802374\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.11947870403527\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:78.02953497618437\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.91129413396119\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.82177032232283\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:92.46105759143829\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:87.38880785405637\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:74.45680722594261\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:58.63149156868458\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:89.04172053523361\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:77.23590133488179\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:63.917365854978556\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:93.98941345214844\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-136.92516632080077\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-21.277468872070315\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-74.41338844299317\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-78.98345642089843\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:39.19292469024658\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:94.25553397536278\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:96.30305590629578\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:94.53674473762513\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:90.26434321403504\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:92.33390358686448\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:95.07803676724433\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.41481811404228\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.59362534470856\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.34882963746786\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.18579039126635\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:97.27664850652218\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.30834412705153\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:96.505576325953\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:96.83569603227079\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:94.54311225414276\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:94.22245272397996\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:95.3125421576202\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:94.67303920425475\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:93.69701394587754\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:94.06940550766886\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.34267050847411\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:93.7011688143015\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:93.35901340842247\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:93.91908687129616\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.75026538223028\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:38.46837090849876\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:88.68099309802055\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:47.75729043036699\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.75868188813328\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:63.82840941250324\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:95.00525344610215\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:93.71975173950196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:93.67318572998047\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:57.62339305877686\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:93.74518394470215\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:93.60194869041443\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.68959914743901\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.69373302459717\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.66934211142362\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.67454397678375\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.62683068513871\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.6861289858818\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.75383816678077\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.7521468845196\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.36957253217697\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.34494317919015\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.51834187880159\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.77555486559868\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.527676025033\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.59936604201793\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.38136269615498\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.56021230816842\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.12918112576008\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.4579049192369\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:94.49765871167183\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:94.09809275344014\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:93.8904640957713\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:95.14076097719372\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:93.88621868938208\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:94.58441414535046\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:93.57116600833834\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:72.09899567216635\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:87.96775818392635\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:86.88763571679591\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:80.60385217219591\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:46.61904449164867\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1130834.4929473877\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-162700.8696735382\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-11000447.223449707\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-12963175.302160645\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-1725592.4993484495\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-90706773.95332031\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1132.8336913228036\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-7010.338914680481\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1214.2978298962116\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-990.9976193785667\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-5145.002488899231\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-345.90726013481617\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:46.47911695539951\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:75.05111818015575\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:57.997316983342174\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:71.49639242887498\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:68.96551189124584\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:83.33742374479772\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:61.13036823272705\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:34.6407522469759\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:78.36613217070698\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:62.98861086070537\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:92.21939770653844\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:72.83992734476924\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:80.55140171870589\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:74.10562177151442\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:85.9177659392357\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:95.87345321513713\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:64.97765725776553\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:74.82909215204417\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:91.10598512752914\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:44.06830120831729\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:68.93476293236017\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:51.104364350438125\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:79.00530227273703\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:88.47819699570536\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2210.2217132568358\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-13566.715771484374\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-15212.16407470703\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-41334.86619415283\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-41117.55805664063\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-90029.33784179688\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-784.8039085388184\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-250.58818511962892\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-279.4213706970215\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-526.6977375030517\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-268.92537422180175\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-551.636975479126\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:94.59784012436867\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:91.87790558561683\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:94.0577842630446\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:92.4005392594263\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.9160024927929\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:91.97319433577358\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:87.4594670496881\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:88.97586479447781\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:93.39064527601005\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:86.49760957635007\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:92.80706300288439\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:94.5134490672499\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:86.96607940457761\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:60.68886849284172\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:69.44393594115972\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:90.26801575124264\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:95.28814685484394\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:69.46513537019491\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:72.04156427457929\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:47.87708156406879\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:54.62326526939869\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:81.15561004467308\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:57.05302196741104\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:83.91210533082484\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-65128.28803710937\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-383215.45234375\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1419.8353225708008\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-145601.62177734377\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-66767.9181640625\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-303977.5408203125\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-181.33198566436766\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-75.20592756271363\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-259.97737102508546\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:87.56498641967774\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-169.90074462890624\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-86.35601348876953\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:98.78222556677648\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:97.64601715411992\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:98.1226643955335\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:98.566247779876\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.9585542947054\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:98.28260552529245\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:93.90284761060029\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.33870030194521\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:94.72645854316652\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:95.26063931584359\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.58768700137735\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:94.2639595963061\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:92.95471959002316\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:93.43582398630679\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:72.4131193228066\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.0379235252738\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:94.4349938553758\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.75772048532963\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:85.66221367064864\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:68.30000284090639\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.38443096466363\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:82.58914061188698\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:85.54648527614772\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:85.07570419609547\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-11680.114514160157\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-228.85957412719728\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-18487.692028808593\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-34949.681323242185\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2623.835713195801\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-8398.82301635742\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:83.81704635620117\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:70.71896386146545\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:2.0074779510498075\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:69.11324248313903\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:84.9425012588501\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:96.33210248947144\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.59792673140764\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.46971935406327\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.87607777006923\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.11834767758846\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.01672987826169\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:99.1515267809853\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:94.87850215807558\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.23206368964166\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:96.66097299531103\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.3269702680409\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.25724712349474\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:97.837008411251\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.823435513675214\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:93.89095692690462\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:93.00319613255562\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:90.17615530267358\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:74.61944636926054\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:95.03306866493077\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:77.47150887660682\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:75.47063148468733\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:90.99032370653003\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:84.73422698825598\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:84.75940533280372\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:81.3536875270307\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-3327.112728881836\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-350.89515991210936\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-7605.189282226563\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1287.9122192382813\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1015.8705169677735\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-254.54925842285155\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:96.25129051208496\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:94.076899600029\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:95.33338710069657\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:93.77998657226563\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:93.87691202163695\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:88.81026153564453\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.47331282533706\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.63149832515046\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.6826301112771\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.41227921433747\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.59345692396164\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.53701940104366\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.08926906883717\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.20118335783482\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.54734546914696\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.1311691172421\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:93.31475217193366\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:98.99205384314992\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:87.40249866843224\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.28355815522373\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:92.88073011338712\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:91.90939050912857\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:93.35180463530122\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.70448639728129\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:72.17280630543827\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:81.80797936096788\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.867680092155936\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:88.94054727796465\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:79.30572872981429\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:84.38500271476805\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:94.47841949462891\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:94.0258337020874\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:94.65178833007812\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:93.44143028259278\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:96.27371826171876\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:94.43471908569336\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.6891704082489\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.68603615760803\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.68693305701017\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.68850997686387\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.68312578201295\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.68552124500275\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.13946016430855\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.76728043500333\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:97.81268743444234\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.50474520716817\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.66846177689732\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.52470009159296\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.44087576195597\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.25466630831362\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:98.2876047372818\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.55814350172876\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.70624730661511\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.64697598144411\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.30900027155876\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:93.8527127146721\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.64485560618341\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:97.4779343932867\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.59484707787632\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.03848404921591\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:81.21371707990765\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:87.63150215893984\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:58.24389092773199\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:72.52336215898394\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:71.36020074263214\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:44.44783267676831\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-35270.21787109375\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-43548.52463226319\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-4921.375012207031\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-5854.734753417969\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-44890.736033630375\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-43875.92727661133\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1017.4706217288972\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-55.57285922765731\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-243.4707197070122\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:67.44433157444001\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-337.1843947410584\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:30.156172466278075\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:76.89398274570704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:68.3142669275403\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:64.67821017801761\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:83.69330715537072\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:63.43423505425454\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:67.7085001423955\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:80.54111955314875\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:96.42356776818633\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:62.46997068226337\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:22.96331370770931\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:90.78857130631805\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.18112001568078\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:43.10434731245041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:95.84116814732552\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:84.18660816587507\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:48.882098908722405\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:62.759191244840615\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:66.23882421702146\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:93.20759472995996\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:63.10588161349296\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:80.64130173921585\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:75.8191792704165\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:65.50106487721204\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:74.30140506476164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-21812.800366210937\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3805.154696273804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-20620.68458251953\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-7511.383587646485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-21380.92674560547\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-14512.008898925782\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-188.5399500608444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-270.8117625951767\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-92.36700375080109\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-9.786750185489645\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-488.6673036813736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-35.636051380634306\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:95.39679234474897\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:92.87600274793803\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:89.59303106963634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:88.26107846982777\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.39505679681898\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:93.59960920512677\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:94.40861627012491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:87.8395843528211\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:87.26392333507538\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:51.333072948455815\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.61739181131125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:91.73381531387568\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.24515047371388\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:67.38036203682422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:55.92528543025254\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:42.41936066150666\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:65.15088351517916\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:68.56266424357891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:95.99000363834203\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:84.2571553900838\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:83.66918991245329\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:13.938148733973499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:92.1646871753037\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:91.290986700356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-5523.005145263672\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-4526.920086669922\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-21177.54493408203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-14545.552294921876\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3377.1104400634767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-9536.223071289061\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-46.328632611036305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-102.68858735561372\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:42.66195013523102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-25.549926590919505\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:9.681352227926254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:44.43323222398759\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:90.49856352359058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:93.22519211750478\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.46043659150601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:95.5119104962796\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:96.5093266060343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:92.10056586582213\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.48749160394073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:90.7138397268951\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:94.96801105961204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:93.07228388488292\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.06183127462864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:91.89332502707839\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:92.75760155841708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:76.65404162704945\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:63.38093015998603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:87.42912340983749\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:61.90035024881363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:58.21482484936714\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:21.396804681420324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:67.15111655294895\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:58.94061428755521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:77.55176344662904\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:63.60967155843973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:47.64243630319833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:54.695742797851565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-2105.959088134766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6712.03666381836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-598.3659381866455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1904.5137817382813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1828.5317962646484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:45.81984992027282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:70.73855046629906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:86.28725230693817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:93.44377751946449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:83.47948545739055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:65.06343245506287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:96.807858286798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:96.37252473793923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.32295829374344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:99.16195018962026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.14624510854483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.2733536541462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:97.04317284822463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:92.64599880762398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:95.51812823824585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:95.17477823868394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:92.14396330341697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:95.01848758123815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:89.09110862426459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:86.58299483582377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:69.41068890690804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:59.86158229708671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:95.1940592981875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:92.99765423685312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:67.38402180671692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:93.59874841421842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:29.67403966188431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:36.727692431211466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:66.43436366915702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:20.040195181965824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:39.546647262573245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-404.83402557373046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:69.89335746765137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-23.655087280273435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:54.32992248535156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:73.01686210632325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:95.72848703861237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:93.71475932598115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:92.3362156867981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:98.55053367614745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:95.77207560539246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:96.1440098285675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.79014330208301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.37907481305301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.1985411375761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.46941215544939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.76092572137713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.77282634973525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:95.23174370229243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.30084415078163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:98.94201227203011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.36139316633343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:94.19503867831082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:94.86071829870343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:93.93247169405223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:74.98588326573372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:93.95669250935316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:93.0709845289588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:93.81450950056315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:93.71203802004456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:94.14935423918068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:63.434166920185085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:68.93741030991077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:93.68041570968926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:72.7187953017652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:79.82582376077771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:93.74339294433594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:69.67281646728516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:93.65527572631835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:70.86228866577149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:93.74446754455566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:60.72620697021485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.68791182935237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.68643733263016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:66.32688732147216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.68661398887635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:52.30622239112854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.68981147706509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.74150015637278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.78135687336326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.792718757689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.76254574195482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.76791200172156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.36316538797692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.78465930372477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.24141576811671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.80337144732475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.76886656582356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.65860653379931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.77366099916398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:97.55422831624746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:93.98241595383735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:93.91037901495584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.21754148863256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:91.32102182507515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:93.80011566281318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:88.56777345091105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:50.724411092698574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:76.71463085189461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:92.79612269029022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:93.69618291407824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:95.58078804910183\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-20428.024802589418\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-32783.343905210495\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-27374.78742904663\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-2382.2845368385315\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-3363.29840965271\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-102599.99839172362\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-594.1384333968163\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-187.35756312310693\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-294.46489773988725\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-72.41906412541866\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-273.33865311145786\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-116.47155016064646\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:94.59038434103131\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:68.15231500416994\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:85.15739265605808\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:72.90891654789448\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:87.92449336871505\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:89.26537758186458\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:84.82728074043989\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:72.11851656287908\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:58.26580919325352\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:95.61184795089066\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:65.15613743811845\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:50.70533036589622\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:61.90086578242481\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:78.98611086905004\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:50.82750390470028\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:52.678777596354486\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:60.702855759859084\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:46.567064795643084\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:32.486273927986616\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:53.8198484301567\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:64.35237103775144\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:65.02013309001923\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:88.3922191336751\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:70.76596897654235\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-36595.98690948486\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-16952.533973693848\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-15149.330421447754\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-28369.660084533687\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-50104.56079483032\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-9022.465758705139\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-116.92214384675026\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-93.07120328247547\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-77.75478099584578\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-5.434850710630412\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:10.715953758358953\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-335.6974703371525\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:93.50661010965705\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:92.45991181619465\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:91.26287478646263\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:92.64384343437851\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:89.61386626847089\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:91.96351559720934\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:91.43462693616749\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:91.38945721797646\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:88.48077410906554\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.00507153114303\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:89.09752662070095\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.0055087044835\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:90.42097974568605\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:84.24906391128899\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:91.1346298011951\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.94976010173559\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:89.86677017416805\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:83.29876367487013\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:86.6060990318656\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:82.77433507265523\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:48.834878647327415\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:90.0569428101182\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:63.49580660313367\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:11.804514083266259\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-8014.04346370697\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-11519.581650543214\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-10348.302929878235\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-10013.22683353424\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-8115.657963562012\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-23736.692205047606\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:32.52211750149727\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:62.797144246101375\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:61.78256168812513\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-4.715730714797983\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:19.53405414819718\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:60.992410075664516\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:92.02809662315995\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:91.9494942869991\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.96539657711982\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:98.14048313200475\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:95.3387718854472\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:95.53019604943692\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.17120964936912\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:92.87338218390941\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:95.65004059448839\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:96.96736463904381\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.21867302879691\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:92.82553751994855\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:93.61268521621824\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:59.49156914353371\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:72.06370179355145\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:65.42107801288365\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:88.85583727471531\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:91.41469687335193\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:83.5719681569375\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:67.57580608204007\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:90.0881026789546\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:64.8051802136004\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:92.72369273863733\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:87.33560033943503\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1956.1591502189635\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-4585.881054115295\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-7759.574596214295\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1217.4626342773438\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1279.2276332855226\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-655.1621173858643\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:74.72052930593492\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:94.32749121785164\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:94.40129196420311\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:63.516013987362385\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:82.58589209318161\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:72.8010674238205\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.88959723580628\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:99.03437264058739\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:99.01307706385852\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.91124591901898\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.96991245299577\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.9757950603962\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:97.81717968322337\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.0696485169232\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:96.77030259557068\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:95.30049681141972\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:97.97318479791284\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.69954253956675\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:92.58045891076327\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.24059066213667\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:77.1715110808611\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.76064835488796\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.10523757506162\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:93.91214745678008\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.87972242683172\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:66.22065087519586\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:93.56919021606446\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:79.20136090815068\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:74.76832411661745\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:87.32155055738986\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-810.4008172243833\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:7.745244598388668\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-59.846420669555656\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-385.4611125946045\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2.529048728942862\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-36.06371364593506\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:93.64114644527434\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:91.40226866006851\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:97.97075232714415\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:94.85961660444737\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:93.31316155493259\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:90.76312495470047\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.44018308045342\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.37377828359604\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.74446595460176\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.6619877204299\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.59945354610682\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.32504436280578\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.65477735102176\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.56366786137222\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.54779961630702\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.43107198774814\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.11705965660512\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.29360975660384\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:88.40489794909954\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:95.73172162100673\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:93.78183142468333\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:94.53076510094107\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.90188410962\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.24605128914118\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:89.61989992931485\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:85.42414637580514\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:91.95470989644528\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:94.73046327435877\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:83.86582280360162\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:65.2146801099181\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:94.25995464324951\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:97.36454429626464\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:82.99001865386964\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:80.5019310951233\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-67.42841663360595\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:97.17491645812987\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.83677935898304\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:99.78851619362831\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.2426190495491\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:96.87586517333985\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:96.83328377716244\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:97.49958899021148\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.7717111080885\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.6046323608607\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.74813637211919\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.76138616204263\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.74643659719732\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.67840538024902\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.73824518918991\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.74143995642663\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.72593314927072\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.71752658784389\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.7479571281001\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.64933378100396\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.10660298988223\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.27261811420321\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.62576760090887\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:97.87791099920868\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.9256901241839\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.25489211082458\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:60.43650454953313\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:93.8470731344074\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:77.35422127917408\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:92.73720911350101\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:41.49766910374164\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.6851699275896\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-38483.641284179685\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-11766.176330566406\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-155145.53935546876\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-87002.00981445312\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-87197.45659179687\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-174450.58417968752\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1357.7799390792845\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-713.7351121425629\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:57.69289762973786\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:57.57030293941499\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1539.5696431159972\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-771.9162397861481\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:8.189294108748435\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:4.0121225744485844\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:81.03111173063516\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-26.76631134152412\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:2.2459599912166617\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:23.54889590442181\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:81.05745827406645\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:72.26871229708195\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:92.36580085903407\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:64.68622585237026\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:73.54983856454491\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:95.00212909281254\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:88.51068617813289\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:14.33291137814522\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:82.05330593958497\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:92.50316465944051\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:88.98429416939616\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:76.48758379518985\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:92.76290862336755\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:76.36345327347517\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.6619464725256\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:59.01303018033504\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:83.19800043143331\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:79.12168552055955\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-75018.35502929687\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-79632.96943359375\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-38768.02802734375\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-98748.61884765625\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-97187.26982421875\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-29624.415820312497\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-582.6879581451416\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:60.93916600346565\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-890.3996624469758\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-306.75646486282346\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-852.3208464622497\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-83.9636324465275\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:69.60244722068309\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:81.73075007200241\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:92.70544888302685\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:81.06746607124805\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:93.71191581021995\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:84.70559850409627\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:83.81212605088949\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:91.3509558359161\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:89.70186232887208\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.41633258610965\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:88.60241199843585\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:80.65776331871749\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:96.33795034429058\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:75.40801487490535\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:90.5935725003481\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:95.1433759800624\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:47.62034509778022\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:93.06448343247176\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:83.76649358719588\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:93.53286328911781\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:36.79471635818481\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:77.97702567130327\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:88.89784737564624\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:77.72203143388032\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-41703.17863769531\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-101646.81220703125\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-64809.959179687496\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-10145.56174926758\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1616.9500762939454\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-113613.157421875\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-122.45796875953675\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-277.9349938869476\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-336.91414451599127\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:93.74891459941864\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-336.0596140861511\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-260.0382113218307\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:89.3641441553831\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:91.97869977448136\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:86.92842093259097\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:89.11928875371814\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:89.73790677264333\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:88.83992464803158\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:91.21512403301895\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:87.60890623629093\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:93.92740872837602\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:90.80449500605464\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:94.94487858116626\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:90.98660142384469\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:71.89159193709493\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:91.60674083493649\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.67507038637996\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:91.48905041664838\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:93.79193657487632\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:95.31198705211281\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:85.51240563243627\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:69.63882927149534\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:66.48810472935438\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:95.25855129938573\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:87.91645582728088\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:91.75576837062836\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-8097.643811035156\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-15618.055493164062\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2243.6708862304686\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1266.2165100097657\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-13063.233715820312\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-6679.025036621094\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-38.18563454151154\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:52.866408276557934\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:94.30766170620917\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:67.61826555728912\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:8.536089801788327\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:75.25499393939971\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:94.60680968165398\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:97.82758826706558\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:96.14202966690063\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:93.17367317676543\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.61223580092192\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:92.31963643580676\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:96.96935920338147\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:95.44293701425195\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:96.36103341504932\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:97.24011702612042\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:97.52377814464272\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.47251061275601\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.75073891878128\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:93.7847276147455\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:93.26706845909357\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:94.2788291245699\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.00334048420191\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.51819075345993\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:91.57423971220851\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:40.809572979807854\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:93.51240569204093\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:73.28885245472192\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:78.12328276336193\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:81.37580724656581\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:80.03258056640625\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-5016.890866088867\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-125.14396362304687\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2171.662289428711\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-729.9588745117187\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-700.7719451904297\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:90.21590979099273\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:96.7490603685379\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:94.75892941951751\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:92.3602924823761\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:92.28549189567565\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:96.38604423999786\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:93.70982019007205\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.61674733888358\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.28967289980501\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.48527522534133\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:98.60884838625789\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.43621982708574\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.46061694994569\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.5737873930484\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.58870178759098\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.60289137791843\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.46778301298619\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:95.87487225607038\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:93.89653393179178\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:94.13619126733393\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:93.89891135022043\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:93.77390575110913\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:93.93563095554708\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.50679444782436\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:87.70115338265896\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:68.88730054050684\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:79.87014523148537\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:86.3735810533166\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:89.5908908188343\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:80.29748337566853\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:93.63888807296753\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:93.37659606933593\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:93.86813611984253\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:93.7355125427246\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:93.54387550354004\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:93.95688018798828\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.67688026428223\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.69183821678162\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.68719152212142\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.68574995994567\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:95.0105664730072\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.62444071769714\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.57252550255508\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.57179648429155\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.7200539059937\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.69602864710613\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.57948472052813\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.70316398395227\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.71660097017885\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.77413106197491\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.76418190672993\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.73889163434505\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.72831674814225\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.74738083556295\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:93.89707697480917\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:94.57683685570956\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:94.45186403691768\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.09428793170954\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:94.68742640949786\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:94.51305110305547\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:66.30007621347904\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:93.99454323798419\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:91.82006849199533\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:44.79781345725059\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:88.43113459125162\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.80990591347218\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-29478320.44937744\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-15416428.029928492\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-13956501.66185913\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-136446724.0574219\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-44462492.817834474\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-106346890.80390625\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-3153.4389230966567\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2250.4967312574386\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-8628.953014326096\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-9938.736480283736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-216.7244752049446\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-7934.890712261201\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:42.004634836316114\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:59.605933631956574\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:76.39665695130824\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:64.85403841733932\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:46.74935845136643\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:64.11056228354572\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:88.13061662763357\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:89.4022810190916\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:73.95394498929382\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:84.17459939308465\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:94.2106393173337\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:95.86676198113709\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:90.16565267778932\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:32.90068132579327\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:70.40488217175007\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:71.47555061802268\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:86.39221996366977\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:90.5366125497967\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:65.93681453391909\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:82.71882346756756\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.13677778393031\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:88.67859762348235\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:75.74461157917976\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:61.975476816296585\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-11486273.256523896\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-4723273.317797852\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-2566.640704345703\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-25693.885571289065\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3158.756024169922\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-27398.897021484372\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1247.0315391540528\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1308.811577129364\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-23.812359046936038\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1486.5730827331543\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-564.2807623028755\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2700.091099405289\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:90.63085382655262\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:81.5724003404379\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:81.90080952048302\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:90.50983749255538\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:97.37511841505766\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:81.63060076385736\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:96.67590438872575\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:93.11093485318125\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:95.7523420251906\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.44354861602187\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:88.47093595713376\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.90702214464545\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:72.89545943178237\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:69.12528681084513\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:85.6827500667423\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:93.07564785331488\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:79.83859552256763\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:77.92127109467984\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:87.77495093457401\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:86.63755442202091\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:93.78049873821436\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:88.25262755015865\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:79.41678655445575\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:89.04037011042237\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-179454.13642578127\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-141525.85273437502\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-23163.379138183594\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-14243.996960449218\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-304006.809765625\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-284377.8546875\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-840.393406677246\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-492.54880599975587\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-371.5249473571777\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-596.6500217437745\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:39.31804842948914\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-229.28233795166017\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:91.87916527688503\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:96.27907894812525\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:98.13732120934874\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:98.11066975146532\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:96.39686924312264\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:97.05566279832274\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.96428210176528\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:98.37204523794352\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.7939302586019\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.0785362266004\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:98.14854470193386\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.83698217608034\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:95.12226561652497\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:94.3853674016893\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.74467482157051\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:93.68962327102199\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:93.34195761237206\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:93.16081629134715\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:60.514056731015444\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:89.06434142123908\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:67.20495211333036\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:85.3004769263789\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:82.04907839037479\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:58.43665744513273\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-6200.174862670899\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-34956.92573242188\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-227845.63552246094\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-20515.97313232422\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-39210.9880859375\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-59782.810742187496\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-121.18464164733886\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:22.334712219238284\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-321.9964916229248\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-89.14542846679687\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-16.41372985839844\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-42.390936088562015\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:99.40896677002311\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.87781026875601\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.78039137125015\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:99.24591851234436\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.85836430061609\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:99.15965746026487\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:97.75922392383218\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.46559939906001\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.42248638160527\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.09052581489087\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.10470467284321\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.31316197514533\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:94.00224483385682\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.72837665006519\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.43508661072701\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:87.3096211500466\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:92.61096711419523\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:95.25938266641461\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.003757977485655\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:93.91780700292438\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:78.01449690163136\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:69.35372798144816\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:77.7285944841802\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:87.09902926497162\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-4326.546710205078\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-16715.066296386718\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-5101.788943481445\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-5122.08313293457\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-16532.96531982422\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-876.1347229003907\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:90.4757911682129\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:71.010941696167\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:76.8688281595707\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:85.8751253604889\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:79.65750045776367\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:84.52140040397644\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.51370870545506\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:93.76752667427063\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:93.78302792236208\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.63241862645373\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:93.50761404260993\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.44238281846046\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.42329724431038\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:98.71639917641878\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.52488927394153\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:98.73382939398289\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.58724426347763\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.5571227990091\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.98502982594073\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:94.00271332375705\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:88.78303585126997\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:93.43565974980592\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.6720560759306\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:96.9938092187047\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:83.69352009575815\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:92.48443291671575\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:91.1976357843727\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:94.77820757869631\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:81.47392925135792\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:80.18206526525319\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:94.90073738098145\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:93.7956901550293\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:90.9845359802246\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:94.95303459167481\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:92.83069915771485\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:92.84431076049805\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.68032734394075\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.69279718399048\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.68017063140869\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.6859689950943\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.69234943389893\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.69405088424682\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.74648368451744\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.56209929697215\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.46508519724011\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.68694075271488\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.67621137946844\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:98.1144475877285\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.7424863666296\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.74480209313333\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.702143445611\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.61098189176991\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.66239613965153\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.2687385879457\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.32776316404342\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.8912647381425\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.2505689818412\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.0695033557713\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:98.72463904768229\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.66311846785247\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:95.1055114865303\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:80.63345248252153\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:78.36919872201979\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:87.02774474639445\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:92.46472013518215\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.65352377574891\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-6405.25186920166\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-5246.045188903809\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-74391.34083557129\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-5204.440538787842\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-85802.43524475097\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-35780.60812225342\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-358.904871892929\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-456.5965640068054\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:11.811316585540776\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-796.6493599891663\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-794.9644325733185\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-37.89658865928649\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:73.49270852208137\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:60.283124214410776\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:89.66415023058653\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:51.14006393402815\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:72.90000473856925\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:72.76785102784633\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:96.06520304605365\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:66.24101780802012\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:96.08343211691826\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:90.40579866543412\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:96.01125412294641\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:93.89634263813495\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:71.35144731402396\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:64.45243731588126\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:79.62461731061339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:67.81002376526595\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:95.62545411679893\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:80.54383976832032\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:91.3583815285936\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:83.91513065695763\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:84.91656235717238\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:84.38454448655249\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:89.99372526817024\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:73.37835388183593\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-9850.248486328126\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-11200.021130371095\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-31072.202832031253\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-58210.267871093754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-53549.924999999996\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-39304.76508789063\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-194.38942573070528\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-213.19030400514603\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-139.00210772156717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:4.43604055643082\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-21.471393811702733\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-324.5118379116058\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:93.35432574301959\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:85.68147094249726\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:92.27504415437579\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:95.61665907353162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:90.18104288764299\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:96.54358311071992\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:91.1592466339469\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.35602057352662\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:85.48780896365642\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:81.14473334997892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:95.83923398293554\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:93.4840969890356\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:71.13275472074747\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:85.50225072242318\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:95.01304067149758\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:60.24829357117414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:86.14220103472472\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:93.53243345376104\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:80.89512848332524\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:83.57648958861827\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:81.17309950366615\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:81.24754264354705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:66.0905169174075\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:83.59346848055719\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-42566.02958984375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-10783.897631835936\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-16072.631797027589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-17472.736889648437\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-9889.94651489258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-20295.048754882813\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-92.21305603981018\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-246.40675573349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-9.83239468932151\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-81.08625317811966\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-9.43702437877656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-110.11467967033389\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:89.94090406857431\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:95.774964456819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.02460987605154\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:97.07223745230586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:89.03812475651503\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:92.55874036047608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:92.22774140685797\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:90.34732270091772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:92.95477114208043\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:95.47500568330288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:96.08279796540738\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:94.62646971582434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:93.37177744247019\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:96.72033290895634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:95.27109356615694\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:74.61250971034168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:92.27432344704867\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:94.36386527316645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:77.82965390235186\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:77.94118224158883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:84.03353926166892\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:95.365817444399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:89.98175962232054\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:83.29238944202662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1921.8386108398438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-6807.3748046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4011.0208099365236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-769.6149124145509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-8073.819500732422\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-7249.643939208984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:52.1230523943901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:72.4909459233284\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:89.69361462593078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:79.13699195384979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-1.182548594474797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:88.28541171550751\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.05584150627256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:99.01372781842947\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.83143798504025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:94.14540666937829\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.47663868581876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.19132439047098\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:95.10587367676199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:94.88456039652229\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:92.94838437959552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:95.38464627563954\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:93.61922535784542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:97.02415739204736\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:86.5951636504382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.31152284219861\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.16481486149132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:92.81898873075842\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:70.85295298248529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:93.72412466183306\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:83.46345734745265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:95.3142640799284\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:82.29006965085864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:89.75108703523874\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:85.90967331789435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:92.66154215224087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-87.9747802734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-865.9286911010743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-360.2404052734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:56.311485290527344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-679.2589599609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-103.38424987792969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:96.30167364478112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:93.82741417884827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:93.24180193543434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:90.96971484422683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:91.1553337097168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-6.347764396667488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.77077745632269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.80647007152437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.69101022928953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.76069743058761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.67787162736059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.69081854242832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.57945666462183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.33986197691411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:97.07935453206301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.23385068903444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.25443679355085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:97.63394303843378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:93.8182741459459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:94.98652294278145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.0068026714027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:93.6347730346024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.05555275231599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.09561976902187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:46.09629110991955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:96.28684231098741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:90.32510944977403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:84.14682987332344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:72.79014581516385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:66.50138182938099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-68.07923965454101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:62.16310806274414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:93.63199272155762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:93.59008331298828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:93.70614013671876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:93.68043928146362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.6875459432602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.68793246746063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:99.79096966981888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.62372449636459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.68765168190004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.68679860830306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.39802124798298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.7574624657631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.79026596378534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.77690945342184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.66282352339476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.76159345433115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.77950829789043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.77211607322097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.66708800401538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.70445534950122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.4843870729208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.67889504283667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:93.83188569098711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:93.92410481786355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:93.93690838068723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:95.64434263780713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:94.24540256261825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.31428884640336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.16479606367648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:68.50501054525375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:90.64424328431487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:86.81396638527512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:93.60503741279244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:86.60698952972889\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-3327.1278033733365\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-55685.725523567206\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-160289.93529891968\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-262832.71420288086\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-40016.1548948288\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-78479.53336606025\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1188.2186945214867\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-21.412006729841227\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-710.332046186924\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1790.4068436294792\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-276.9888187214732\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-478.3428373008967\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:19.82189084170386\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:90.08800415545703\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:51.6238100554794\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-1.0669946380890805\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:51.35348193645477\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:42.01068423837423\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:94.47668042108417\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:90.17244538217784\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:92.4857010181062\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:94.13996307495982\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:92.3974236135371\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:80.38522569611668\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:67.70846597589552\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:65.99152216911315\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:84.71227060779928\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:82.50292654894292\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:83.73816434182227\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:45.97317571640015\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:78.975989818573\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:66.4017366848886\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:75.4678453989327\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:70.96941157132387\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:76.6748372707516\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:83.39402816034853\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-77964.92051620483\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-33987.96787948609\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-29819.296158599856\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-72363.11174545289\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-47832.14970855713\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-77045.0873167038\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-508.09108729958535\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-291.2259760916233\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-425.7523864090443\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-378.1927895724773\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-219.03546285629272\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-623.6520673274994\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:92.4441834885627\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:87.41470336378552\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:87.08760566478595\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:90.023526644893\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:86.75100841452368\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:88.69321842119098\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:96.2446447558701\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:85.49248288422822\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.40292093604803\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.27164041195064\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.00886117480695\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:84.62491104677319\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:89.95091956481338\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:87.81021735221147\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:76.67313495203852\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:93.19641875997185\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:89.38125669509172\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:88.38589977410156\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:75.05179810523987\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:64.04340446218848\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:57.642848145961764\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:92.08576733991504\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:74.30932324118913\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:91.57176882494241\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-19999.9153090477\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-50721.134874916075\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-10577.561106681824\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-13522.628151273728\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-20772.03684463501\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-15318.409061431885\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-47.3655278980732\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-3.1980986356735297\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-279.91455484628676\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-159.92275964021684\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-39.417040675878525\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-25.559220188856123\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:95.1666688703932\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:95.63920908942819\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.4005506535992\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:94.43100630193949\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:95.01027325838804\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:96.28820991590618\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:95.75043601468205\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.62337394384667\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:95.02612534686922\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:98.27698013857007\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.76801694403403\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.66039616535419\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:92.90934926820918\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:95.6003557767719\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:92.75868994314223\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:89.33857900872827\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:89.45708947591484\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:94.2527006238699\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:59.49371865689754\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:77.21197958961129\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:62.389856284856805\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:81.04279097076505\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:88.4851168103516\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:84.09461521022021\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-12972.941918945313\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-4958.992964553833\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4545.034005737305\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-8269.20066986084\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-9727.478197193146\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-4082.0074584960935\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:64.64309138059616\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:21.716904577612873\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:24.11534999608993\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:28.300388106703757\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:18.295680791139603\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-3.834240338206296\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:98.37776766642928\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:98.81493174545467\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.58271394493057\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.89177975803614\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.4713271887973\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.6184591403231\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.84395943507552\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.8424922056496\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:97.16899687126279\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.9125773113221\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.82234539985657\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.3021552335471\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:96.52136536687613\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.17986692041158\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:88.76163569688798\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:94.35166262462735\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.77468859925867\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:93.7393468638882\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:92.48077732566745\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:85.19300220496953\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:82.21967706605791\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:87.86985921822487\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:69.51753729209304\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:79.68655142821372\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-755.6146852493287\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-942.7244112968446\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-110270.76085281372\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-773.8385435581208\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-424.7147767305374\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-700.675589942932\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:60.24557688832284\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:92.48446247577668\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:91.02082253545522\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:87.17594766616821\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:91.36311175599694\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:88.6350879073143\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:98.98680121917278\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.5736744091846\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.54967566207051\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.26493275202812\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:98.11283251792192\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.59389117062092\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.39668756723404\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.5654917255044\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.2049113675952\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.29884011037647\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.41788003379479\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.34874899610877\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:96.3927306227386\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:96.68441384844482\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:97.71898518055677\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:97.70859970711172\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:96.78117344155908\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:97.74185447171331\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:94.08167751170696\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:94.62771723894402\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:90.18357879817486\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:92.79297347608953\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:84.32144507505\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:45.102564819157124\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-62.48038740158081\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:87.6288911819458\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:92.18826045989991\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-2969.124855804443\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:93.30914840698242\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:93.18709926605224\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.60596985816956\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:96.43476539701223\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.26009681597351\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.47425339221954\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:99.25231263637542\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:95.90993578433991\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.6887963719666\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.6677029132843\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.60243044160306\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:96.4284752521664\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.55475644655526\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.6743681460619\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.60952266082168\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.65656601488591\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.58246707767248\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.59978309292346\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.69080797722563\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.67129626572132\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.38013819330372\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.04990418255329\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.38250226737\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.94975732155144\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.24697496751324\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.19350803270936\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:92.75503159351646\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:86.2585917815566\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:92.94364041239022\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:95.48224029690027\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:87.18977522850037\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.26497068181634\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-423212.66718750005\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-402741.81953125\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-578120.6281249999\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-142109.66621093752\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-439456.373828125\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-133874.35126953127\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-5946.233427619934\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-3012.5026834487917\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-560.7436486244202\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-4611.878606224061\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-897.4339445590973\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2192.721347618103\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-26.90359562039375\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-75.98642418384551\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-170.42778385877608\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-111.74466851949694\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-229.80894709825517\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-68.02042397260666\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:87.96243614591658\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:75.85605483800173\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:83.64533273279666\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:85.71718923598527\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:81.78686882406473\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:89.10880882665515\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:89.95483644716442\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:87.26328481845557\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:87.0727513089776\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:79.00892720445991\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:92.25446491986513\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:90.51534760892392\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:82.48709479123355\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:92.45268874056637\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:88.98093654513359\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:78.0418909035623\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:72.24943279996513\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:91.6142045326531\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-111050.88935546875\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-714844.5050781249\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-33365.916674804685\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-49224.94377441406\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-176343.39423828127\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-373833.469921875\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-126.70954725742338\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1791.2541141510007\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1621.1288841247558\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1246.4096991062163\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1847.3191370010377\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:65.86894805431366\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:66.94531046822667\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:95.66962243318558\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:70.47208895087242\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:72.43750960603357\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:62.41025052517652\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:79.80414399802684\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:86.56387597620487\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:82.3562820315361\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:85.10957013741137\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:84.90912682637573\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.36399227492511\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:85.24770957641303\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:91.50732125118375\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:95.04305019155144\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:95.13310708999634\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:94.64405354224145\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:95.12858179695904\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:86.22038656435906\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:95.66979222800582\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:60.24584838598967\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:85.91594538874925\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:92.68903060257435\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:69.77694968879223\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:93.44266251185908\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-311663.06328125\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-7845.930712890625\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-198650.72197265623\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-140740.28496093748\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-46198.90922851562\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-87639.95185546875\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-674.4328406810761\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-354.76016952991483\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-257.04143598079685\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-300.88443114757536\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-785.6854138374329\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-529.4667534828186\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:97.61672197431326\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:95.02188609465956\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:86.98869226574898\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:90.43078310191632\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:81.44152529090643\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:91.55344297364354\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:95.11956068556756\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.97874564304948\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:91.33119044043123\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:90.87310585007071\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:93.42625301810912\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.15848383978009\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:93.41601947396994\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:93.45656057242304\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:86.84440460205079\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:94.11913202218712\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:93.33761667460203\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:95.6796201724559\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:77.25464742183685\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:89.70442185513676\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:73.07575422823429\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:87.84054423719645\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:90.95177041143178\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:96.64400020688772\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-95409.26948242188\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-104510.72822265625\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-19843.8005859375\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2031.3800399780273\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-12018.507153320314\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-24578.703540039063\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:58.3723748922348\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:64.00984315872192\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-48.38714702129363\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-0.04529180526733345\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-221.85004239082335\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-260.94936389923095\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:95.99419043362141\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:95.40727145522833\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:94.11306135058403\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:95.31969059556722\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:96.07089166529477\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:95.65426105409861\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:95.85720165092498\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.48085236139596\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:97.11999529749154\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:96.56424822132104\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:94.96716101020574\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:97.8570958878845\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.73858254402876\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.48903016671538\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:92.4030466388911\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.63476309403778\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.99482822045684\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:93.43027884550392\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:80.28931022956968\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:94.00268720574677\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:74.32502252086996\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:88.98381527736782\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:86.84677806273102\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:90.32604738250375\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-3903.6759918212892\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-379.3420379638672\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-790.4627258300782\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-14333.31474609375\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1331.0457641601563\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1409.207112121582\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:80.5106567621231\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:65.17554907798767\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:81.4344253063202\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:86.4406445980072\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:75.22078523635865\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:81.28931491374969\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:93.72564858943224\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:93.4124571442604\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.55927999764681\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.56928057409823\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:93.49447431638836\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.32266695946454\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.4965611943975\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.63360165581106\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.61781894117594\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.59428032487631\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.43615826778114\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.4845432555303\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:94.10809381231665\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:93.9392877459526\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.08676333278417\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:95.36091235503554\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:95.96998668834567\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.3445649344474\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.70340112149715\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:93.71900458298623\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:72.04476007968188\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:93.71327461004257\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.6831682576798\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.7537292316556\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:94.66647453308106\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:93.90709037780762\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-70.69649047851563\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-1557.8185623168945\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-223.72737579345704\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-1083.0662315368652\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.34896831512451\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.41898617744447\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.68514111042022\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.67372028827667\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.64534084796905\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.69033033847809\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.64601773023605\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.55323721170426\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.54814592897891\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.71774309799075\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.72309291511775\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.0474781036377\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.73781421659514\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.73107735663652\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.71799163343384\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.73192504541949\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.72160011641681\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.75857634916902\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.51644912771881\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.27024771273136\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.68275097310543\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.0809924555011\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:97.90992406979203\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:95.37238354310394\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:93.79808059260249\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:93.66793163195253\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:93.70040045455099\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:96.60304388999938\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:94.55958863571287\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.75217894464731\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-21269328.77421875\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-38607157.327185825\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-601396390.125\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-180189268.1109375\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-809194902.509375\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-483520734.56562495\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-127117.42666168214\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-52480.73697814941\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-11739.664943885804\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-128014.74629974367\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-102696.9458618164\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-22208.69391937256\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-17.8698351174593\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-1.948233526945109\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-92.96363548338414\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:17.004791887849567\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:49.85300542861223\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:3.1604597747325935\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:92.845787358284\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:89.32727443911135\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:94.7961831793189\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:91.36371640004216\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:95.23274400699884\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:88.58894237205386\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:74.03772853910924\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:67.43030098788441\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:87.19659245088697\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:79.99670058004557\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:92.03321593794972\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:91.7589030141011\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:87.6099621489644\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:73.69250582195819\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:90.77818411886692\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:91.20760356932878\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:78.70830911025405\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:93.76951194349677\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-99642.49702148438\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-17743602.394542694\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-175332.78632812502\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-94309.13872070312\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-2683274.8948257444\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-101495.83305664062\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-3571.5703552246096\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-2987.9213745117186\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-3343.917315673828\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2751.180035400391\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1194.3915459632872\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-438.2280891418457\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:94.42959440909327\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:94.83501466363668\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:88.82422496825455\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:90.41094876527787\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:76.81240171045064\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:70.35243563652038\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:96.23820126578212\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:96.99622388519347\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:97.17743238629774\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.40080951773562\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:95.51447424348444\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:94.40819080285728\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:92.76359140668065\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:92.22292350847275\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:93.32243923498318\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:93.36883173249662\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:90.82189810425044\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:87.00403254646808\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:81.71501276418567\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:93.22274562679232\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:63.686448423564435\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:93.67620852552353\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:76.80761717669667\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:92.68678324688227\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1487962.9950195313\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1415427.809375\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-19005.497020721436\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-665478.2453124999\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-638034.8859374999\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-574356.9074218749\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2662.5170166015623\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1172.1253807067872\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-290.7635862350464\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-4062.5424926757814\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1468.6876838684082\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1685.6491500854493\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:84.20811538994313\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:84.20814337432385\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:95.33452763520181\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:90.53317721337079\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.75448883026839\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:94.46831137686968\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:96.96995904706418\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.8724077358842\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:98.61268489398061\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:98.2605539433658\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.11709081567824\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.09680181238801\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:94.4109065130353\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:95.55129736913368\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:92.27371566481888\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:94.44840623075143\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:92.71117043942213\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:96.35914841629565\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:84.48316859155894\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:92.52946365829557\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:91.60253453142941\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:88.83288571462036\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:73.17505792006851\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:84.76446307450533\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-334245.0421875\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-403281.64807128906\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-401370.6525390625\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1782789.528125\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-59639.833300781254\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-901890.7\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-677.4918144226074\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-477.71796531677245\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-363.52844886779786\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-292.3402244567871\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-208.9697057723999\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1964.3581802368165\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:99.61890225559473\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:95.44239347279073\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.81609375588596\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:98.51710581481457\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:95.81837320923805\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:91.15295717716218\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:99.51049728635698\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.10229531489313\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.0468663342297\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.40060789529234\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.79830033127219\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:98.71864064335824\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:97.06099573671818\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.75815675258636\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:96.7944811547175\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.89328334592282\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:91.6069335144013\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.02170854024588\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:72.46241645812988\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:78.23012196421624\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:89.75172888673842\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:94.9378003812395\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:93.18869093265386\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:89.78023557495327\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-435169.557421875\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-537547.9753906251\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-689105.3972656251\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-267432.8440551758\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-412498.899609375\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-283027.9279296875\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:63.671019220352164\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:71.18695325851441\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:55.1368052482605\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:65.4956931591034\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:44.58565063476563\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:50.27954157590866\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:93.68494896441698\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.69984980821609\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:94.54083384685218\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:93.65342662688346\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:93.55970067083835\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:93.5012105166912\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.5439987950027\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.48538609296084\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.45396605017595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.54400070793926\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.42633196869866\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.5092011243105\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.6185298629105\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.49233011975885\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.150416566059\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.497693281807\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.65270154764876\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:97.80880067422986\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:80.4659349039197\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:95.01972091794015\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:94.91111607532949\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:85.98506125845016\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:94.44580149482935\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:85.25263852439821\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:82.47549324035644\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:93.6506191253662\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-3406.7143981933596\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:81.911328125\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:85.89057273864746\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:94.37454147338867\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:93.69126558303833\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.67733861207962\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.6758498430252\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.66297702789306\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.69579710960389\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.70150198936462\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.45889553930611\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.7419329404831\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:93.68687568902969\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.68710082117468\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:94.6733353599906\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:93.6869848281145\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.65034865159541\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.49951964989305\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.68905048239976\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.59132150262595\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.60780156739057\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.65986983813345\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.04891582131386\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.57806366682053\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:98.91282108575106\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.26422851023963\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.19359575286506\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:98.45231222435832\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:96.4041202859953\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:87.61130141466856\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:96.07309334501623\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:96.30394954811781\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:94.16968204304575\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:95.01826314926147\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-112803.50913085938\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-6214.748205566407\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-193127.7067504883\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-193496.21395874023\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-113066.34020385743\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-33045.26728820801\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1548.9359287261962\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:36.29538106918335\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1091.3188759803772\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-401.83481252193445\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1846.3828532218934\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-81.03741720914842\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:44.56025652885437\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:52.79483816474676\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:50.84922202676534\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:21.67058315873146\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:72.60993272662162\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:37.26886449456215\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:85.77143944092094\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:95.07343828603625\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:77.08462524414062\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:77.24594479501248\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:86.23300588093699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:87.35984757319093\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:85.91393116638064\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:94.9059371303767\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:96.92674536146224\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:92.06715881638229\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:91.41911447420716\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:88.44583606682718\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:86.84228640198708\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:72.1520110592246\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:84.12880801036954\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:75.96808619052172\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.28433565795421\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:80.19910592138767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-40889.085620117185\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-52954.64653320313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-122563.62120361328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-64143.17048950195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-95958.0095703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-69668.17451171875\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-257.21029567718506\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-402.25799427032473\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-3.7324106216430675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-435.49366376399996\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-663.7909248769283\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-194.90984603166578\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:77.46930337622761\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:83.67491508349775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:83.68746217153966\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:94.45312495678664\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:81.1325331941247\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:78.37424646988511\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:89.3583316322416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:96.58029791191221\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:94.51353740617633\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:89.20631233751773\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:91.0761896379292\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.50657018888742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:91.56058185566216\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:91.87416701354087\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:96.74293730772334\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:75.28140779212117\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:79.51978570893407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:80.18652255609632\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:94.29669730365276\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:79.71423506736755\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:78.47644689232112\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:80.90879550874233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:89.29677080325781\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:74.69023435711861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-17957.897717285156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-45016.419750976565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-9204.435961914061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-35459.55375976562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-35783.14165649414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-56485.73784179688\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-284.8967486023903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-517.200817155838\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-196.33389236927036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-816.9064120292663\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-81.01841411590576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-150.4416296303272\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:85.33690692186356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:86.38072317838669\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:89.37398368641733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:93.61165910810232\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.70679637417197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:89.91983222514392\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:95.50262940116227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:94.0336248986423\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:93.49823681712151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:95.21692293211818\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:94.25511160837486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:90.39092583358288\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:91.64915989674628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:93.33244741372764\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:92.7451804343611\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:93.09388365149498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:94.13565594553947\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:92.89893634840845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:94.6188121855259\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:91.78916213456542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:93.13042267691344\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:71.52513428032398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:85.51109749153257\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:88.98191406168043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-15336.986010742188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-18198.103100585937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5703.67672405243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-21610.761791992187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-6653.651552009582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2532.11731262207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-95.07580342292785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:22.443945002555843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:4.954684102535245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:66.25985107421874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:47.73051983118057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:5.497211766242982\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:96.090671646595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:96.54507353897206\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:98.61827561752871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:97.07952306536026\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:98.88482180014253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:98.30736834816635\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:96.651296141278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:97.27979464018718\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:94.1848428696394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:95.45248366370798\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:97.69665367603302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:94.05625479593873\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.78595721721649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.74945423826576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.80779720321297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.46963682137431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.92676227455958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.67813731618226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:93.65570780038833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:77.62177336663008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:88.31034104339778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:93.79700160250067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:72.90705304890871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:87.23456502854823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-182.2119171142578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1062.18028717041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-15656.259472656251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-162.00584716796874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1122.4956924438477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-806.8781311035157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:80.39228565692902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-58.16064624786377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:95.53821086883545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:91.14805324077606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:94.5587643623352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:83.89267266988753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.74377718865871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.71912226304413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.64861697107553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.49397899769247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.71469309031963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.63923332691192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.53678055789787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.25920469984412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.56628081053496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.49056172054262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:98.73420074433088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.58091377615929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:93.77744101285934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:93.73651786968112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:93.59543901737779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:93.83504591807723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:93.72135255672038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:93.91705625839532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:92.47430552765728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:93.69598697535693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:93.67778054699302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:79.29741480872035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:90.8219781205058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:74.19651658982038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:93.73407974243165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-8210.824353027345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:93.86231536865235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-2720.1939041137693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:90.81479873657227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:75.23588485717774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:98.27964618206025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.6608515381813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.23507068157197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.82889111042023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.68617825508119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:40.06239695549011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.75215473882854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.72065182328225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.39656408429146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.78995049223303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.54727532975376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.78367940243334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.71585845053195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.73262642621994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.7694972248748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.73083238601684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.73568662032484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.71554914601147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:98.75400315523147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:95.952850625664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:94.63763206936419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:97.43554774839431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:97.50957793705165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:93.76750592812895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:93.67716232389212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:91.21803284436464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:93.72146609537305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:89.08638555519282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:94.1183293396607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.70531612001359\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-46960.81875619888\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-32958.84360427856\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-170891.5254693985\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-8665.360814619065\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-50134.76225624084\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-6071.27873544693\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-173.3153541326523\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-73.35359372496606\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-112.88298320472241\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-98.17184314429761\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:16.99252017438412\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-670.8527571141719\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:65.00342903882266\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:85.07819399721922\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:43.53071521073579\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:40.43216998763383\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:12.455051048845057\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:13.111391750350599\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:82.7071818381548\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:85.33761235978454\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:93.12030695509166\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:92.42930317055435\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:93.00351850762964\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:94.16581244524569\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:88.87404437493534\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:86.05308023889083\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:91.56676936578006\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:78.56013735765592\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:91.59151879772544\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:91.25918096750975\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:78.36669177487492\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:81.13588418103754\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:81.63095247931778\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:62.78737767487764\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:86.25737942717969\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:88.48475041948258\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-248137.81737976073\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-362936.1740715027\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-314702.1708105087\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-195082.79907226562\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-327127.6091596127\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-455784.93721923826\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1709.229699242115\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-2128.9149427533152\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2541.5359969615934\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-870.9902566075325\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-6229.8150827407835\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3810.819653403759\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:74.54851990155875\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:74.06788478679955\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:80.58969021849333\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:81.56989482529463\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:79.98857003264129\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:69.48115868344902\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:96.28343897275626\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.12320739589632\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:95.73865908011794\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.59130516485311\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:94.16168264579028\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:95.3033546898514\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:93.58838689606637\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:95.13806956447661\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:94.20194521285593\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:89.85766917206347\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:93.25403081793337\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:92.24468775205314\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:85.31821428313852\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:75.6965569877997\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:88.39804924665951\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:81.88339779637755\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:79.3817565780133\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:86.86097783818842\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-63952.02653484345\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-111732.43484573363\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-155980.1152496338\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-97793.69971637726\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-127571.55306034087\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-107047.17465705871\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-167.9371486544609\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-226.88922595977786\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1755.6305383443832\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1235.9242539227007\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1114.8528783798217\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-393.56825543642043\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:91.73513636775314\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:91.76989675685763\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:87.52837117761374\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:94.00869847610593\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:90.00522116366774\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:89.97536020502449\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:98.05411103405058\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.56716599902137\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:95.84247204139828\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:98.14801713973283\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.14327923581004\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.1420193489641\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:92.47056800723075\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:94.6297464992851\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:92.89220432995353\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:92.95825350135564\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:95.71283794846386\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:95.1681981574744\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:79.81278379671275\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:82.43506438992918\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:77.61653510406613\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:86.66067709922791\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:83.26056159436703\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:81.94113730564713\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-12289.542046165467\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-30371.37213459015\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-14198.6713889122\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-26408.074526977536\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-15783.49369058609\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-18967.24544181824\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-131.75208957195284\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-50.8409761428833\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-82.69952411651612\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-164.42312371730802\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-85.78391664028169\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-77.5976432710886\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:95.70982914883643\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:96.37650187909603\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:94.71356388572603\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:96.09367102701218\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:96.43650681190192\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:96.64316040501\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.91685685291887\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.78101074546576\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.23942266418598\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.11676392678636\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.02271102629602\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.07067081369459\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:97.2322189741768\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:95.71474706456065\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.6765543717891\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.65378360264003\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:97.05943339690566\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:95.54997566714883\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:94.27925652433187\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:93.84962069131434\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:82.96123159378767\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:89.53142166920006\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:94.66782984016463\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:91.41471137162299\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-7018.492800331116\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2550.8466386795044\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1434.1227622985841\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1553.1122457265856\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-5704.667900848389\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2192.4915475845337\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:62.60360069870949\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:83.22652423381805\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:82.07844859361649\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:79.09458252340555\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:58.251732611656195\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:84.49743857383729\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.27073333784938\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:98.65825857594609\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.20573472306133\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:98.80969099756331\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:85.20298467129469\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:98.8072954967618\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.55257227048277\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.32419760338962\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.53917197212577\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.51430319682694\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.38458823934198\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.50046985559166\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:98.50703486548737\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.17346650399269\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.23337291069329\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:97.05521026868374\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.46957860456314\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.04654037058353\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:92.70657558813691\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:93.34880695305765\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:94.89412365928293\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:88.5299620276317\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:94.54493146650493\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:90.08586808741093\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:30.67666702270507\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-717.5159198760987\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-655.120814704895\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-1006.2159734725952\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-316.28309440612793\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-557.6644956588746\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:91.33454520702362\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:92.54048489928246\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:84.65969216823578\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:89.38420767784119\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:88.55055220127106\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:91.2442840538919\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:95.06940926648676\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:98.75435088984669\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.42716600988061\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.32994462344796\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.61061283573508\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.46121347714215\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.63135406672954\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.64711587801575\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.64758731499315\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.6678687915206\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.59551446065306\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.67805772945285\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.34358122849372\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.06438082791865\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.33747139051556\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:98.83957318067552\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.25647415667773\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.31082088537514\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.84599456973373\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:96.23678582645952\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:94.19674315042795\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:95.80605028644204\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:95.6897710159421\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.6413054458797\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-357425.0017578125\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-995725.17265625\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-683074.7332031251\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-59426.03325195313\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-35225.56328125\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-692885.7160156249\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1367.1975164413452\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-6501.221360778808\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-7097.24201965332\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-11219.211295318604\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-4769.695471572876\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-738.1815271377563\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-551.088289642334\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-434.3255484104157\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-371.0701122283935\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-520.9164178133011\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-603.570194387436\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-424.1876810789108\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:35.94788357317448\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:59.717281158268456\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:45.59861444830895\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.1244452059269\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:77.57001449242235\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:44.896808764338495\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:95.8774787530303\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:96.35313637964428\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:87.50767543129624\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:52.22847511023283\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:92.27076430879532\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:76.381110637635\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:92.47615259476007\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:86.47366770170629\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:86.82754156775772\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:90.0060455173254\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:90.20718079991639\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:93.97041048184037\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-743129.5183593751\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-188525.49873046877\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-633682.9816406249\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-1247451.97578125\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-2088450.075\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-838935.471875\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2354.418456554413\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-895.4005637645721\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-13592.540209960938\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-14126.991997146606\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-696.3282220602035\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-22.558847427368157\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:18.310748761892313\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:37.84964188039302\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:84.30062773227691\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:32.36504437625408\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:14.241386353969576\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:39.067049509286875\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:83.94805665314198\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:84.66576444096863\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:86.61271618157626\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:84.53390900567173\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:79.20149267017842\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:81.95727069675922\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:95.8275961920619\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:89.4685034841299\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:91.12819828093052\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:93.16566529870033\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:83.67770031020045\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:96.09182357676328\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:92.60366313047707\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:85.14887517876923\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:77.47199536636472\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:93.00420750193298\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:93.44228644482791\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:73.56912176832557\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-430198.020703125\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1374947.04765625\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1230367.503125\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-749381.4714843751\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1212393.0890625\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1019967.0671875\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1138.558211517334\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2121.069485473633\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-3297.4381988525392\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2037.8565450668336\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2107.789570617676\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1008.9356811523437\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:71.8119960397482\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:75.8918729543686\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:71.21917836964131\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:71.89194563180207\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:69.82695264220237\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:79.22504029273986\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:88.86520551294088\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:94.00173512399196\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:92.37247300874442\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:95.60835302192719\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:95.58724910002202\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:90.74379615150391\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:96.41765256226063\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:94.73711610250174\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.97286803908646\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:96.39325596131384\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:95.17011495530605\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:90.67463485710323\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:92.63034593500197\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:96.39109100624918\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:88.94888985604048\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:84.97604908719659\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:94.69644013457\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:73.67602318152787\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-136265.39130859377\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-262122.8498046875\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-260509.8162109375\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-184530.26298828123\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-153255.56464843752\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-277224.147265625\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-127.56771392822266\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-344.4185192108154\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-438.5967595100403\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-2626.581233215332\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-3581.598812866211\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-656.8312223434449\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:89.56508430242538\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:95.27176364362239\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:94.23177179768682\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:90.18443574905396\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.12436097562313\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:93.26372264176607\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:95.69266849458218\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:95.93494968507439\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:96.03399991020561\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:95.83055431973189\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:96.50482570221648\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:96.74046159870923\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.96251998357474\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.64936826506164\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:93.96786780953408\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:94.7157666908577\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.6458539403975\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:92.37791521772742\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:93.76014858558774\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:92.14600276201963\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:96.06193781867624\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:92.96647929511964\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:89.69516554493457\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:67.74214303940535\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-96895.71967773438\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-8276.692431640624\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-31237.190478515622\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-32207.948535156247\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2169.394915771484\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-136212.54707031252\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-184.8648483276367\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:63.9421130180359\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:85.22374455928802\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-2176.751559448242\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-157.00034446716307\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:70.27916259765625\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.54123217239976\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:93.58586658556014\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.42933569252492\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:94.19598442958667\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:98.95365376770496\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.07108734250069\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.55530734919012\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.14297383669764\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.39790835268796\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.5610941015766\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:98.79251825734973\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.24463984593748\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:98.8843983149156\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:95.31051264815032\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:94.34987777192146\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:95.93698979504406\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.58048147670925\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:97.62761711291968\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.80173745974898\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:95.13519494794309\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:93.51319490782916\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:94.08285680115223\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.56321848109364\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.84552093222737\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:94.6652208328247\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-3079.7874862670897\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-4583.706134033203\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:93.85228576660157\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-1178.9966171264648\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-57.056767272949216\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-230.3316467285156\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.49118961989879\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.69175616502761\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-12.9761999130249\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:23.30363957881928\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.68137969970704\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.58956080675125\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:93.68671195656061\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.69909592866898\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.6871671795845\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.7403402671218\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.64560533165931\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.73671020902694\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.736118638888\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.72460518479348\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.74205663204194\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.72866601571441\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.71573128774762\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.58230187725276\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.62817824645899\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.56521962657571\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.53690953813494\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.56191592980176\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.57480909004808\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:93.91878827754408\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:93.8463277861476\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:93.96092053875327\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:93.90759221874177\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:93.77754915524275\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.53882478838787\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-99241008.17792968\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-5777411004.45\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-5170213771.85\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-499545363.05864257\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-3213598200.35\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-8001861246.150001\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-945399.9224975585\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-60614.59215698241\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-55139.23856582642\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-155264.78921661378\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-576607.6892059327\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-45901.18326187134\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:34.26754645742476\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-570.787965118885\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-400.705238366127\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-108.97364690601825\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-62.743824066966766\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-163.05573162436485\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:88.81774957925082\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:92.21434813700617\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:81.07074504569172\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:88.12797593474389\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:93.22420510388912\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:89.7809612981975\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:94.27936809565873\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:94.802086324431\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:63.94115376472473\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:92.82226637750864\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:94.37863683216274\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:93.23400641977787\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:82.4077819172293\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:80.63997889608146\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:93.72235389510169\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:90.59340664409102\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:92.75181932896376\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:81.59390972964465\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-686057.7374999999\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-524616705.6221909\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-89398.7287109375\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-332027.5896484375\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-58560060.27744141\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-916891520.1575196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-71.32455654144287\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-6123.152084541321\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2122.5041931152346\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-10631.938089561463\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-84967.36226291656\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-11480.12147808075\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:89.15488432012498\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:93.9391905784607\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:52.82868079245091\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:96.5178722858429\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:83.45916513167322\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:40.94313502311706\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.85982249365188\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:97.83582513257862\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:96.61292041484266\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:96.60993739608675\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:97.49268607478588\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:98.0223225035239\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:93.27225499078632\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:95.58984866235404\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:95.64201709199696\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:93.98658350780606\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:94.34376694597304\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:95.20984393637627\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:94.15734476875514\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:94.06511572478338\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:94.3460164790973\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:91.64378977185115\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:91.14000203339383\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:85.65016524177045\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-433898.073046875\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-987011.975\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1863179.8078125\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-832179.12421875\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-244263.1330078125\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-690330.3484375001\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-4343.598406982422\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-3831.5039093017576\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-128.34888153076173\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-3479.882662963867\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2010.6241638183594\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-31.498438644409177\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:82.51974941790104\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:74.40924143791199\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:73.6283851891756\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:85.72160545140505\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:60.15200573205948\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:86.8953338086605\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:98.74428462944925\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:98.98949024789036\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:98.47158251162618\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.85336324269883\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:98.2768174001947\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.59475694410503\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:96.5416486285627\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:96.11561444113032\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:96.2996864611283\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:96.9138314474374\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:93.40999391302466\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:96.19379906448303\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:80.09421798251569\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:88.40935293678194\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:92.24595783706755\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:93.45295023377986\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:91.92628637347372\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:94.39814841412007\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-660534.2999999999\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1850514.7234375\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-3606527.0281249997\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2052429.6125\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3972375.759765625\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-5445243.284375\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-550.9520942687989\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-988.3940284729003\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-4464.5673191070555\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-3253.0836517333983\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-5773.730236816406\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-5188.259356689453\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:93.94145555496216\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:95.02678612545132\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:93.93300361633301\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:87.71779049038886\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:96.1491322375834\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:93.93322918862104\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:99.53588656592183\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.25206784531474\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.28415243253112\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.09887071102858\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.36495801880956\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.3098650877364\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:97.81668289173395\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:97.66344120167196\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:98.44472203431651\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.67678795009851\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:98.39392094500363\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:97.90533108040691\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:95.41152921654283\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:81.3205454647541\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:93.65766701437532\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:91.15243850778788\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:89.74683176651597\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:92.91974940923974\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-4984.891659545899\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-254241.81953125\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2586131.7609375003\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-150935.48408203127\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-4388303.05\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2791329.466113281\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:4.121791791915896\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-98.72696533203124\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-470.32628707885743\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-90.96873455047607\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-1.9637996673584013\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:90.23039050102234\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:94.13966204822064\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:93.36320274472236\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:95.30343455076218\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.6242446810007\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:93.38206981420517\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.25831176787615\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.66231111809611\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.5330396283418\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.54209770541638\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.63824275266379\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.65291809346527\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.64433700011578\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:99.07968905922026\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.5204525096342\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.69864878095686\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.53504947684705\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.88452572957613\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:99.09674519323744\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:95.60008906833828\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:94.7375306006521\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:94.40045688254759\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:96.38879579426721\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:95.45321266613901\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:94.83303539194166\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-7.367652130126956\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-191560.98457031252\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-2556098.9031249997\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-1216638.25859375\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:75.85303431749344\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-177390.91621093752\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:92.85452580451965\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:94.75503950119018\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.71431157588958\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.67412600517272\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-59.740690422058094\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.70175218582153\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.68712475001813\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:93.68676654994488\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:93.68671337962151\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.68707717657088\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.68676934838295\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.64734858572483\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.68845415227115\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.7332254588604\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.59446602924726\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.68434939086437\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.7678792483639\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.63082555383444\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.38435651622713\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.37501354925334\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.34481031030882\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.45455354079604\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.29188548736275\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.24427521266043\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:97.77784286099485\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:94.48733205497265\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:97.46149498932064\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:94.60652614682913\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:97.61515999822878\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:96.47664036117493\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-89222.59091491699\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-30622.081484985352\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-8959.623323059082\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-49401.83432464599\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-129406.25916137695\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-29936.84415893555\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2036.2395810127257\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2585.6882981300355\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1240.785931301117\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-766.8208762168885\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-306.1791290283203\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2059.118778038025\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:20.983733683824536\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:11.411996516585354\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:15.12831183671951\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:29.489368122816085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:39.437702220678325\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:12.54703554213047\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:96.3805712994188\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:86.70531802922487\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:94.07500540614127\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:87.79700686261059\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:94.47514882273971\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:89.58495442308485\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:91.9525900280103\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:93.53913175556808\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:95.91969676837326\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:94.52011056989431\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:80.26906062290072\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:85.25747953727841\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:94.59454520270228\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:94.54331843331457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:88.47871012054384\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:95.56386544629932\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:77.0000150643289\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:86.4771837696433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-160115.24482421877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-149846.91337890623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-351634.987109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-165413.12431640623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-99097.2638671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-137943.77280883788\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-694.8576898217201\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-868.5747210502624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-706.8368682146072\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1093.8171324253083\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-504.8483593940735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1388.2272413253784\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:76.10038036853075\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:78.89631355404853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.36782614886761\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:77.01971711590886\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:71.46169096082448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:87.47566938586533\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.58775499388575\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:96.11142737083136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:96.14470053445547\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:88.86575630009175\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:96.3720742404461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:88.4662886030972\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:95.5441576837562\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:95.65344369709491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:89.22620213888585\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:92.16058307103813\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:77.78853723853827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:91.87005525864662\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:80.2081987157464\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:86.51599746458231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:96.31615445595234\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:81.14196925163269\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:92.74763837717474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:92.81969792153686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-41527.1477355957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-51711.4324798584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-142248.35029296877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-73880.61507263184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-167113.20625000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-153954.41718750002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-304.503796672821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-516.9103424072266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-756.1196993350983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1103.9425230026245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-499.2721765995026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-128.08584938049313\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:94.64907598979771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:91.33394045233727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:92.61493744254112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:94.3149267449975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:90.75606677681208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:89.1853288680315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:92.88972024768591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:93.48098060153424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:95.8085164833814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:92.23662305735051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:94.97646433291956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:95.03844247404486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:93.41330474764109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:93.79381981957704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.55595471002161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:95.7605079099536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:91.91753968298435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:93.85601816512644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:88.64486096315086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:85.8230252262205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:95.57172917146237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:93.11559331119061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:93.91932056806982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:83.12969268932939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-24797.494738769532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-22050.75554199219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-34435.938793945315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-5898.810427856445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-34528.199536132815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-17671.411307525632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-337.28470001220705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-361.9396450042725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-133.2688422679901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-335.5703260421753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:6.441789352893834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-108.12023429870608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:96.77705213800073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:96.32578134685754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:97.05547616723925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:96.63506597578525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:97.27073451029136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:97.3741620451212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:92.74927663654088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:98.0899763757363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:95.43111067600549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:97.49429263621569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:97.70335223525763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:96.63940386758186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.12622203566134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.3568600513041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:91.84862820804119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:93.92415324598551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.9597410481423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.411983827129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:92.83800257127733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:87.64607874564827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:87.70119507983327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:88.79115075655281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:88.03951629474759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:94.49494210593402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-3963.511126708984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1291.1222869873047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1557.10126953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-674.7792785644531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-4969.196932983398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-588.4279663085938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:86.31627337932586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:58.85629132688046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:75.71882874965668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:44.41004648208619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:66.2135060429573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-148.8730152130127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.70525172799826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.73881592005492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.41077647730708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.78845657482744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.53881304338574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.69834620202892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.5652547352016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.23106505647301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.55853671794758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.60852559916675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.57249985709787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.58091880306601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:93.78028409089893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:93.74873144254087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:93.78425547592342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:93.7185422245413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:93.65714016426354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:94.22999982918263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.72932881191373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:94.83730132933707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:93.69110416062176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:93.71875966247171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.68806981630622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:94.94166715145111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:94.71429424285888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-53643.64750976563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:93.13731842041015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-28.836972045898435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:93.44071388244629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-1470.0292045593262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.66648079752922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-53.11700942516326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:95.20481381416322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-396.8833996415138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:98.26444421708584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:97.11645075529813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.7201625391841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:99.69114636182785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.71928868182005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.6006649557501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.77005193307996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.72071332931517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.76526087969542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.72753767855465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.73432278363033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.7605628490448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.30635558012872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.71374691314995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:97.28902096720412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.31839166423306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:97.01588286608458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:95.25988556854426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:96.64537481497973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:97.05244283415378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.23485443592071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:93.69785178769379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:94.34937644004822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:95.9913459122181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:93.69432691521943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.17671221904456\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-116929.26160907745\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-188107.76668395998\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-69727.05922203064\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-116523.82359118463\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-166188.32942199707\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-860698.708734131\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-788.3031235128641\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1055.4337578803302\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-10364.972090414167\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-5743.584176531434\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-625.1149355858564\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-384.4302646994591\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:17.407041841745375\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:25.15795726031065\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:66.55605644192546\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:28.155293220095334\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:42.214208871219306\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-12.441281352937228\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:94.44256737716496\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:89.38166309250519\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:87.00235856547953\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:89.8770362354815\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:85.54964539278298\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:92.53656301274896\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:84.01482249815018\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:75.90847154147923\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:90.61827951529995\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:93.28121151430533\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:87.06722341123968\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:81.55607049316168\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:91.9902772884816\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:76.98380839973689\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:79.1682118743658\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:80.04161419980228\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:82.09918550513684\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:92.44791325945407\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-1077210.4279304503\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-458319.2742221832\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-1175449.7531982423\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-417144.87598581315\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1180249.656008911\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-1250821.3653477193\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-11350.504695260524\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-8411.106708824635\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-5409.010966968536\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-9984.703710126876\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-10396.410363902152\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-12843.996628332137\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:60.306753462180495\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:48.11209685821086\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-30.749349809437998\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:-0.9197710182517804\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-8.008045879751435\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-0.5969073571264749\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:96.92635672092437\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:96.46407785834744\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:97.15066660419106\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.83308117985725\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:96.3961424164474\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:96.11753410119563\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:92.59661428472027\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:94.22460421994329\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:93.49528149128892\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:94.45041555399075\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:93.97021890841425\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:89.08903181459755\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:91.03662919644266\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:85.07165361177175\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:91.06019539684057\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:92.6127987860702\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:90.55139372418634\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:89.87609894908964\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-328833.4713638306\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-377987.18337078096\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-211958.05926132202\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-439628.9843191147\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-511311.87116241455\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-301931.640271759\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2227.7360332250596\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-946.7169786930084\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2308.806565785408\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-5157.432574144005\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-6587.424867153168\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1446.240156418085\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:78.96174341067672\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:69.59317130446433\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:75.13395217135549\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:54.50870151221751\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:67.59489277750254\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:78.79135060459376\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:98.4501402192749\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:98.7220712184906\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.79162981025875\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:98.2491910382174\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.63371169790625\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.36873822631314\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:97.52289749123156\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:97.05923999333754\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:97.86994785531424\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:97.60821674568578\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:97.15514104738831\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:97.25344496984036\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:92.61991138895974\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:87.74582279557363\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:93.58788740681484\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:90.00340673327446\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:90.79327425984665\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:90.40906386803836\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-99280.7387802124\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-84369.15459251404\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-45354.54226818085\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-64834.45668678283\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-89863.16831703186\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-39585.58467311859\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-976.634450006485\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-2629.541181218624\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1280.8107929229736\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-464.9071125984192\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-1430.3713545799255\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-526.6752591222524\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:89.36027506012469\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:81.80255733132363\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:89.18043660088443\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:91.68696202933788\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:87.18090464174747\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:89.86233275085688\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.98167642820627\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.25085243210196\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:99.03294124417008\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.15281491279602\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.09219541810454\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.06355083622039\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:98.74942073523998\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:98.23822420432698\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:98.65527346581221\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:98.39014430958778\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:98.18753293859773\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:96.61989916302264\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:91.69722446557135\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:89.84802126809954\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:90.86963039617986\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:94.85980408699251\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:89.25542669557035\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:92.69400582946837\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-16489.18874721527\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-7398.047736740112\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-11205.521430969238\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-11585.720648765564\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-12705.240506744385\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-6072.019326877594\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:54.32715251352638\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:12.171247500181192\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-3563.2573106408117\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-83.59278359413148\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-86.79593827724457\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-189.8596241950989\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:93.13396694213152\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:95.35553583838046\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:95.42816935516893\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:94.998604933545\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:92.0813415683806\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:92.87671945914626\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.48431702367961\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.4468182561919\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.5061728540808\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.44842833802105\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.46176012586803\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.46945809572935\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:99.06882430287078\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.95434565246106\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.9525806920603\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:98.8979550037533\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:98.96941663511097\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.73953250423074\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:95.42998517602682\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:94.67608844935894\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:95.73179857712239\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:91.23622888810932\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:95.56598316752351\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.9862679682672\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-474.47726249694824\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-2416.1973876953125\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-585.4251745939255\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-1527.4377658843996\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:90.03471069335937\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-3582.362543678283\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:13.10813636779785\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:80.57483312487602\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:35.100180339813235\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:54.80037395954132\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:58.14283916950226\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:79.308618247509\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:98.63207495324313\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:98.36715385764838\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:98.32365937829017\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:98.22898152023554\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:98.37033793479205\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:97.2566834077239\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.62602038243786\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.62794530577958\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.62880902439356\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.62446923144161\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.64305290207267\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.64088955335319\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.34157018312253\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.39708166122436\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.36224297918379\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.34559230469168\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.36973828533664\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.49051245339214\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:98.23539564013481\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:96.46268622241915\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:97.57542652189731\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:97.26583650158717\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:97.40771270721162\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:98.12093760110437\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-156284.18144531248\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-2123898.9484375003\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-1212921.559375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-2051547.340625\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-1765674.0984375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-2396641.6765624997\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-16911.413806152344\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-16676.933520507813\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-25303.06220703125\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-3021.5313369750975\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-5327.205426025391\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-27377.92229003906\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-824.0106840133667\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-1301.3083314418793\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-848.1541091442109\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-888.3547294616699\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-1365.9146592140198\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-1591.4438446998595\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:-26.452008098363876\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:-37.8437333881855\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:-71.34169895648957\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:-31.992933714389803\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:-57.86782964468002\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:-52.399008774757384\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:77.68591310307383\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:92.32086223363876\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:85.39549593254924\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:83.05142014622689\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:84.26362801864742\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:76.30120035782456\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:87.36854590252041\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:91.15824193079025\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:88.09252813644707\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:80.12871056720614\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:92.6669888837263\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:87.88450963422656\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-1732689.5734375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3418262.4250000003\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-3571085.2312499997\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-2515263.5968750003\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3880752.6593750003\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-870674.7354248047\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-52.60450296401977\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-55771.51313476562\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-22172.883374023437\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-68330.397265625\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-2049.962657165527\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:48.033884572982785\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-22.490186482667916\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:37.989303883910175\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:8.52296694815159\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:-25.31314305067063\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-30.14170108437537\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:9.105376818776135\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:78.13040350079537\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:65.3842556476593\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:74.78295273035765\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:79.33381233811379\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:96.06269816458224\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:80.14940229132772\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:90.68643151279538\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:93.40049115456641\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:96.09656624123454\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:90.2408468298614\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:90.56548196040094\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:89.63851761519909\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:90.8312700882554\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:94.35114510729909\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:94.97105942489578\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:96.4289474312216\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:94.56984672769903\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:96.0744405203499\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-4046668.4343749997\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-4244401.246875\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1670995.3875\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-4667918.434375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-854421.8708740234\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-4468893.284375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-46218.73955078125\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-247.42375068664552\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-49466.72797851563\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2298.9185745239256\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-7127.1990234375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-4373.227841186524\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:54.389301745593556\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:81.31769395023585\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:28.679145833849905\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:76.81956747174263\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:53.03204620182513\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:77.32042725868523\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:88.47769865617157\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:87.6385742418468\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:93.28133815657348\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:86.64536757990717\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:84.32977388836443\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:87.9961277011782\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:90.0711233805865\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:94.89577835071832\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.41401325594634\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:93.16369171431288\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:90.90800575315953\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:94.57371551580727\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:93.69041539411992\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:92.79228747989983\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:89.8899062357843\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:92.63544859383255\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:93.48026728257537\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:95.46446051895619\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-280043.2146484375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-106163.14873046875\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-39164.36333007812\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-693497.9753906251\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-238684.8126953125\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-35047.86811523438\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-11299.293749999999\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-15390.68427734375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-14831.201403808594\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-14862.9412109375\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-11940.02632446289\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1057.6799934387207\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:88.24293461367489\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:89.43414749130608\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:93.38178886137902\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:86.04112216085196\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:94.40705861840397\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:84.29864562675357\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:93.02024293309078\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:95.16849855594337\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:96.24770452082157\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:91.14464859850705\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:94.6382136821747\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:92.75762183684856\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:95.01479066917673\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:93.5271462360397\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:94.8352876536548\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:95.08892552107572\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:94.50354774221778\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:94.02790797129273\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:93.1819079734385\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:94.38142578275874\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:93.0550534080714\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:94.83480464811437\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:94.04649194628\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:94.32534954175354\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-41861.890942382815\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-150575.51093750002\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-76865.34248046875\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-212531.61796875\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-145804.22539062498\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-146654.58808593752\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-13.134533691406247\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-33.933251571655276\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-117.67175846099853\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-1154.4941360473633\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-307.55171127319335\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-437.3585636138916\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:93.19774222671985\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:93.11302633006126\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:94.06274589598179\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:94.53691754117608\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:92.52855977863074\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:93.50584938079119\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.06478905715048\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.24054856337608\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.23954177144914\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:94.32746123922989\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:98.66846722206101\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:98.41376877645962\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:97.75391154745594\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:98.20667080692947\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:98.44458511620759\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:96.93970712870359\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:94.94920300487429\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:97.30510955341161\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:93.8981481777504\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:93.79214454367757\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:93.82579917125405\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:93.68879462275655\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.69578413665295\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.88729771766812\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-3512.906414794922\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-1773.0447357177734\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-2854.070323181152\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:83.23349304199219\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-21691.090625\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:81.2397029876709\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-208.5032289505005\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:51.10088315010071\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:94.13718914985657\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:39.0414900124073\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.8660540819168\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:93.790988779068\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.68775422200561\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:93.67907415181398\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:93.68691551592201\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.6790954953991\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.68051525652409\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:93.66184566020965\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.73982148468494\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.70963610000908\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.7033590670675\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.74455191381276\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.69826845489442\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.69579489268362\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.5801479834132\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.61102601373568\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.56201430149376\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.58784105554223\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.61436649486423\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.60782667249441\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:94.52086573205888\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:94.58003604784608\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:94.48734366316349\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:95.55538344942033\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:95.21681173406542\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:94.04122854061426\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-4924911570.276074\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-32326880088.550003\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-16104755258.15\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-18165647518.05\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-8845955923.25\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-6442746617.75\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1468867.1644592285\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2122840.2689941404\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1212069.6483276368\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1132301.6534790038\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-3094613.5546875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1847912.9699218748\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-1025.0069803357126\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-1261.2671030640602\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-2075.6121928215025\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-345.4529399901628\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-174.30798458252102\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-2828.51602807045\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:63.89202103763818\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:93.98296793820336\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:56.611535479128364\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:93.13588163144887\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:54.036982296407224\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.89937180280686\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:89.8673836003989\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:85.33300251644104\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:94.32355938963593\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:90.36721397023648\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:92.34556576013566\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:95.15036346465348\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:87.38580665402115\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:94.60975135713817\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:87.6980838527903\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:93.5901988208294\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:94.67236478626728\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:93.37778446596349\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-1012676.8328125\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-218432.3015625\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-68828.70659179687\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-1069211.93671875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-8106715.456445313\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-81025131.82631835\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1154.7989303588868\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-23032.116859436035\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-32971.34223632813\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-396980.4408713818\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-25125.400012207032\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-409333.173914361\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:24.17214574813843\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-20.424916148185734\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-139.1845355376601\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:46.11080625131726\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-0.14023132324219034\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:8.36616658866406\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:97.89565454279072\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.22991747751365\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:97.22562260162086\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:97.70103132268414\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:91.77012516409158\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:96.10470067169517\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:96.4889733666554\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:96.72545937635005\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:96.47017054948955\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:96.16895958380773\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:96.40370114147663\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:97.34753124224953\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:94.09052582141013\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:95.56448156272526\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:94.72642843723297\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:91.24259324539453\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:90.53683327538893\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:93.18565694782883\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-512578.92890625\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-703665.3546874999\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-9309895.387500001\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-5537308.909375\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-328161252.43828124\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-3545586.6437500003\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-18280.404431152343\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-90518.6505859375\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-11925.625079345702\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-18471.54716796875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-12030.849131774901\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-9314.022595214845\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:44.16586108207703\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:85.90402239039541\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:72.6336473941803\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:85.13676307201385\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:45.37910766601563\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:87.3216785017401\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.66307093305512\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:99.3379162135534\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:97.11951868310571\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:98.81694918368011\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:99.43657482154667\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:98.64722761586309\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:97.8390959110111\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:96.2725686205551\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:98.14928851537407\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:97.84245657827705\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:97.33469429043762\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:97.92121128169819\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:91.09692020006477\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:93.49873650558293\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:95.03589472696186\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:93.38812082521616\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:93.83646160904317\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:91.14900626866147\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-4348021.01875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-4538348.3625\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-8128079.762500001\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-9131259.260546874\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3751113.5968750003\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-4743932.10625\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-13653.29765625\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-2202.9174392700197\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-21450.268322753906\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-17422.107238674165\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-1810.559422302246\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-16003.785311174392\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:75.0198299407959\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:81.94004849493504\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:88.87611759901046\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:89.1738439321518\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:74.00408763587475\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:81.77264313101769\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:98.84650058038534\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.49287781240419\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.79244669470935\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.47138066142797\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.44477678481489\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.40910570500418\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:98.84215666241943\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:98.8195146707818\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:98.66901199799031\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:97.46170482654124\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:98.17964170314372\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:98.81323636692832\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:94.93873470574617\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:94.44659452941269\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:90.83329170793294\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:94.23539891596884\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:93.69843881838024\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:94.10234784903004\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-289515.5291015625\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-9190950.96875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-9326266.481250001\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2970118.2843750003\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2118594.2156249997\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-4126199.6843749997\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-3.0789787292480497\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-397.1670692443848\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-229.7852814435959\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:27.32495031356812\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-2025.040966796875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-242.42431468963622\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:91.86455800235271\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:91.97425912097097\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:94.35720235109329\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:92.78546240627765\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:92.5140446960926\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:95.1506506614387\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.69493818096817\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.73454400058836\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.67105248309672\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.72501045241951\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.73686107294634\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.75293753407895\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:99.1784372379072\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:99.25499154403806\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:99.17523867301642\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:99.0475059629418\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:99.10526693221182\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:98.70371327912434\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:97.71447039190679\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:96.85054886220023\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:96.88759973142295\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:96.07691870499401\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:96.79121256824584\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:97.04121473766864\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-713623.2160156249\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-172173.74091796877\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-6693464.412109375\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-317246.4373046875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-292064.82109375\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-204725.9259765625\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:47.53978078365326\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:93.5694420337677\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:4.844496726989744\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:93.67408123016358\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:86.9437705039978\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-4838.604382252693\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:93.68657065927982\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:93.55138440579177\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:98.66712810993195\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:93.68672737181186\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.68756130635738\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:93.68645592331887\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.75188467651606\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.78075315244496\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.77738609714434\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.77926484234632\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.77846713233738\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.78714318163694\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.41924543045462\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.44064923888072\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.42987634101883\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.41106885932386\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.41782780624926\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.42182701043785\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:98.76382716763764\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:98.66240272391587\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:98.65628399262205\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:98.67390206828713\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:97.83029310610145\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:98.73910658797249\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-467040.3573242187\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-14406.154122924803\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-66782.01536254883\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-66652.58822631836\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-53597.9516784668\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-145907.21906127932\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2022.441105079651\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1201.091620826721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-173.96071560382845\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-732.1308626174928\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-952.0708727359771\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-507.83821027278896\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:6.988494694232939\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-7.592929345369348\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-5.6666026711464035\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:12.537073549628253\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:8.36597586274147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-31.074273478984836\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:85.6224962376058\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:85.64436979927123\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:92.75039267241955\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:84.95319841951132\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:94.51878425478935\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:91.16549472883344\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:91.210745719634\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:84.27298022136091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:96.20268235537223\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:85.5784420967102\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:88.22999439761043\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:93.06739146262407\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:77.08036048337817\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:88.48219232521951\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:88.9761181782931\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:86.67781580723822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:89.96061122715473\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:93.590054073371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-346322.77708740236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-347428.1755859375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-437729.8457885742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-509192.48618164065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-268318.25281982427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-696442.2952270508\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2570.1962774276735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-2173.194501876831\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2372.2878131866455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-4003.4531072616583\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1977.6774251937866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1064.4140377283095\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:83.99941904693841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:63.020334446430205\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:61.945871599018574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:60.98211764246225\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:65.16748922914266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:73.25263709798455\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.18295789211987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.89153893738985\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:88.99807827249168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:90.61366669200362\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:93.95411403533072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:88.21966518722475\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:91.33800583556294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:91.43087664917111\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:95.13160712569953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:93.65756473429501\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:92.3559939365834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:92.48957736175507\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:91.70803500153124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:93.46228214986623\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:89.52966725192965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:96.63558595310897\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:90.66084781438111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:87.36632635332644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-60419.85555419922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-145508.2788574219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-3568.3705112457274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-200484.59177246093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-213921.22376708986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-173460.40214843748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2118.889855194092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-7.4684924662113295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2935.1582449913026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2871.396065235138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-893.3382333278656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-410.8504648923874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:93.43595992326736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:76.03792965039611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:83.37154441401363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:93.40183949619532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:94.44456106200813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:95.99828406125307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:95.40696897991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:95.0069216106087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:92.25128810461611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:93.58769192919135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:93.73794960416853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:94.61984366234391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:94.14781326539814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:93.94320002086461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:93.11051353700459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:92.17064588405192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:93.76620979458093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:93.79515706785023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:93.46089172214269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:93.91225412599742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:91.51251868065447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:95.2570307513699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:88.60568246357144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:93.52407591640949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-32323.951953124997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-44219.57952270508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-72940.1789276123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-24471.79588623047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-16050.262576293946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-22011.446685791016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-753.3802618026733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-142.11200885772706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-635.3113695144654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-873.8131395339966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-352.9390206336975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-840.9714195728302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:97.7181035971269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:97.12219391912222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:93.85841706544161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:93.57942638546228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:96.62567258123308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:96.56442498266698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:96.9389840811491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:97.40200536148622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:97.98202509032562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:98.53529087994247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:98.13213429674506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:97.73269233042375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:93.68247632421554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:94.00355809405447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:93.82299690172076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:94.02668962432071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:93.57088638357818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:93.61197901442647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:93.81578183658421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:96.02020744420588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:95.91181388664991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:93.87260150182992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:93.6461896089837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:89.46745891608298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-2584.934244251251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-18298.673779296874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-5789.722383785248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1618.0864253997804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-4106.1976867675785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-5220.402965927125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-2468.116982460022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-160.20612411499022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-573.5287589073181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-307.15069646835326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:59.89068808555603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:36.27208182811737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:99.73397292699666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:99.5695201843977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:99.46525114234537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:99.71002652049064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:99.54085436053573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:99.62436284520663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.58196352943777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.56802528640254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.55253456188366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.42861389890312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.57746831313708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.52726142406463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:93.74107345491647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:93.77163642272353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:93.79550253301859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:93.77141230087727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:93.84477643063292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:93.80220113750546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:94.32554940879345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:93.68726043663919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:93.68985292557626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:93.73179901242257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:93.75065622963011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:93.8873705651611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:91.31421394348145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:27.94836730957031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:94.1268461227417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-118.2777816772461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-354.60487060546876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:97.12800903320313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:95.35696697086095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:96.35793805122375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:93.87187540531158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:90.65205171108246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:93.99635939598083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:91.70080258846282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:99.7095455145929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:98.33400965854526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:99.72717230655252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:99.72089650779962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:99.68230033442379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:99.73630123510956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.14485497856512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.72655247747898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.70048453179187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.6628124174662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.69021706543863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.71014040568843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:96.90279835835099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:98.99969752542674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.34852276146412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.43601006343961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:95.2891078453511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.33572312295436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:93.69001021869481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:93.87808256596327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:93.75977300480008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:93.69217578060926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:93.69410124775021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:93.69152839910238\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-268176.44018154143\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-251780.8847070694\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-997275.8067010404\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-2798571.15027008\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-498875.51321191783\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-648051.7291595459\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-6283.709569633007\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2854.1793081283568\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-568.2224617004395\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-863.2027161985636\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-11827.252312752604\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-39157.480008012055\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:51.79999904129654\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:13.008752180449667\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-72.77583480812608\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-10.67962851729245\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-21.9167479114607\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-43.47820076514035\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:71.03961538570002\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:84.72005251869558\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:68.1197538677603\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:64.2682460859418\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:68.21934189982713\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:76.21428803063463\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:88.69878501156346\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:94.57562160231173\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:91.12166189565323\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:88.96453268174082\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:91.28748775478452\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:92.5922172177583\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:87.59930203678087\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:93.53701955657452\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:89.8334300391376\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:91.33178323665634\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:89.65561428554356\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:92.08655594708398\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-4441183.506008529\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3482998.5810760497\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-4812728.985034561\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-3853896.199414063\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-6139346.240642548\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-3944636.40696392\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-29567.35278248787\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-46119.03712984324\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-43976.620511937144\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-30903.536799252033\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-45048.33808175921\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-60476.53891620636\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-53.716079814732076\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-169.2246984615922\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-881.2573418557644\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:-250.6742756560445\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-121.68180411979557\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-258.65864039473234\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:95.13025417886675\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:95.64922481626272\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:96.30078353378921\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:95.56234358744696\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:94.1076513695065\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:92.18207337688654\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:97.0306548490189\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:94.96312697236426\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:95.67510981196537\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:97.1863527412992\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:96.7661599523155\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:97.59815615573898\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:90.04103454910218\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:93.10974339779932\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:92.78068753294647\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:92.29902983214706\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:93.31245296467095\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:94.26632350571454\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-2246293.553513336\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1653223.3152965545\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1356107.4105926512\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1821538.2795936584\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1663627.4563843727\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1401094.4491134644\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-12122.047336268424\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-10848.461097812653\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-9517.187764394284\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-24604.791251277926\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-24209.80710248947\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-15865.012150406837\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:38.56290100514889\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:-9.859636326134202\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:-258.3338089898229\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:30.233077818155284\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:-126.28243126720191\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:-44.51275238525123\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:97.43099693320691\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:97.70059551112354\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:98.47152106184512\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:97.88282765252517\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:97.69814882259816\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:96.73059628400952\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:98.04764650634024\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:97.53624853901565\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:97.934090266563\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:97.0706396440044\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:97.2245090801269\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:98.42245755130425\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:89.64442825783044\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:94.94364483654499\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:93.80917792040854\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:95.29544453257695\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:94.50612281002104\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:94.3868040018715\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-269642.27652692795\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-166452.87528734206\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-847821.7693572999\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-601205.6495712281\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-239041.5434829712\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-494599.97783012385\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-2803.844620323181\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-2208.4323075056077\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1870.757523469627\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-7421.292176532745\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-2001.2689421415328\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-3307.5371024370193\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:63.70330313444137\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:68.3003889851272\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:24.713233520090583\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:83.03277280703188\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:73.80492614731193\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:72.14816299229861\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:99.08216104097664\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:99.07509622257203\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:98.87541383355855\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:99.34876738730819\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:99.21628864891827\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:99.10807078648358\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:99.0122172338888\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:98.47885737698525\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:98.97370359692722\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:99.14119568300083\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:98.77897464931011\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:98.76041251653805\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:96.38391573037953\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:96.67632648283616\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:95.80537143964321\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:95.31091917734594\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:96.18183343725978\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:94.23841074518859\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-25555.8645029068\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-30666.90668525696\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-25228.48877620697\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-33255.98496360779\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-26218.747434616093\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-21553.659707641604\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-786.0823858559131\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-592.079344034195\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-36.29790452867747\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-370.3562112390995\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-1198.925216436386\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-4311.947067165375\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:88.03349802307785\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:92.37718557193875\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:91.9246136277914\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:90.61846777051687\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:92.55312190949917\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:89.91745566129684\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:99.49098257981241\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:99.45365782696753\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:99.4373567495437\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:99.49472503140568\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:99.45440797740594\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:99.49909961465747\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:99.16701182369142\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:99.20407727137209\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:99.17778856419027\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:99.1551812268328\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:99.24403515723534\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:99.25370566323399\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:96.83230319749563\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:98.08548703361303\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:97.40655792341568\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:97.66358877830207\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:98.11217241573613\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:97.75416152328252\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-16874.48737678528\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-5968.101629257202\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-27902.794057655337\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:74.38163900375366\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-3705.982318973541\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-3601.085976600647\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-487.71522970199584\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-312.1837827866199\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-163.86688339710233\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-129.91508495211602\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-215.96900765895845\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-425.1996321439743\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:94.08507925868035\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:94.8003161907196\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:96.65219613909721\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:92.2695160797797\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:93.88473518267274\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:96.21188361942768\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:99.63604666572064\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:99.64032986420207\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:99.63093661365565\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:99.6258162844926\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:99.66094077583404\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:99.63475625142455\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:99.54187075421214\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:99.48036750606262\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:99.3931720778346\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:99.4974618362263\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:99.48992249686272\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:99.53517452292144\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:98.80862680897117\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:98.7611014741473\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:98.70723979882897\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:98.68700475525111\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:98.69442472364753\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:98.77870621718466\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#setup perangkat (GPU jika tersedia)\n",
        "\n",
        "hidden_layers = [1, 2, 3]\n",
        "neurons = [4, 8, 16, 32, 64]\n",
        "activations = [nn.Sigmoid, nn.ReLU, nn.Softmax, nn.Tanh]\n",
        "epochs_list = [1,10,25,50,100,250]\n",
        "learning_rates = [10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "batch_sizes = [16,32,64,128,256,512]\n",
        "#hyperparameter yang akan diuji\n",
        "\n",
        "results = []\n",
        "#menyimpan hasil\n",
        "\n",
        "for layers in hidden_layers:\n",
        "    for neuron in neurons:\n",
        "        for activation in activations:\n",
        "            for epochs in epochs_list:\n",
        "                for lr in learning_rates:\n",
        "                    for batch_size in batch_sizes:\n",
        "                        model = MLPRegression(input_size=X_train_tensor.shape[1],\n",
        "                                              hidden_layers=layers,\n",
        "                                              neurons=neuron,\n",
        "                                              activation=activation).to(device)\n",
        "                        #membuat dan memindahkan model ke perangkat (GPU atau CPU)\n",
        "#melakukan eksperimen dengan kombinasi hyperparameter\n",
        "\n",
        "                        criterion = nn.MSELoss()\n",
        "                        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "                        #mendefinisikan loss function dan optimizer\n",
        "\n",
        "                        for epoch in range(epochs):\n",
        "                            model.train()\n",
        "                            optimizer.zero_grad()\n",
        "                            outputs = model(X_train_tensor.to(device))\n",
        "                            loss = criterion(outputs, y_train_tensor.to(device))\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                        #training loop\n",
        "\n",
        "                        # Evaluasi model setelah pelatihan\n",
        "                        model.eval()\n",
        "                        with torch.no_grad():\n",
        "                            y_pred = model(X_test_tensor.to(device)).cpu().numpy()\n",
        "                            mae = mean_absolute_error(y_test, y_pred)\n",
        "                            mse = mean_squared_error(y_test, y_pred)\n",
        "                            r2 = r2_score(y_test, y_pred)\n",
        "                            accuracy = (1 - mae / max(y_test)) * 100\n",
        "                        #evaluasi model setelah pelatihan\n",
        "\n",
        "                        results.append({\n",
        "                            'layers': layers,\n",
        "                            'neurons': neuron,\n",
        "                            'activation': activation.__name__,\n",
        "                            'epochs': epochs,\n",
        "                            'lr': lr,\n",
        "                            'batch_size': batch_size,\n",
        "                            'mae': mae,\n",
        "                            'mse': mse,\n",
        "                            'r2': r2,\n",
        "                            'accuracy': accuracy\n",
        "                        })\n",
        "                        print(f\"Layers: {layers}, Neurons: {neuron}, Activation: {activation.__name__}, Epochs: {epochs}, LR: {lr}, Batch Size: {batch_size}, Accuracy:{accuracy}\")\n",
        "                        #menyimpan hasil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"mlp_regression_hidden layer 123.csv\", index=False)\n",
        "print(\"Semua hasil telah disimpan ke 'mlp_classification_hidden layer 123.csv'.\")\n",
        "#mengonversi hasil ke DataFrame dan menyimpannya ke CSV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj7oN4s8v165",
        "outputId": "4dde8ead-8334-44a6-e21a-87aaa718812f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semua hasil telah disimpan ke 'mlp_classification_hidden layer 123.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = ['layers', 'neurons', 'activation', 'epochs', 'lr', 'batch_size']\n",
        "mean_mae_by_hyperparameter = results_df.groupby(hyperparameters)['mae'].mean().reset_index()\n",
        "#memilih hyperparameter yang relevan dan menghitung rata-rata Mean Absolute Error (MAE)\n",
        "\n",
        "for param in hyperparameters:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
        "    plt.title(f'Mean MAE vs. {param.capitalize()}', fontsize=14)\n",
        "    plt.xlabel(param.capitalize(), fontsize=12)\n",
        "    plt.ylabel('Mean MAE', fontsize=12)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "#memvisualisasikan rata-rata MAE terhadap setiap hyperparameter."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vKZYcu10wGzR",
        "outputId": "d7cc1b0e-b829-4347-946f-d888787ca311"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-21-9e09720504a2>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}